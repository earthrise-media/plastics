{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Site Monitoring and Contour Generation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import datetime\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import rasterio as rs\n",
    "import shapely\n",
    "from tensorflow import keras\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from scripts import dl_utils\n",
    "from scripts.dl_utils import predict_spectrogram, rect_from_point"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Download Data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def load_ensemble(folder_path):\n",
    "    model_files = [file for file in os.listdir(folder_path) if '.h5' in file]\n",
    "    model_list = []\n",
    "    for file in model_files:\n",
    "        model_list.append(keras.models.load_model(os.path.join(folder_path,file)))\n",
    "    return model_list\n",
    "\n",
    "def predict_ensemble(pairs, model_list):\n",
    "    ensemble_preds = []\n",
    "    for pair in pairs:\n",
    "        pred_stack = []\n",
    "        for ensemble_model in model_list:\n",
    "            pred_stack.append(predict_spectrogram(pair, ensemble_model, unit_norm=True))\n",
    "        ensemble_preds.append(np.median(pred_stack, axis=0))\n",
    "    return ensemble_preds\n",
    "\n",
    "def generate_contours(preds, dates, threshold=0.5, plot=False):\n",
    "    \"\"\"\n",
    "    Generate a list of contours for a set of predictions\n",
    "    Inputs\n",
    "        - preds: A list of numpy prediction arrays\n",
    "        - dates: A list of dates for each scene in prediction list\n",
    "        - threshold: Value under which pixels are masked. Given that the heatmaps are first\n",
    "                     blurred, it is recommended to set this value lower than in blob detection\n",
    "        - plot: Visualize outputs if True\n",
    "    Outputs\n",
    "        - A list of contours. Each prediction frame has a separate list of contours. \n",
    "          Contours are defined as (x,y) pairs\n",
    "        - A list of dates for instance when contours were generated\n",
    "    \"\"\"\n",
    "    \n",
    "    img_size = preds[0].shape\n",
    "    \n",
    "    # Set a prediction threshold. Given that the heatmaps are blurred, it is recommended\n",
    "    # to set this value lower than you would in blob detection\n",
    "    contour_list = []\n",
    "    date_list = []\n",
    "    hierarchies = []\n",
    "    for pred, date in zip(preds, dates):\n",
    "        # If a scene is masked beyond a threshold, don't generate contours\n",
    "        masked_percentage = np.sum(pred.mask / np.size(pred.mask))\n",
    "        if masked_percentage < 0.1:\n",
    "            pred = np.array(Image.fromarray(pred).resize((img_size[0] * SCALE, img_size[1] * SCALE), Image.BICUBIC))\n",
    "            # OpenCV works best with ints in range (0,255)\n",
    "            input_img = (pred*255).astype(np.uint8)\n",
    "            # Blur the image to minimize the influence of single-pixel or mid-value model outputs\n",
    "            blurred = cv2.GaussianBlur(input_img, (8 * SCALE + 1,8 * SCALE + 1), cv2.BORDER_DEFAULT)\n",
    "            # Set all values below a threshold to 0\n",
    "            _, thresh = cv2.threshold(blurred, int(threshold * 255), 255, cv2.THRESH_TOZERO)\n",
    "            # Note that cv2.RETR_CCOMP returns a hierarchy of parent and child contours\n",
    "            # Needed for fixing the case with polygon holes \n",
    "            # https://docs.opencv.org/master/d9/d8b/tutorial_py_contours_hierarchy.html\n",
    "            contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            #contours = [contour for contour in contours if cv2.contourArea(contour) > 40 * SCALE]\n",
    "            contour_list.append(contours)\n",
    "            date_list.append(date)\n",
    "            hierarchies.append(hierarchy)\n",
    "            \n",
    "            if plot:\n",
    "                plt.figure(figsize=(16,4), dpi=150)\n",
    "                plt.subplot(1,4,1)\n",
    "                plt.imshow(np.array(Image.fromarray(pred).resize((img_size[0], img_size[1]), Image.BICUBIC)), vmin=0, vmax=1, cmap='RdBu_r')\n",
    "                plt.title('Pred')\n",
    "                plt.axis('off')\n",
    "                plt.subplot(1,4,3)\n",
    "                plt.imshow(thresh, vmin=0, vmax=255, cmap='RdBu_r')\n",
    "                plt.title('Thresholded Blur')\n",
    "                plt.axis('off')\n",
    "                plt.subplot(1,4,2)\n",
    "                plt.imshow(blurred, vmin=0, vmax=255, cmap='RdBu_r')\n",
    "                plt.title('Blurred')\n",
    "                plt.axis('off')\n",
    "                plt.subplot(1,4,4)\n",
    "                three_channel_preds = np.stack((blurred, blurred, blurred), axis=-1)\n",
    "                preds_contour_img = cv2.drawContours(three_channel_preds, contours, -1, (255, 0, 0), SCALE)\n",
    "                plt.imshow(preds_contour_img /255, vmin=0, vmax=255)\n",
    "                plt.title(f\"{len(contours)} separate contours\")\n",
    "                plt.axis('off')\n",
    "                plt.suptitle(date)\n",
    "                plt.show()\n",
    "                \n",
    "    return contour_list, date_list, hierarchies\n",
    "\n",
    "def generate_polygons(contour_list, hierarchies, bounds_list, preds, plot=False):\n",
    "    \"\"\"\n",
    "    Convert a list of coordinates into georeferenced shapely polygons\n",
    "    Inputs\n",
    "        - List of contours\n",
    "        - List of patch coordinate boundaries\n",
    "    Returns\n",
    "        - A list of shapely MultiPolygons. One for each coordinate in the input list\n",
    "    \"\"\"\n",
    "    contour_multipolygons = []\n",
    "    for contours, bounds, hierarchy in zip(contour_list, bounds_list, hierarchies):\n",
    "        # Define patch coordinate bounds to set pixel scale\n",
    "        bounds = shapely.geometry.Polygon(bounds).bounds\n",
    "        transform = rs.transform.from_bounds(*bounds, preds[0].shape[0] * SCALE, preds[0].shape[1] * SCALE)\n",
    "        polygon_coords = []\n",
    "        for contour in contours:\n",
    "            # Convert from pixels to coords\n",
    "            contour_coords = []\n",
    "            for point in contour[:,0]:\n",
    "                lon, lat = rs.transform.xy(transform, point[1], point[0])\n",
    "                contour_coords.append([[lon, lat]])\n",
    "            polygon_coords.append(np.array(contour_coords))\n",
    "        if len(polygon_coords) > 0:\n",
    "            contour_polygons = generate_sp_polygons(polygon_coords, hierarchy)\n",
    "        else:\n",
    "            contour_polygons = []\n",
    "\n",
    "        multipolygon = shapely.geometry.MultiPolygon(contour_polygons)\n",
    "        if not multipolygon.is_valid:\n",
    "            multipolygon = multipolygon.buffer(0)\n",
    "        if plot:\n",
    "            display(multipolygon)\n",
    "        contour_multipolygons.append(multipolygon)\n",
    "    return contour_multipolygons\n",
    "\n",
    "def pad_preds(preds, window_size):\n",
    "    pad_len = window_size - 1\n",
    "    padded_preds = np.concatenate(([np.mean(preds[:pad_len], axis=0) for _ in range(pad_len)], preds))\n",
    "    return padded_preds\n",
    "\n",
    "\n",
    "def mask_predictions(preds, window_size=6, threshold=0.1):\n",
    "    # Create a median prediction mask\n",
    "    if len(preds) <= window_size:\n",
    "        window_size = len(preds)\n",
    "    padded_preds = pad_preds(preds, window_size)\n",
    "    masks = np.array([np.median(padded_preds[i:i+window_size], axis=0) for i in range(0, len(preds))])\n",
    "    masks[masks < threshold] = 0\n",
    "    masks[masks > threshold] = 1\n",
    "    \n",
    "    # mask predictions\n",
    "    masked_preds = np.ma.multiply(preds, masks)\n",
    "    return masked_preds\n",
    "\n",
    "\n",
    "def _DFS(polygons, contours, hierarchy, sibling_id, is_outer, siblings):\n",
    "  while sibling_id != -1:\n",
    "      contour = contours[sibling_id].squeeze(axis=1)\n",
    "      if len(contour) >= 3:\n",
    "        first_child_id = hierarchy[sibling_id][2]\n",
    "        children = [] if is_outer else None\n",
    "        _DFS(polygons, contours, hierarchy, first_child_id, not is_outer, children)\n",
    "\n",
    "        if is_outer:\n",
    "          polygon = shapely.geometry.Polygon(contour, holes=children)\n",
    "          #display(polygon)\n",
    "          #print(hierarchy[sibling_id])\n",
    "          polygons.append(polygon)\n",
    "        else:\n",
    "          siblings.append(contour)\n",
    "\n",
    "      sibling_id = hierarchy[sibling_id][0]\n",
    "\n",
    "def generate_sp_polygons(contours, hierarchy):\n",
    "  \"\"\"Generates a list of Shapely polygons from the contours hirarchy returned by cv2.find_contours().\n",
    "     The list of polygons is generated by performing a depth-first search on the contours hierarchy tree.\n",
    "     Code from https://gist.github.com/stefano-malacrino/7d429e5d12854b9e51b187170e812fa4\n",
    "  Parameters\n",
    "  ----------\n",
    "  contours : list\n",
    "    The contours returned by cv2.find_contours()\n",
    "  hierarchy : list\n",
    "    The hierarchy returned by cv2.find_contours()\n",
    "  Returns\n",
    "  -------\n",
    "  list\n",
    "    The list of generated Shapely polygons\n",
    "  \"\"\"\n",
    "  \n",
    "  hierarchy = hierarchy[0]\n",
    "  polygons = []\n",
    "  _DFS(polygons, contours, hierarchy, 0, True, [])\n",
    "  return polygons\n",
    "\n",
    "def resolve_overlapping_contours(confirmed_sites, contour_df):\n",
    "    \"\"\"\n",
    "    This is not a function I am proud of writing. The intention is to \n",
    "    look at a dataframe of contours, find sets of overlapping contours,\n",
    "    and then assign a contour to the site which is nearest. It seems that\n",
    "    this could be done with less code and fewer loops.\n",
    "    Inputs:\n",
    "      - confirmed_sites: the original dataframe of site names and coordinates\n",
    "      - contour_gdf: a dataframe of contours for each site through time\n",
    "    Returns:\n",
    "      - a contour dataframe with no overlapping contours.\n",
    "    \"\"\"\n",
    "    rect_height = 0.02\n",
    "    rects = []\n",
    "    coords = [[site.x, site.y] for site in confirmed_sites['geometry']]\n",
    "    for candidate in coords:\n",
    "        rect = dl_utils.rect_from_point(candidate, rect_height)\n",
    "        rects.append(shapely.geometry.Polygon(rect['coordinates'][0]))\n",
    "\n",
    "    confirmed_sites['rect'] = rects\n",
    "    names = confirmed_sites['name']\n",
    "    overlapping = []\n",
    "    for name, rect in zip(names, rects):\n",
    "        overlapping.append([rect.overlaps(other_rects) for other_rects in rects])\n",
    "    confirmed_sites['overlap'] = [list(confirmed_sites['name'][overlap]) for overlap in overlapping]\n",
    "\n",
    "    contour_df['updated_geometry'] = [None for _ in range(len(contour_df))]\n",
    "\n",
    "    all_contours = []\n",
    "    contour_indices = []\n",
    "    for site in tqdm(names):\n",
    "        site_contours = list(contour_df[contour_df['name'] == site]['geometry'])\n",
    "        site_indices = list(contour_df[contour_df['name'] == site]['geometry'].index)\n",
    "        site_dates = list(contour_df[contour_df['name'] == site]['date'])\n",
    "        site_center = confirmed_sites[confirmed_sites['name'] == site]['geometry'].item()\n",
    "        overlapping_sites = list(confirmed_sites[confirmed_sites['name'] == site]['overlap'])[0]\n",
    "        \n",
    "        # iterate through each site with a rect that overlaps the site of interest rect\n",
    "        for external_site in overlapping_sites:\n",
    "            external_contours = list(contour_df[contour_df['name'] == external_site]['geometry'])\n",
    "            external_dates = list(contour_df[contour_df['name'] == external_site]['date'])\n",
    "            external_center = confirmed_sites[confirmed_sites['name'] == external_site]['geometry'].item()\n",
    "            \n",
    "            # iterate through each date where the site has a contour\n",
    "            for index, date in enumerate(site_dates):\n",
    "                \n",
    "                # check if overlapping site has a contour at that date\n",
    "                if date in external_dates:\n",
    "                    site_index = external_dates.index(date)\n",
    "                    \n",
    "                    # sometimes contours can be none. Check if contours exist for both\n",
    "                    if site_contours[index] and external_contours[site_index]:\n",
    "                        \n",
    "                        # check if the multipolygon contours overlap\n",
    "                        try:\n",
    "                            contours_overlap = site_contours[index].overlaps(external_contours[site_index])\n",
    "                            if contours_overlap == True:\n",
    "                                # if the contours overlap, create a new list of polygons\n",
    "                                site_polygon_list = []\n",
    "\n",
    "                                # make sure sites are multipolygons rather than polygons\n",
    "                                if type(external_contours[site_index]) != shapely.geometry.multipolygon.MultiPolygon:\n",
    "                                    external_contours[site_index] = shapely.geometry.MultiPolygon([external_contours[site_index]])\n",
    "\n",
    "                                # for each polygon in the external site multipolygon\n",
    "                                for external_polygon in external_contours[site_index].geoms:\n",
    "                                    # check each polygon in the site multipolygon to see if they overlap\n",
    "                                    if type(site_contours[index]) != shapely.geometry.multipolygon.MultiPolygon:\n",
    "                                        site_contours[index] = shapely.geometry.MultiPolygon([site_contours[index]])\n",
    "                                    for site_polygon in site_contours[index].geoms:\n",
    "\n",
    "                                        # if the site polygon overlaps, check which rect center is nearest\n",
    "                                        if site_polygon.overlaps(external_polygon):\n",
    "                                            site_centroid = site_polygon.centroid\n",
    "                                            site_distance = site_center.distance(site_centroid)\n",
    "                                            external_centroid = external_polygon.centroid\n",
    "                                            external_distance = external_center.distance(external_centroid)\n",
    "                                            if site_distance > external_distance:\n",
    "                                                #print(f\"Site {site} overlaps {external_site} on {date}, {site}'s polygon is closer\")\n",
    "                                                try:\n",
    "                                                    site_contours[index] -= site_polygon\n",
    "                                                except Exception as e:\n",
    "                                                    print(e)\n",
    "                                            # else:\n",
    "                                                #print(f\"Site {site} overlaps {external_site} on {date}, {external_site}'s polygon is closer\")\n",
    "                        except Exception as e:\n",
    "                            print(e)\n",
    "\n",
    "        all_contours += site_contours\n",
    "        contour_indices += site_indices\n",
    "\n",
    "    resolved_df = gpd.GeoDataFrame({\n",
    "            'name': contour_df['name'][contour_indices], \n",
    "            'date': contour_df['date'][contour_indices]}, \n",
    "            geometry=all_contours).set_crs('EPSG:4326')\n",
    "\n",
    "    resolved_df['area (km^2)'] = resolved_df['geometry'].to_crs('epsg:3395').map(lambda p: p.area / 10**6 if p != None else None)\n",
    "    \n",
    "    return resolved_df\n",
    "\n",
    "def filter_scattered_contours(contours, polygon_threshold=3, area_threshold=0.003):\n",
    "    # Bad contours are oftentimes small point sources of heat scattered throughout a frame\n",
    "    # If there are more than `polygon_threshold` contours in a multipolygon, and the average\n",
    "    # contour area is above `area_threshold`, then delete the polygons for that time point.\n",
    "    # area threshold is in km^2\n",
    "\n",
    "    filtered_contours = contours.copy()\n",
    "    for i in range(len(contours)):\n",
    "        site = contours.iloc[i]\n",
    "        if site['geometry'] != None and type(site['geometry']) == shapely.geometry.multipolygon.MultiPolygon:\n",
    "            num_polygons = len(site['geometry'].geoms)\n",
    "            area = site['area (km^2)']\n",
    "            if num_polygons >= polygon_threshold and area / num_polygons < area_threshold:\n",
    "                filtered_contours.iloc[i] = None\n",
    "    print(sum(filtered_contours['geometry'] == None) - sum(contours['geometry'] == None), \"contours removed\")\n",
    "    return filtered_contours"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "version_num = str(2.1)\n",
    "contour_output_path = f'../data/model_outputs/site_contours/{version_num}'\n",
    "if not os.path.exists(contour_output_path):\n",
    "    os.mkdir(contour_output_path)\n",
    "# Image upsampling factor. Makes for smoother contours\n",
    "SCALE = 4\n",
    "# Rect needs to be large enough to cover big sites. \n",
    "# But large rects take longer to process and increase false positive likelihood\n",
    "RECT_WIDTH = 0.008\n",
    "START_DATE = '2016-06-01'\n",
    "END_DATE = '2021-09-01'\n",
    "MOSAIC_PERIOD = 3\n",
    "SPECTROGRAM_INTERVAL = 2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#model_name = 'spectrogram_v0.0.11_2021-07-13'\n",
    "#model = keras.models.load_model(f'../models/{model_name}.h5')\n",
    "\n",
    "ensemble_name = 'v0.0.11_ensemble-8-25-21'\n",
    "model_list = load_ensemble(f'../models/{ensemble_name}')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "confirmed_sites_file = 'philippines_confirmed_v0.0.7_3.5_0.6_blob_detect_v0.1_classifier'\n",
    "confirmed_sites = gpd.read_file(f\"../data/sampling_locations/{confirmed_sites_file}.geojson\")\n",
    "coords = [[site.x, site.y] for site in confirmed_sites['geometry']]\n",
    "names = confirmed_sites['name']\n",
    "print(len(confirmed_sites), 'sites loaded')\n",
    "display(confirmed_sites.head())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Initialize a contour GeoDataFrame. I'm not certain that EPSG:4326 is the correct coordinate system.\n",
    "# Coordinate system must be set in order to compute polygon areas\n",
    "contour_gdf = gpd.GeoDataFrame(columns=['geometry', 'area (km^2)', 'date', 'name']).set_crs('EPSG:4326')\n",
    "failures = []\n",
    "for coord, name in zip(tqdm(coords), names):\n",
    "    try:\n",
    "        # Download data\n",
    "        mosaics, metadata = dl_utils.download_mosaics(\n",
    "            rect_from_point(coord, RECT_WIDTH), START_DATE, END_DATE, MOSAIC_PERIOD, method='min')\n",
    "        pairs = dl_utils.pair(mosaics, SPECTROGRAM_INTERVAL)\n",
    "\n",
    "        # Generate predictions\n",
    "        #preds = [predict_spectrogram(pair, model) for pair in pairs] # single model\n",
    "        preds = dl_utils.predict_ensemble(pairs, model_list)\n",
    "        preds_t = np.copy(preds)\n",
    "        for i in range(len(preds)):\n",
    "            preds_t[i][preds[i] < 0.5] = 0\n",
    "        window_size = 8\n",
    "        preds_m = mask_predictions(preds_t, window_size=window_size, threshold=0.2)\n",
    "\n",
    "        # Generate contours and polygons\n",
    "        dates = dl_utils.get_starts(START_DATE, END_DATE, 3, 2)[SPECTROGRAM_INTERVAL:]\n",
    "        bounds = [sample['wgs84Extent']['coordinates'][0][:-1] for sample in metadata[SPECTROGRAM_INTERVAL:]]\n",
    "        contours, contour_dates = generate_contours(preds_m, dates, threshold=0.2, plot=False)\n",
    "        polygons = generate_polygons(contours, bounds, preds_m, plot=False)\n",
    "\n",
    "        # Write contours to a GeoDataFrame\n",
    "        gdf = gpd.GeoDataFrame(geometry=polygons).set_crs('EPSG:4326')\n",
    "        gdf['date'] = [datetime.datetime.fromisoformat(date) for date in contour_dates]\n",
    "\n",
    "        # Calculate contour area. I'm not certain this is a valid technique for calculating area\n",
    "        gdf['area (km^2)'] = gdf['geometry'].to_crs('epsg:3395').map(lambda p: p.area / 10**6)\n",
    "        gdf['name'] = [name for _ in range(len(contour_dates))]\n",
    "        contour_gdf = contour_gdf.append(gdf, ignore_index=True)\n",
    "    except Exception as e:\n",
    "        print(name, 'failed')\n",
    "        print(e)\n",
    "        failures.append(name)\n",
    "\n",
    "print(f'{1 - len(failures) / len(confirmed_sites):.1%} success rate')\n",
    "print(f'Failed sites: {failures}')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "polygon_threshold = 3\n",
    "min_area_threshold = 0.003\n",
    "filtered_df = filter_scattered_contours(contour_gdf, polygon_threshold=polygon_threshold, area_threshold=min_area_threshold)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "resolved_df = resolve_overlapping_contours(confirmed_sites, filtered_df)\n",
    "resolved_df.to_file(f'{contour_output_path}/{confirmed_sites_file}_mask_window_{window_size}_upsampled_{SCALE}_contours_model_{ensemble_name}.geojson', driver='GeoJSON')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit ('venv-plastics': pyenv)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "interpreter": {
   "hash": "4a01d8cce8e3093998fa99b03bade8c0e7fde9c8096298c7b656f9b435102d6b"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

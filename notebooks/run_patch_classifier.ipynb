{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Patch Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from keplergl import KeplerGl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from scripts.viz_tools import normalize, plot_image_grid\n",
    "from scripts.dl_utils import download_patch, rect_from_point, pad_patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def patch_classifier_predict(polygon, model, start_date, end_date):\n",
    "    \"\"\"\n",
    "    Run a patch classifier on the polygon of interest.\n",
    "    Outputs predictions and patches for each patch extracted.\n",
    "    \"\"\"\n",
    "    input_width = model.input_shape[1]\n",
    "    \n",
    "    img_stack = download_patch(polygon, start_date, end_date)\n",
    "    img_stack = [pad_patch(img, input_width) for img in img_stack]\n",
    "    \n",
    "    preds = []\n",
    "    patches = []\n",
    "    for patch in img_stack:\n",
    "        if np.sum(patch.mask) / patch.size < cloud_threshold:\n",
    "            patch = pad_patch(patch, input_width)\n",
    "            patches.append(patch)\n",
    "            preds.append(model.predict(np.expand_dims(normalize(patch), axis=0))[0,1])\n",
    "    assert len(preds) == 0, \"No cloud free patches extracted. Try expanding your data time period.\"\n",
    "    return preds, patches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('../models/v1.1.0_200_4-23-21_patch_classifier_45px_patch.h5')\n",
    "input_width = model.input_shape[1]\n",
    "\n",
    "# Get model input size in degrees\n",
    "rect_width = np.round((input_width / 100) / 111.1, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Candidate Site Patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load coordinates from the detect_candidates output\n",
    "filename = 'Nusa_Tenggara_v1.1.8_2019-2020_candidates_pred-thresh_0.645_min-sigma_3.5_area-thresh_0.0025'\n",
    "\n",
    "candidate_sites = pd.read_csv('../data/model_outputs/candidate_sites/' + filename + '.csv')\n",
    "candidate_coords = [[lon, lat] for lat, lon in zip(list(candidate_sites['lat']), list(candidate_sites['lon']))]\n",
    "candidate_names = candidate_sites['name']\n",
    "candidate_polygons = [rect_from_point(coord, rect_width) for coord in candidate_coords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = '2020-01-01'\n",
    "end_date = '2020-06-01'\n",
    "output_dir = '../data/model_outputs/candidate_sites/'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.mkdir(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Network and Visualize Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud_threshold = 0.1\n",
    "\n",
    "patch_predictions = {}\n",
    "for polygon, name in tqdm(zip(candidate_polygons, candidate_names), total=len(candidate_polygons)):\n",
    "    preds, patches = patch_classifier_predict(polygon, model, start_date, end_date)\n",
    "    \n",
    "    patch_predictions[name] = {\n",
    "        'preds': preds,\n",
    "        'patches': patches,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.path.join(output_dir, filename)\n",
    "\n",
    "images = []\n",
    "labels = []\n",
    "for site in patch_predictions:\n",
    "    images.append(np.ma.median(patch_predictions[site]['patches'], axis=0))\n",
    "    labels.append(f\"{site.split('_')[-1]}: {np.mean(patch_predictions[site]['preds']):.2f}\")\n",
    "plot_image_grid(images, labels=labels, file_path=file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write Candidate Sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_preds = [np.mean(patch_predictions[site]['preds']) for site in patch_predictions]\n",
    "var_preds = [np.var(patch_predictions[site]['preds']) for site in patch_predictions]\n",
    "\n",
    "candidate_sites['mean'] = [np.mean(patch_predictions[site]['preds']) for site in patch_predictions]\n",
    "candidate_sites['median'] = [np.median(patch_predictions[site]['preds']) for site in patch_predictions]\n",
    "candidate_sites['min'] = [np.min(patch_predictions[site]['preds']) for site in patch_predictions]\n",
    "candidate_sites['max'] = [np.max(patch_predictions[site]['preds']) for site in patch_predictions]\n",
    "candidate_sites['variance'] = [np.var(patch_predictions[site]['preds']) for site in patch_predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.25\n",
    "# Write only sites with predictions greater than a threshold, or with a value of -1 (no data)\n",
    "filtered_candidate_sites = candidate_sites.query(f'mean > {threshold}')\n",
    "print(f\"{len(filtered_candidate_sites)} / {len(preds)} sites found above the threshold of {threshold}\")\n",
    "filtered_candidate_sites.to_csv(f'../data/model_outputs/candidate_sites/{filename}_patch_clf_thresh_{threshold}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_candidate_sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kepler_config={\n",
    "  \"version\": \"v1\",\n",
    "  \"config\": {\n",
    "    \"visState\": {\n",
    "      \"filters\": [],\n",
    "      \"layers\": [\n",
    "        {\n",
    "          \"id\": \"anqfulm\",\n",
    "          \"type\": \"point\",\n",
    "          \"config\": {\n",
    "            \"dataId\": \"Candidate Sites\",\n",
    "            \"label\": \"Point\",\n",
    "            \"color\": [\n",
    "              221,\n",
    "              178,\n",
    "              124\n",
    "            ],\n",
    "            \"columns\": {\n",
    "              \"lat\": \"lat\",\n",
    "              \"lng\": \"lon\",\n",
    "              \"altitude\": None\n",
    "            },\n",
    "            \"isVisible\": True,\n",
    "            \"visConfig\": {\n",
    "              \"radius\": 30,\n",
    "              \"fixedRadius\": False,\n",
    "              \"opacity\": 0.8,\n",
    "              \"outline\": True,\n",
    "              \"thickness\": 3,\n",
    "              \"strokeColor\": None,\n",
    "              \"colorRange\": {\n",
    "                \"name\": \"Global Warming\",\n",
    "                \"type\": \"sequential\",\n",
    "                \"category\": \"Uber\",\n",
    "                \"colors\": [\n",
    "                  \"#5A1846\",\n",
    "                  \"#900C3F\",\n",
    "                  \"#C70039\",\n",
    "                  \"#E3611C\",\n",
    "                  \"#F1920E\",\n",
    "                  \"#FFC300\"\n",
    "                ]\n",
    "              },\n",
    "              \"strokeColorRange\": {\n",
    "                \"name\": \"Global Warming\",\n",
    "                \"type\": \"sequential\",\n",
    "                \"category\": \"Uber\",\n",
    "                \"colors\": [\n",
    "                  \"#5A1846\",\n",
    "                  \"#900C3F\",\n",
    "                  \"#C70039\",\n",
    "                  \"#E3611C\",\n",
    "                  \"#F1920E\",\n",
    "                  \"#FFC300\"\n",
    "                ]\n",
    "              },\n",
    "              \"radiusRange\": [\n",
    "                0,\n",
    "                50\n",
    "              ],\n",
    "              \"filled\": False\n",
    "            },\n",
    "            \"hidden\": False,\n",
    "            \"textLabel\": [\n",
    "              {\n",
    "                \"field\": None,\n",
    "                \"color\": [\n",
    "                  255,\n",
    "                  255,\n",
    "                  255\n",
    "                ],\n",
    "                \"size\": 18,\n",
    "                \"offset\": [\n",
    "                  0,\n",
    "                  0\n",
    "                ],\n",
    "                \"anchor\": \"start\",\n",
    "                \"alignment\": \"center\"\n",
    "              }\n",
    "            ]\n",
    "          },\n",
    "          \"visualChannels\": {\n",
    "            \"colorField\": None,\n",
    "            \"colorScale\": \"quantile\",\n",
    "            \"strokeColorField\": {\n",
    "              \"name\": \"mean\",\n",
    "              \"type\": \"real\"\n",
    "            },\n",
    "            \"strokeColorScale\": \"quantile\",\n",
    "            \"sizeField\": None,\n",
    "            \"sizeScale\": \"linear\"\n",
    "          }\n",
    "        }\n",
    "      ],\n",
    "      },\n",
    "      \"mapStyle\":{\n",
    "         \"styleType\":\"satellite\"\n",
    "      }\n",
    "   }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_patches = [np.ma.median(patch_predictions[site]['patches'], axis=0) for site in filtered_candidate_sites['name']]\n",
    "plot_image_grid(positive_patches, labels=[name.split('_')[-1] for name in filtered_candidate_sites['name']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot blob locations on a satellite base image\n",
    "candidate_map = KeplerGl(height=800, config=kepler_config)\n",
    "candidate_map.add_data(data=filtered_candidate_sites, name='Candidate Sites')\n",
    "candidate_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

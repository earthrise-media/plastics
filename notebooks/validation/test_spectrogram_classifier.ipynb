{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import pickle\n",
    "from sklearn import metrics\n",
    "from tensorflow import keras\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from scripts import dl_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ndvi(pixel_arrays):\n",
    "    return (pixel_arrays[:,7] - pixel_arrays[:,3]) / (pixel_arrays[:,7] + pixel_arrays[:,3])\n",
    "\n",
    "def filter_ndvi(data, lower_bound=0, upper_bound=0.4):\n",
    "    ndvi = compute_ndvi(data)\n",
    "    index = np.logical_and(ndvi > lower_bound, ndvi < upper_bound)\n",
    "    filtered_data = data[index.all(axis=1)]\n",
    "    print(f\"{len(filtered_data) / len(data):.1%} of samples within NDVI range\")\n",
    "    return filtered_data\n",
    "\n",
    "def filter_bright(data, brightness_threshold=2500):\n",
    "    filtered_data = data[np.mean(data, axis=(1,2)) < brightness_threshold]\n",
    "    filtered_data.shape\n",
    "    print(f\"{len(filtered_data) / len(data) :.1%} of data below brightness limit\")\n",
    "    return filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dir = '../../data/training_data/pixel_arrays_3mo-mosaics_2x-int/'\n",
    "\n",
    "data_files = ['pixel_positive_polygons_2019-06-01_2021-06-01_pixel_arrays.pkl',\n",
    "              'negative_validation_points_farm_2019-06-01_2021-06-01_pixel_arrays.pkl',\n",
    "              'negative_validation_points_beach_2019-06-01_2021-06-01_pixel_arrays.pkl',\n",
    "              'negative_validation_points_river_2019-06-01_2021-06-01_pixel_arrays.pkl',\n",
    "              'negative_validation_points_city_2019-06-01_2021-06-01_pixel_arrays.pkl',\n",
    "              'negative_validation_points_forest_2019-06-01_2021-06-01_pixel_arrays.pkl',\n",
    "              'negative_validation_points_bare_2019-06-01_2021-06-01_pixel_arrays.pkl'\n",
    "             ]\n",
    "label_files = [f.split('s.pkl')[0] + '_labels.pkl' for f in data_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_arrays = []\n",
    "labels = []\n",
    "for data, label in tqdm(zip(data_files, label_files), total=len(data_files)):\n",
    "    with open(os.path.join(train_data_dir, data), 'rb') as f:\n",
    "        pixel_arrays += pickle.load(f)\n",
    "    with open(os.path.join(train_data_dir, label), 'rb') as f:\n",
    "        labels += pickle.load(f)\n",
    "            \n",
    "pixel_arrays = np.array(pixel_arrays)\n",
    "labels = np.array(labels)\n",
    "positive_arrays = pixel_arrays[labels == 1]\n",
    "negative_arrays = pixel_arrays[labels == 0]\n",
    "\n",
    "print(f\"Loaded {len(positive_arrays):,} positive pixel arrays and {len(negative_arrays):,} negative pixel arrays\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_data = {}\n",
    "for data in tqdm(data_files):\n",
    "    if 'negative' in data:\n",
    "        land_class = data.split('_')[3]\n",
    "        with open(os.path.join(train_data_dir, data), 'rb') as f:\n",
    "            neg_data[land_class] = np.array(pickle.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_positive_arrays = filter_ndvi(positive_arrays)\n",
    "filtered_positive_arrays = filter_bright(filtered_positive_arrays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_vectors = np.concatenate((filtered_positive_arrays, negative_arrays))\n",
    "pixel_labels = np.concatenate((np.ones(len(filtered_positive_arrays)), np.zeros(len(negative_arrays))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{len(filtered_positive_arrays):,} Positive Samples\")\n",
    "print(f\"{len(negative_arrays):,} Negative Samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Single Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'spectrogram_v0.0.7_2021-05-20'\n",
    "model = keras.models.load_model(f'../../models/{model_name}.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(np.expand_dims(dl_utils.normalize(pixel_vectors), axis=-1))[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(pixel_labels, preds > threshold, target_names=['Not Waste', 'Waste'], digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Positive-Class Accuracy: {np.sum(preds[pixel_labels == 1] > threshold) / sum(pixel_labels == 1):.2%}')\n",
    "print(f'Negative-Class Accuracy: {np.sum(preds[pixel_labels == 0] <= threshold) / sum(pixel_labels == 0):.2%}')\n",
    "\n",
    "for land_class in neg_data.keys():\n",
    "    neg_preds = model.predict(np.expand_dims(dl_utils.normalize(neg_data[land_class]), axis=-1))[:,1]\n",
    "    print(f'{land_class} Accuracy: {np.sum(neg_preds <= threshold) / len(neg_data[land_class]):.2%}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test RGB Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_model = keras.models.load_model('../../models/spectrogram_vrgb_2021-10-14.h5')\n",
    "rgb_preds = rgb_model.predict(np.expand_dims(dl_utils.normalize(pixel_vectors)[:,[3,2,1]], axis=-1))[:,1]\n",
    "print(f'RGB Positive-Class Accuracy: {np.sum(rgb_preds[pixel_labels == 1] > threshold) / sum(pixel_labels == 1):.2%}')\n",
    "print(f'RGB Negative-Class Accuracy: {np.sum(rgb_preds[pixel_labels == 0] <= threshold) / sum(pixel_labels == 0):.2%}')\n",
    "print(metrics.classification_report(pixel_labels, rgb_preds > threshold, target_names=['Not Waste', 'Waste'], digits=4))\n",
    "for land_class in neg_data.keys():\n",
    "    neg_preds = rgb_model.predict(np.expand_dims(dl_utils.normalize(neg_data[land_class][:,[3,2,1]]), axis=-1))[:,1]\n",
    "    print(f'{land_class} Accuracy: {np.sum(neg_preds <= threshold) / len(neg_data[land_class]):.2%}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test RGB IR Pixel Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_model = keras.models.load_model('../../models/spectrogram_vrgb_ir_2021-10-14.h5')\n",
    "rgb_preds = rgb_model.predict(np.expand_dims(dl_utils.normalize(pixel_vectors)[:,[7,3,2,1]], axis=-1))[:,1]\n",
    "print(f'RGB Positive-Class Accuracy: {np.sum(rgb_preds[pixel_labels == 1] > threshold) / sum(pixel_labels == 1):.2%}')\n",
    "print(f'RGB Negative-Class Accuracy: {np.sum(rgb_preds[pixel_labels == 0] <= threshold) / sum(pixel_labels == 0):.2%}')\n",
    "print(metrics.classification_report(pixel_labels, rgb_preds > threshold, target_names=['Not Waste', 'Waste'], digits=4))\n",
    "for land_class in neg_data.keys():\n",
    "    neg_preds = rgb_model.predict(np.expand_dims(dl_utils.normalize(neg_data[land_class])[:,[7,3,2,1]], axis=-1))[:,1]\n",
    "    print(f'{land_class} Accuracy: {np.sum(neg_preds <= threshold) / len(neg_data[land_class]):.2%}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Atemporal Pixel Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atemporal_model = keras.models.load_model('../../models/spectrogram_vno-spectrogram-3_2021-10-19.h5')\n",
    "normed = dl_utils.normalize(pixel_vectors)\n",
    "pixel_labels_atemporal = np.concatenate((pixel_labels, pixel_labels))\n",
    "preds = atemporal_model.predict(np.expand_dims(np.concatenate((normed[:,:,0], normed[:,:,1])), axis=-1))[:,1]\n",
    "print(f'Atemporal Positive-Class Accuracy: {np.sum(preds[pixel_labels_atemporal == 1] > threshold) / sum(pixel_labels_atemporal == 1):.2%}')\n",
    "print(f'Atemporal Negative-Class Accuracy: {np.sum(preds[pixel_labels_atemporal == 0] <= threshold) / sum(pixel_labels_atemporal == 0):.2%}')\n",
    "print(metrics.classification_report(pixel_labels_atemporal, preds > threshold, target_names=['Not Waste', 'Waste'], digits=4))\n",
    "for land_class in neg_data.keys():\n",
    "    normed = dl_utils.normalize(neg_data[land_class])\n",
    "    neg_preds = atemporal_model.predict(np.expand_dims(np.concatenate((normed[:,:,0], normed[:,:,1])), axis=-1))[:,1]\n",
    "    print(f'{land_class} Accuracy: {np.sum(neg_preds <= threshold) / (len(normed) * 2):.2%}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Ensemble of Pixel Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_name = 'v0.0.11_ensemble-8-25-21'\n",
    "model_list = dl_utils.load_ensemble(f'../../models/{ensemble_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normed_input = dl_utils.unit_norm_pixel(pixel_vectors)\n",
    "ensemble_preds = np.array([model.predict(np.expand_dims(normed_input, axis=-1))[:,1] for model in model_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(pixel_labels, np.median(ensemble_preds, axis=0) > threshold, target_names=['Not Waste', 'Waste'], digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Positive-Class Accuracy: {np.sum(np.mean(ensemble_preds, axis=0)[pixel_labels == 1] > threshold) / sum(pixel_labels == 1):.2%}')\n",
    "print(f'Negative-Class Accuracy: {np.sum(np.mean(ensemble_preds, axis=0)[pixel_labels == 0] <= threshold) / sum(pixel_labels == 0):.2%}')\n",
    "\n",
    "for land_class in neg_data.keys():\n",
    "    neg_preds = np.array([model.predict(np.expand_dims(dl_utils.unit_norm_pixel(neg_data[land_class]), axis=-1))[:,1] for model in model_list])\n",
    "    neg_preds = np.median(neg_preds, axis=0)\n",
    "    print(f'{land_class} Accuracy: {np.sum(neg_preds <= threshold) / len(neg_data[land_class]):.2%}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../models/random_forest.pkl', 'rb') as f:\n",
    "    forest = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_vectors.reshape(pixel_vectors.shape[0], -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normed_input = dl_utils.normalize(pixel_vectors)\n",
    "forest_preds = forest.predict(normed_input.reshape(normed_input.shape[0], -1))\n",
    "\n",
    "print(f'RGB Positive-Class Accuracy: {np.sum(forest_preds[pixel_labels == 1] > threshold) / sum(pixel_labels == 1):.2%}')\n",
    "print(f'RGB Negative-Class Accuracy: {np.sum(forest_preds[pixel_labels == 0] <= threshold) / sum(pixel_labels == 0):.2%}')\n",
    "print(metrics.classification_report(pixel_labels, forest_preds, target_names=['Not Waste', 'Waste'], digits=4))\n",
    "for land_class in neg_data.keys():\n",
    "    normed_input = dl_utils.normalize(neg_data[land_class])\n",
    "    neg_preds = forest.predict(normed_input.reshape(normed_input.shape[0], -1))\n",
    "    print(f'{land_class} Accuracy: {np.sum(neg_preds <= threshold) / len(neg_data[land_class]):.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Patch Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dir = '../../data/training_data/spectrogram_patches_3mo-mosaics_2x-int'\n",
    "\n",
    "patch_data_files = [\n",
    "    'negative_validation_points_farm_2019-06-01_2021-06-01_period_3_interval_2_method_min_patch_arrays.pkl',\n",
    "    'negative_validation_points_beach_2019-06-01_2021-06-01_period_3_interval_2_method_min_patch_arrays.pkl',\n",
    "    'negative_validation_points_river_2019-06-01_2021-06-01_period_3_interval_2_method_min_patch_arrays.pkl',\n",
    "    'negative_validation_points_city_2019-06-01_2021-06-01_period_3_interval_2_method_min_patch_arrays.pkl',\n",
    "    'negative_validation_points_forest_2019-06-01_2021-06-01_period_3_interval_2_method_min_patch_arrays.pkl',\n",
    "    'negative_validation_points_bare_2019-06-01_2021-06-01_period_3_interval_2_method_min_patch_arrays.pkl',\n",
    "    'pixel_positive_polygons_2019-06-01_2021-06-01_period_3_interval_2_method_min_patch_arrays.pkl'\n",
    "]\n",
    "\n",
    "patch_label_files = [f.split('s.pkl')[0] + '_labels.pkl' for f in patch_data_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_arrays = []\n",
    "patch_labels = []\n",
    "for data, label in tqdm(zip(patch_data_files, patch_label_files), total=len(patch_data_files)):\n",
    "    with open(os.path.join(train_data_dir, data), 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "        patch_arrays += [np.concatenate((dl_utils.unit_norm(dl_utils.pad_patch(patch[0], 28, 28)), \n",
    "                                         dl_utils.unit_norm(dl_utils.pad_patch(patch[1], 28, 28))), axis=-1) for patch in data]\n",
    "    with open(os.path.join(train_data_dir, label), 'rb') as f:\n",
    "        patch_labels += pickle.load(f)\n",
    "            \n",
    "patch_arrays = np.array(patch_arrays)\n",
    "patch_labels = np.array(patch_labels)\n",
    "positive_patch_arrays = patch_arrays[patch_labels == 1]\n",
    "negative_patch_arrays = patch_arrays[patch_labels == 0]\n",
    "\n",
    "print(f\"Loaded {len(positive_patch_arrays):,} positive pixel arrays and {len(negative_patch_arrays):,} negative pixel arrays\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_patch_data = {}\n",
    "for data in tqdm(patch_data_files):\n",
    "    if 'negative' in data:\n",
    "        land_class = data.split('_')[3]\n",
    "        with open(os.path.join(train_data_dir, data), 'rb') as f:\n",
    "            data =  pickle.load(f)\n",
    "            neg_patch_data[land_class] = np.array([np.concatenate((dl_utils.unit_norm(dl_utils.pad_patch(patch[0], 28, 28)), \n",
    "                                         dl_utils.unit_norm(dl_utils.pad_patch(patch[1], 28, 28))), axis=-1) for patch in data]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_model = keras.models.load_model('../../models/model_10.h5', custom_objects={'ELU': keras.layers.ELU})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_preds = patch_model.predict(patch_arrays)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.6\n",
    "print(\"Single Model, Model 3\")\n",
    "print(metrics.classification_report(patch_labels, patch_preds > threshold, target_names=['Not Waste', 'Waste'], digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Positive-Class Accuracy: {np.sum(patch_preds[patch_labels == 1] > threshold) / sum(patch_labels == 1):.2%}')\n",
    "print(f'Negative-Class Accuracy: {np.sum(patch_preds[patch_labels == 0] <= threshold) / sum(patch_labels == 0):.2%}')\n",
    "\n",
    "for land_class in neg_patch_data.keys():\n",
    "    neg_preds = patch_model.predict(neg_patch_data[land_class])[:,1]\n",
    "    print(f'{land_class} Accuracy: {np.sum(neg_preds <= threshold) / len(neg_patch_data[land_class]):.2%}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_folder = 'patch_ensemble_v2.0'\n",
    "patch_model_list = []\n",
    "for path in os.listdir(f'../../models/{model_folder}'):\n",
    "    patch_model_list.append(keras.models.load_model(f'../../models/{model_folder}/{path}', custom_objects={'ELU': keras.layers.ELU}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_patch_ensemble(X, models, return_disagreement=False):\n",
    "    preds = list() #list of model predictions, will be (len(models), len(X), 2) in dimension\n",
    "    \n",
    "    #run ensemble\n",
    "    for model in models:\n",
    "        preds.append(model.predict(X))\n",
    "    \n",
    "    #convert soft predictions to absolute\n",
    "    for pred in preds:\n",
    "        for i in range(0, pred.shape[0]):\n",
    "            y = [0, 0]\n",
    "            y[np.argmax(pred[i])] = 1.0\n",
    "            pred[i] = y\n",
    "    \n",
    "    #aggregate predictions in votes\n",
    "    pred_sum = preds[0]\n",
    "    for i in range(1, len(preds)):\n",
    "        pred_sum += preds[i]\n",
    "    \n",
    "    #pick the prediction with the highest votes\n",
    "    for i in range(0, len(pred_sum)):\n",
    "        y = [0, 0]\n",
    "        y[np.argmax(pred_sum[i])] = 1.0\n",
    "        pred_sum[i] = y\n",
    "    \n",
    "    #compute the std of the votes (a measure of disagreement)\n",
    "    if return_disagreement:\n",
    "        return np.asarray(pred_sum), np.std(np.asarray(preds)[:,:,0],0)\n",
    "    \n",
    "    return np.asarray(pred_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_patch_preds = predict_patch_ensemble(patch_arrays, patch_model_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_patch_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Ensemble of 32 Models\")\n",
    "print(metrics.classification_report(patch_labels, ensemble_patch_preds[:,1], target_names=['Not Waste', 'Waste'], digits=4))\n",
    "\n",
    "print(f'Positive-Class Accuracy: {np.sum(ensemble_patch_preds[:,1][patch_labels == 1] > threshold) / sum(patch_labels == 1):.2%}')\n",
    "print(f'Negative-Class Accuracy: {np.sum(ensemble_patch_preds[:,1][patch_labels == 0] <= threshold) / sum(patch_labels == 0):.2%}')\n",
    "\n",
    "for land_class in neg_patch_data.keys():\n",
    "    neg_preds = predict_patch_ensemble(neg_patch_data[land_class], patch_model_list)[:,1]\n",
    "    print(f'{land_class} Accuracy: {np.sum(neg_preds <= threshold) / len(neg_patch_data[land_class]):.2%}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5449280da88087bfd38190fcaab9940b2d5c81d9d2575a498a2489a8a7c73f86"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit ('venv-plastics': pyenv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

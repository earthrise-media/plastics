{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Temporal Patch Classifier\n",
    "Currently set up to run a temporal patch classifier that takes inputs of shape `(batch_size, h, w, 24)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from keplergl import KeplerGl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from tensorflow import keras\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from scripts.viz_tools import normalize, plot_image_grid\n",
    "from scripts.dl_utils import download_patch, rect_from_point, pad_patch, unit_norm\n",
    "from scripts import dl_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_DATE = '2019-01-01'\n",
    "END_DATE = '2020-02-01'\n",
    "METHOD = 'min'\n",
    "MOSAIC_PERIOD = 3  # the period over which to mosaic image data in months\n",
    "SPECTROGRAM_INTERVAL = 2  # For spectrogram analysis, the time from the start of one mosaic to the start of the next,\n",
    " # in number of mosaic periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def patch_classifier_predict(polygon, model):\n",
    "    \"\"\"\n",
    "    Run a patch classifier on the polygon of interest.\n",
    "    Outputs predictions and patches for each patch extracted.\n",
    "    \"\"\"\n",
    "    \n",
    "    mosaics, _ = dl_utils.download_mosaics(polygon, START_DATE, END_DATE, MOSAIC_PERIOD, method=METHOD)\n",
    "    new_pairs = dl_utils.pair(mosaics, SPECTROGRAM_INTERVAL)\n",
    "    pairs = [p for p in new_pairs if dl_utils.masks_match(p)]\n",
    "    \n",
    "    preds = []\n",
    "    for pair in pairs:\n",
    "        model_input = np.zeros((28,28,24))\n",
    "        model_input[:,:,:12] = unit_norm(pad_patch(pair[0], 28))\n",
    "        model_input[:,:,12:] = unit_norm(pad_patch(pair[1], 28))\n",
    "        pred = model.predict(np.expand_dims(model_input, axis=0))[0][1]\n",
    "        preds.append(pred)\n",
    "    if len(preds) == 0:\n",
    "        print(\"No cloud free patches extracted. Try expanding your data time period.\")\n",
    "    \n",
    "    return preds, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the model version number for pixel classifier that generated the candidate points\n",
    "pixel_classifier_version = '0.0.7'\n",
    "# List the desired patch classifier version\n",
    "patch_classifier_version = '0.3'\n",
    "output_dir = f'../data/model_outputs/candidate_sites/{pixel_classifier_version}/patches_v{patch_classifier_version}'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(f'../models/v{patch_classifier_version}_weak_labels_28x28x24.h5', \n",
    "                                custom_objects={'LeakyReLU': keras.layers.LeakyReLU,\n",
    "                                                'ELU': keras.layers.ELU,\n",
    "                                                'ReLU': keras.layers.ReLU\n",
    "                                               })\n",
    "input_height = model.input_shape[1]\n",
    "# Get model input size in degrees\n",
    "rect_height = ((input_height + 4) / 100) / 111.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Candidate Site Patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load coordinates from the detect_candidates output\n",
    "filename = 'west_timor_v0.0.7_2019-01-01_2021-06-01mosaic-median_blobs_thresh_0.8_min-sigma_5_area-thresh_0.0025'\n",
    "\n",
    "candidate_sites = gpd.read_file(f'../data/model_outputs/candidate_sites/{pixel_classifier_version}/' + filename + '.geojson')\n",
    "candidate_sites['rects'] = [rect_from_point([point.x, point.y], rect_height) for point in candidate_sites['geometry']]\n",
    "print(len(candidate_sites), \"candidate sites loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Network and Export Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "patch_predictions = {}\n",
    "for polygon, name in tqdm(zip(candidate_sites['rects'], candidate_sites['name']), total=len(candidate_sites['rects'])):\n",
    "    try:\n",
    "        preds, patches = patch_classifier_predict(polygon, model)\n",
    "\n",
    "        print(f\"{name}, {preds}\")\n",
    "        patch_predictions[name] = {\n",
    "            'preds': preds,\n",
    "            'patches': patches,\n",
    "        }\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Keyboard Interrupt!\")\n",
    "        break\n",
    "    except Exception as e:\n",
    "        print('Failure', name)\n",
    "        print(e)\n",
    "        patch_predictions[name] = {\n",
    "            'preds': [],\n",
    "            'patches': [],\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill candidate sites with -1 values. -1 indicates no data\n",
    "# These will only be replaced if the patch classifier predicted at that location\n",
    "candidate_sites['mean'] = [-1 for _ in range(len(candidate_sites))]\n",
    "candidate_sites['min'] = [-1 for _ in range(len(candidate_sites))]\n",
    "candidate_sites['max'] = [-1 for _ in range(len(candidate_sites))]\n",
    "candidate_sites['std'] = [-1 for _ in range(len(candidate_sites))]\n",
    "candidate_sites['count'] = [-1 for _ in range(len(candidate_sites))]\n",
    "\n",
    "# I round to 6 decimals since kepler.gl can sometimes be confused in thinking scientific notation is a string\n",
    "for site in patch_predictions:\n",
    "    index = np.argmax(candidate_sites['name'] == site)\n",
    "    preds = patch_predictions[site]['preds']\n",
    "    if len(preds) > 0:\n",
    "        candidate_sites.loc[index, ('mean')] = round(np.mean(preds).astype(np.float), 6)\n",
    "        candidate_sites.loc[index, ('min')] = round(np.min(preds).astype(np.float), 6)\n",
    "        candidate_sites.loc[index, ('max')] = round(np.max(preds).astype(np.float), 6)\n",
    "        candidate_sites.loc[index, ('std')] = round(np.std(preds).astype(np.float), 6)\n",
    "        candidate_sites.loc[index, ('count')] = len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Lon, lat are redundant given the geometry. Drop them from the exported file\n",
    "candidate_sites_export = candidate_sites.drop(['lon', 'lat', 'rects'], axis=1)\n",
    "candidate_sites_export.to_file(os.path.join(output_dir, 'patch_' + filename + '.geojson'), driver='GeoJSON', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "num_img = int(np.ceil(np.sqrt(len([np.mean(v['preds']) for v in patch_predictions.values() if len(v['preds']) > 0]))))\n",
    "plt.figure(figsize=(num_img * 2,num_img), dpi=150, facecolor=(1,1,1))\n",
    "\n",
    "counter = 1\n",
    "for v in patch_predictions.values():\n",
    "    if len(v['preds']) > 0:\n",
    "        plt.subplot(num_img, num_img, counter)\n",
    "        images = np.zeros((28,57,12))\n",
    "        patches = v['patches'][0]\n",
    "        images[:,:28,:] = unit_norm(pad_patch(patches[0], 28))\n",
    "        images[:,29:,:] = unit_norm(pad_patch(patches[1], 28))\n",
    "        plt.imshow(np.clip(images[:,:,3:0:-1] / 4 + 0.5, 0, 1))\n",
    "        plt.axis('off')\n",
    "        plt.title(f\"{np.mean(v['preds']):.2f}\")\n",
    "        counter += 1\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.25\n",
    "filtered_candidate_sites = candidate_sites_export.query(f'mean > {threshold}')\n",
    "print(f\"{len(filtered_candidate_sites)} / {len(candidate_sites_export)} sites found above the threshold of {threshold}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_candidate_sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kepler_config={\n",
    "  \"version\": \"v1\",\n",
    "  \"config\": {\n",
    "    \"visState\": {\n",
    "      \"filters\": [],\n",
    "      \"layers\": [\n",
    "        {\n",
    "          \"id\": \"anqfulm\",\n",
    "          \"type\": \"point\",\n",
    "          \"config\": {\n",
    "            \"dataId\": \"Candidate Sites\",\n",
    "            \"label\": \"Point\",\n",
    "            \"color\": [\n",
    "              221,\n",
    "              178,\n",
    "              124\n",
    "            ],\n",
    "            \"columns\": {\n",
    "              \"lat\": \"lat\",\n",
    "              \"lng\": \"lon\",\n",
    "              \"altitude\": None\n",
    "            },\n",
    "            \"isVisible\": True,\n",
    "            \"visConfig\": {\n",
    "              \"radius\": 30,\n",
    "              \"fixedRadius\": False,\n",
    "              \"opacity\": 0.8,\n",
    "              \"outline\": True,\n",
    "              \"thickness\": 3,\n",
    "              \"strokeColor\": None,\n",
    "              \"colorRange\": {\n",
    "                \"name\": \"Global Warming\",\n",
    "                \"type\": \"sequential\",\n",
    "                \"category\": \"Uber\",\n",
    "                \"colors\": [\n",
    "                  \"#5A1846\",\n",
    "                  \"#900C3F\",\n",
    "                  \"#C70039\",\n",
    "                  \"#E3611C\",\n",
    "                  \"#F1920E\",\n",
    "                  \"#FFC300\"\n",
    "                ]\n",
    "              },\n",
    "              \"strokeColorRange\": {\n",
    "                \"name\": \"Global Warming\",\n",
    "                \"type\": \"sequential\",\n",
    "                \"category\": \"Uber\",\n",
    "                \"colors\": [\n",
    "                  \"#5A1846\",\n",
    "                  \"#900C3F\",\n",
    "                  \"#C70039\",\n",
    "                  \"#E3611C\",\n",
    "                  \"#F1920E\",\n",
    "                  \"#FFC300\"\n",
    "                ]\n",
    "              },\n",
    "              \"radiusRange\": [\n",
    "                0,\n",
    "                50\n",
    "              ],\n",
    "              \"filled\": False\n",
    "            },\n",
    "            \"hidden\": False,\n",
    "            \"textLabel\": [\n",
    "              {\n",
    "                \"field\": None,\n",
    "                \"color\": [\n",
    "                  255,\n",
    "                  255,\n",
    "                  255\n",
    "                ],\n",
    "                \"size\": 18,\n",
    "                \"offset\": [\n",
    "                  0,\n",
    "                  0\n",
    "                ],\n",
    "                \"anchor\": \"start\",\n",
    "                \"alignment\": \"center\"\n",
    "              }\n",
    "            ]\n",
    "          },\n",
    "          \"visualChannels\": {\n",
    "            \"colorField\": None,\n",
    "            \"colorScale\": \"quantile\",\n",
    "            \"strokeColorField\": {\n",
    "              \"name\": \"mean\",\n",
    "              \"type\": \"real\"\n",
    "            },\n",
    "            \"strokeColorScale\": \"quantile\",\n",
    "            \"sizeField\": None,\n",
    "            \"sizeScale\": \"linear\"\n",
    "          }\n",
    "        }\n",
    "      ],\n",
    "      },\n",
    "      \"mapStyle\":{\n",
    "         \"styleType\":\"satellite\"\n",
    "      }\n",
    "   }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot blob locations on a satellite base image\n",
    "candidate_map = KeplerGl(height=800, config=kepler_config)\n",
    "candidate_map.add_data(data=filtered_candidate_sites.copy(), name='Candidate Sites')\n",
    "candidate_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Datasets\n",
    "This notebook is the source for downloading Sentinel data for the spectral classifier\n",
    "\n",
    "### Inputs\n",
    "Sites are generated from geojson inputs. The positive TPA sites are defined by polygons, and the negative sites are defined by points. \n",
    "New negative sites can be added by following the example of the bootstrap dataset\n",
    "\n",
    "### Raw Data:\n",
    "The output is a dictionary with a structure `[date][site_name][band][band_img]`\n",
    "\n",
    "### Pixel Vectors:\n",
    "The output is a list of vectors. `[num_vectors][bands]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import ee\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from scripts.get_s2_data_ee import get_history, get_history_polygon, get_pixel_vectors\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentinel 2 band descriptions\n",
    "band_descriptions = {\n",
    "    'B1': 'Aerosols, 442nm',\n",
    "    'B2': 'Blue, 492nm',\n",
    "    'B3': 'Green, 559nm',\n",
    "    'B4': 'Red, 665nm',\n",
    "    'B5': 'Red Edge 1, 704nm',\n",
    "    'B6': 'Red Edge 2, 739nm',\n",
    "    'B7': 'Red Edge 3, 779nm',\n",
    "    'B8': 'NIR, 833nm',\n",
    "    'B8A': 'Red Edge 4, 864nm',\n",
    "    'B9': 'Water Vapor, 943nm',\n",
    "    'B11': 'SWIR 1, 1610nm',\n",
    "    'B12': 'SWIR 2, 2186nm'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_geojson(file_name):\n",
    "    \"\"\"Load points saved as a GeoJSON and return a dictionary\"\"\"\n",
    "    with open(os.path.join(DATA_DIR, file_name)) as f:\n",
    "        sites = json.load(f)\n",
    "    f.close()\n",
    "\n",
    "    sampling_df = pd.DataFrame({\n",
    "        'name': [file_name.split('_')[0] + '_' + str(index) for index in range(len(sites['features']))],\n",
    "        'lon': [site['geometry']['coordinates'][0] for site in sites['features']],\n",
    "        'lat': [site['geometry']['coordinates'][1] for site in sites['features']],\n",
    "        'coords': [site['geometry']['coordinates'][0:2] for site in sites['features']],\n",
    "    })\n",
    "    \n",
    "    return sampling_df\n",
    "\n",
    "def load_csv(file_name):\n",
    "    sampling_df = pd.read_csv(os.path.join(DATA_DIR, file_name), converters={'coords': eval})\n",
    "    \n",
    "    return sampling_df\n",
    "\n",
    "def sample_adjacent(tpa_sites, offset, direction='east'):\n",
    "    \"\"\"\n",
    "    Outputs a data frame of sampling locations based on a distance\n",
    "    and direction from each TPA site.\n",
    "    This can be used for adjacent site sampling, or to create \"random\" negative sites if the\n",
    "    offset distance is set further away from the TPA location.\n",
    "    Returns a data frame\n",
    "    \"\"\"\n",
    "    if  'east' in direction.lower():\n",
    "        adjacent_sites = pd.DataFrame({\n",
    "            'name': [f\"{name}_{direction.lower()}_{offset}\" for name in tpa_sites['name']],\n",
    "            'lon': [lon + offset for lon in tpa_sites['lon']],\n",
    "            'lat': [lat for lat in tpa_sites['lat']],\n",
    "            'coords': [[lon + offset, lat] for lon, lat in zip(tpa_sites['lon'], tpa_sites['lat'])]\n",
    "        })\n",
    "        \n",
    "    if  'west' in direction.lower():\n",
    "        adjacent_sites = pd.DataFrame({\n",
    "            'name': [f\"{name}_{direction.lower()}_{offset}\" for name in tpa_sites['name']],\n",
    "            'lon': [lon - offset for lon in tpa_sites['lon']],\n",
    "            'lat': [lat for lat in tpa_sites['lat']],\n",
    "            'coords': [[lon + offset, lat] for lon, lat in zip(tpa_sites['lon'], tpa_sites['lat'])]\n",
    "        })\n",
    "    \n",
    "    if  'north' in direction.lower():\n",
    "        adjacent_sites = pd.DataFrame({\n",
    "            'name': [f\"{name}_{direction.lower()}_{offset}\" for name in tpa_sites['name']],\n",
    "            'lon': [lon for lon in tpa_sites['lon']],\n",
    "            'lat': [lat + offset for lat in tpa_sites['lat']],\n",
    "            'coords': [[lon + offset, lat] for lon, lat in zip(tpa_sites['lon'], tpa_sites['lat'])]\n",
    "        })\n",
    "    \n",
    "    if  'south' in direction.lower():\n",
    "        adjacent_sites = pd.DataFrame({\n",
    "            'name': [f\"{name}_{direction.lower()}_{offset}\" for name in tpa_sites['name']],\n",
    "            'lon': [lon for lon in tpa_sites['lon']],\n",
    "            'lat': [lat - offset for lat in tpa_sites['lat']],\n",
    "            'coords': [[lon + offset, lat] for lon, lat in zip(tpa_sites['lon'], tpa_sites['lat'])]\n",
    "        })\n",
    "    \n",
    "    return adjacent_sites\n",
    "\n",
    "def save_patch_history(data, name, label_class):\n",
    "    file_name = f\"{name}_raw_{num_months}_months_{start_date}\"\n",
    "    with open(os.path.join(OUTPUT_DIR, 'patch_histories', f\"{file_name}_patch_history.pkl\"),\"wb\") as f:\n",
    "        pickle.dump(data, f)\n",
    "        \n",
    "    with open(os.path.join(OUTPUT_DIR, 'patch_histories', f\"{file_name}_patch_history_labels.pkl\"),\"wb\") as f:\n",
    "        pickle.dump([label_class] * len(data), f)\n",
    "        \n",
    "        \n",
    "def create_pixel_vectors(patch_history, num_months, holdout=False):\n",
    "    # Decompose patch history into vectors\n",
    "    # Output is month, pixel, band_value\n",
    "    pixel_data = []\n",
    "    if not holdout:\n",
    "        for month in list(patch_history.keys())[:num_months]:\n",
    "            pixel_vectors, width, height = get_pixel_vectors(patch_history, month)\n",
    "            pixel_data.append(pixel_vectors)\n",
    "\n",
    "    else:\n",
    "        for month in list(patch_history.keys())[num_months:]:\n",
    "            pixel_vectors, width, height = get_pixel_vectors(patch_history, month)\n",
    "            pixel_data.append(pixel_vectors)\n",
    "    # flatten all pixel_vectors into a flat set of vectors\n",
    "    # num_vectors, num_bands\n",
    "    pixel_vectors = []\n",
    "    for month in pixel_data:\n",
    "        for pixel in month:\n",
    "            pixel_vectors.append(pixel)\n",
    "\n",
    "    print(np.shape(pixel_vectors)[0], \"pixel vectors\")\n",
    "    \n",
    "    return pixel_vectors\n",
    "\n",
    "def save_pixel_vectors(data, name, label_class):\n",
    "    file_name = f\"{name}_raw_{num_months}_months_{start_date}\"\n",
    "    with open(os.path.join(OUTPUT_DIR, 'pixel_vectors', f\"{file_name}_pixel_vectors.pkl\"),\"wb\") as f:\n",
    "        pickle.dump(data, f)\n",
    "        \n",
    "    with open(os.path.join(OUTPUT_DIR, 'pixel_vectors', f\"{file_name}_pixel_vector_labels.pkl\"),\"wb\") as f:\n",
    "        pickle.dump([label_class] * len(data), f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Sampling Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration:\n",
    "# Set directory where training site json files are located and files are saved\n",
    "# Set rect width for all patches that are not TPA sites\n",
    "DATA_DIR = '../data/sampling_locations'\n",
    "OUTPUT_DIR = '../data/training_data'\n",
    "\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.mkdir(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load TPA Polygon Sites from GeoJSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>area</th>\n",
       "      <th>daily_volume</th>\n",
       "      <th>coords</th>\n",
       "      <th>polygons</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TPA Jungut Batu</td>\n",
       "      <td>115.459414</td>\n",
       "      <td>-8.670958</td>\n",
       "      <td>1.20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[115.45941439485306, -8.670958330781342]</td>\n",
       "      <td>ee.FeatureCollection({\\n  \"functionInvocationV...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TPA Biaung</td>\n",
       "      <td>115.498017</td>\n",
       "      <td>-8.679930</td>\n",
       "      <td>1.85</td>\n",
       "      <td>9433.0</td>\n",
       "      <td>[115.49801683267276, -8.679930042100876]</td>\n",
       "      <td>ee.FeatureCollection({\\n  \"functionInvocationV...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TPA Sente</td>\n",
       "      <td>115.454460</td>\n",
       "      <td>-8.530372</td>\n",
       "      <td>1.00</td>\n",
       "      <td>43219.0</td>\n",
       "      <td>[115.45446033358267, -8.530371792768301]</td>\n",
       "      <td>ee.FeatureCollection({\\n  \"functionInvocationV...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TPA Regional Bangli</td>\n",
       "      <td>115.367927</td>\n",
       "      <td>-8.353542</td>\n",
       "      <td>0.99</td>\n",
       "      <td>47350.0</td>\n",
       "      <td>[115.3679270185395, -8.353541681392851]</td>\n",
       "      <td>ee.FeatureCollection({\\n  \"functionInvocationV...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TPA Peh</td>\n",
       "      <td>114.583295</td>\n",
       "      <td>-8.327938</td>\n",
       "      <td>2.00</td>\n",
       "      <td>38130.0</td>\n",
       "      <td>[114.58329467897306, -8.327937523143966]</td>\n",
       "      <td>ee.FeatureCollection({\\n  \"functionInvocationV...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  name         lon       lat  area  daily_volume  \\\n",
       "0      TPA Jungut Batu  115.459414 -8.670958  1.20           NaN   \n",
       "1           TPA Biaung  115.498017 -8.679930  1.85        9433.0   \n",
       "2            TPA Sente  115.454460 -8.530372  1.00       43219.0   \n",
       "3  TPA Regional Bangli  115.367927 -8.353542  0.99       47350.0   \n",
       "4              TPA Peh  114.583295 -8.327938  2.00       38130.0   \n",
       "\n",
       "                                     coords  \\\n",
       "0  [115.45941439485306, -8.670958330781342]   \n",
       "1  [115.49801683267276, -8.679930042100876]   \n",
       "2  [115.45446033358267, -8.530371792768301]   \n",
       "3   [115.3679270185395, -8.353541681392851]   \n",
       "4  [114.58329467897306, -8.327937523143966]   \n",
       "\n",
       "                                            polygons  \n",
       "0  ee.FeatureCollection({\\n  \"functionInvocationV...  \n",
       "1  ee.FeatureCollection({\\n  \"functionInvocationV...  \n",
       "2  ee.FeatureCollection({\\n  \"functionInvocationV...  \n",
       "3  ee.FeatureCollection({\\n  \"functionInvocationV...  \n",
       "4  ee.FeatureCollection({\\n  \"functionInvocationV...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load TPA dataset\n",
    "with open(os.path.join(DATA_DIR, 'tpa_points.geojson')) as f:\n",
    "    tpa_points = json.load(f)\n",
    "\n",
    "tpa_sites = pd.DataFrame({\n",
    "    'name': [site['properties']['Name'] for site in tpa_points['features']],\n",
    "    'lon': [site['geometry']['coordinates'][0] for site in tpa_points['features']],\n",
    "    'lat': [site['geometry']['coordinates'][1] for site in tpa_points['features']],\n",
    "    'area': [site['properties']['Surface_Ha'] for site in tpa_points['features']],\n",
    "    'daily_volume': [site['properties']['TOT_Kg/Day'] for site in tpa_points['features']],\n",
    "    'coords': [site['geometry']['coordinates'] for site in tpa_points['features']]\n",
    "})\n",
    "\n",
    "\n",
    "# Add earth engine TPA Polygons to TPA dataframe\n",
    "with open(os.path.join(DATA_DIR, 'tpa_polygons.geojson'), 'r') as f:\n",
    "    json_tpa = json.load(f)\n",
    "f.close()\n",
    "tpa_polygons = [ee.FeatureCollection([element]) for element in list(json_tpa['features'])]\n",
    "\n",
    "tpa_sites['polygons'] = tpa_polygons\n",
    "display(tpa_sites.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Sampling Sites from GeoJSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>coords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>city_0</td>\n",
       "      <td>114.619837</td>\n",
       "      <td>-8.361932</td>\n",
       "      <td>[114.6198374623975, -8.361931821454325]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>city_1</td>\n",
       "      <td>115.218992</td>\n",
       "      <td>-8.682543</td>\n",
       "      <td>[115.2189915773064, -8.682542635447703]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>city_2</td>\n",
       "      <td>115.152099</td>\n",
       "      <td>-8.803352</td>\n",
       "      <td>[115.1520991337562, -8.803351890677076]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>city_3</td>\n",
       "      <td>115.448223</td>\n",
       "      <td>-8.676354</td>\n",
       "      <td>[115.4482234100242, -8.676354239123828]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>city_4</td>\n",
       "      <td>115.552125</td>\n",
       "      <td>-8.674258</td>\n",
       "      <td>[115.5521252514949, -8.674258048038155]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     name         lon       lat                                   coords\n",
       "0  city_0  114.619837 -8.361932  [114.6198374623975, -8.361931821454325]\n",
       "1  city_1  115.218992 -8.682543  [115.2189915773064, -8.682542635447703]\n",
       "2  city_2  115.152099 -8.803352  [115.1520991337562, -8.803351890677076]\n",
       "3  city_3  115.448223 -8.676354  [115.4482234100242, -8.676354239123828]\n",
       "4  city_4  115.552125 -8.674258  [115.5521252514949, -8.674258048038155]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampling_df = load_geojson('city_points_30.geojson')\n",
    "sampling_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Sites Adjacent to another List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>coords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TPA Jungut Batu_north_0.01</td>\n",
       "      <td>115.459414</td>\n",
       "      <td>-8.660958</td>\n",
       "      <td>[115.46941439485306, -8.670958330781342]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TPA Biaung_north_0.01</td>\n",
       "      <td>115.498017</td>\n",
       "      <td>-8.669930</td>\n",
       "      <td>[115.50801683267277, -8.679930042100876]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TPA Sente_north_0.01</td>\n",
       "      <td>115.454460</td>\n",
       "      <td>-8.520372</td>\n",
       "      <td>[115.46446033358268, -8.530371792768301]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TPA Regional Bangli_north_0.01</td>\n",
       "      <td>115.367927</td>\n",
       "      <td>-8.343542</td>\n",
       "      <td>[115.37792701853951, -8.353541681392851]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TPA Peh_north_0.01</td>\n",
       "      <td>114.583295</td>\n",
       "      <td>-8.317938</td>\n",
       "      <td>[114.59329467897307, -8.327937523143966]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             name         lon       lat  \\\n",
       "0      TPA Jungut Batu_north_0.01  115.459414 -8.660958   \n",
       "1           TPA Biaung_north_0.01  115.498017 -8.669930   \n",
       "2            TPA Sente_north_0.01  115.454460 -8.520372   \n",
       "3  TPA Regional Bangli_north_0.01  115.367927 -8.343542   \n",
       "4              TPA Peh_north_0.01  114.583295 -8.317938   \n",
       "\n",
       "                                     coords  \n",
       "0  [115.46941439485306, -8.670958330781342]  \n",
       "1  [115.50801683267277, -8.679930042100876]  \n",
       "2  [115.46446033358268, -8.530371792768301]  \n",
       "3  [115.37792701853951, -8.353541681392851]  \n",
       "4  [114.59329467897307, -8.327937523143966]  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adjacent_df = sample_adjacent(tpa_sites, 0.01, 'north')\n",
    "adjacent_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Sampling Sites from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>coords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>city_0</td>\n",
       "      <td>114.619837</td>\n",
       "      <td>-8.361932</td>\n",
       "      <td>[114.6198374623975, -8.361931821454325]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>city_1</td>\n",
       "      <td>115.218992</td>\n",
       "      <td>-8.682543</td>\n",
       "      <td>[115.2189915773064, -8.682542635447703]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>city_2</td>\n",
       "      <td>115.152099</td>\n",
       "      <td>-8.803352</td>\n",
       "      <td>[115.1520991337562, -8.803351890677076]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>city_3</td>\n",
       "      <td>115.448223</td>\n",
       "      <td>-8.676354</td>\n",
       "      <td>[115.4482234100242, -8.676354239123828]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>city_4</td>\n",
       "      <td>115.552125</td>\n",
       "      <td>-8.674258</td>\n",
       "      <td>[115.5521252514949, -8.674258048038155]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     name         lon       lat                                   coords\n",
       "0  city_0  114.619837 -8.361932  [114.6198374623975, -8.361931821454325]\n",
       "1  city_1  115.218992 -8.682543  [115.2189915773064, -8.682542635447703]\n",
       "2  city_2  115.152099 -8.803352  [115.1520991337562, -8.803351890677076]\n",
       "3  city_3  115.448223 -8.676354  [115.4482234100242, -8.676354239123828]\n",
       "4  city_4  115.552125 -8.674258  [115.5521252514949, -8.674258048038155]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampling_df = load_csv('negative_sites.csv')\n",
    "sampling_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write Sampling Sites to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_df.to_csv(os.path.join(DATA_DIR, 'negative_sites_test.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "RECT_WIDTH = 0.002"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Patch History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading city_0\n",
      "Downloading city_1\n",
      "Downloading city_2\n",
      "Downloading city_3\n",
      "Downloading city_4\n",
      "Downloading city_5\n",
      "Downloading city_6\n",
      "Downloading city_7\n",
      "Downloading city_8\n",
      "Downloading city_9\n",
      "Downloading city_10\n",
      "Downloading city_11\n",
      "Downloading city_12\n",
      "Downloading city_13\n",
      "Downloading city_14\n",
      "Downloading city_15\n",
      "Downloading city_16\n",
      "Downloading city_17\n",
      "Downloading city_18\n",
      "Downloading city_19\n",
      "Downloading city_20\n",
      "Downloading city_21\n",
      "Downloading city_22\n",
      "Downloading city_23\n",
      "Downloading city_24\n",
      "Downloading city_25\n",
      "Downloading city_26\n",
      "Downloading city_27\n",
      "Downloading city_28\n",
      "Downloading city_29\n",
      "Downloading city_30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [01:49<00:00, 109.43s/it]\n"
     ]
    }
   ],
   "source": [
    "# Create a list of patch histories\n",
    "# Each patch history is a dictionary with the format:\n",
    "# patch_history[date][site_name][band][band_img]\n",
    "# This function takes a while to run as it is extracting data from GEE\n",
    "\n",
    "site_list = sampling_df\n",
    "num_months = 1\n",
    "start_date = '2019-01-01'\n",
    "\n",
    "patch_history = get_history(site_list['coords'], \n",
    "                              site_list['name'], \n",
    "                              RECT_WIDTH,\n",
    "                              num_months = num_months,\n",
    "                              start_date = start_date,\n",
    "                              cloud_mask = True)\n",
    "\n",
    "save_patch_history(patch_history, 'city_points_30', 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download TPA Polygon History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing TPA Jungut Batu\n",
      "Processing TPA Biaung\n",
      "Processing TPA Sente\n",
      "Processing TPA Regional Bangli\n",
      "Processing TPA Peh\n",
      "Processing TPA Temesi\n",
      "Processing TPA Bengkala\n",
      "Processing TPA Bebandem\n",
      "Processing TPA Mandung\n",
      "Processing TPA Regional Suwung\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 1/2 [01:19<01:19, 79.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing TPA Jungut Batu\n",
      "Processing TPA Biaung\n",
      "Processing TPA Sente\n",
      "Processing TPA Regional Bangli\n",
      "Processing TPA Peh\n",
      "Processing TPA Temesi\n",
      "Processing TPA Bengkala\n",
      "Processing TPA Bebandem\n",
      "Processing TPA Mandung\n",
      "Processing TPA Regional Suwung\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [02:06<00:00, 63.24s/it]\n"
     ]
    }
   ],
   "source": [
    "# Get patch histories for TPA sites\n",
    "num_months = 2\n",
    "start_date = '2020-01-01'\n",
    "tpa_patch_history = get_history_polygon(tpa_sites['coords'], \n",
    "                                        tpa_sites['name'], \n",
    "                                        tpa_sites['polygons'], \n",
    "                                        4 * RECT_WIDTH,\n",
    "                                        start_date = start_date,\n",
    "                                        num_months = num_months,\n",
    "                                       )\n",
    "save_patch_history(tpa_patch_history, 'tpa_sites', 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Pixel Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10764 pixel vectors\n"
     ]
    }
   ],
   "source": [
    "pixel_vectors = create_pixel_vectors(patch_histories, len(patch_histories))\n",
    "save_pixel_vectors(pixel_vectors, 'city_points_30', 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pixel Vectors with a Holdout Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2547 pixel vectors\n",
      "4269 pixel vectors\n"
     ]
    }
   ],
   "source": [
    "# holdout_months refers to a strategy of holding out the last n months of data for validation\n",
    "# Set this value to the number of months you want to separate from the training data\n",
    "\n",
    "holdout_months = 3\n",
    "\n",
    "pixel_vectors = create_pixel_vectors(tpa_patch_history, len(tpa_patch_history) - holdout_months)\n",
    "save_pixel_vectors(pixel_vectors, 'tpa_train', 1)\n",
    "\n",
    "holdout_pixel_vectors = create_pixel_vectors(tpa_patch_history, -holdout_months, holdout=True)\n",
    "save_pixel_vectors(holdout_pixel_vectors, 'tpa_holdout', 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Spatial Patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_img_stack(patch_history):\n",
    "    img_stack = []\n",
    "    for date in patch_history:\n",
    "        for site in patch_history[date]:\n",
    "            spectral_stack = []\n",
    "            band_shapes = [np.shape(patch_history[date][site][band]) for band in band_descriptions]\n",
    "            if np.array(band_shapes).all() > 0:\n",
    "                for band in band_descriptions:\n",
    "                    spectral_stack.append(patch_history[date][site][band])\n",
    "                if np.min(spectral_stack) > 0:\n",
    "                    img_stack.append(np.rollaxis(np.array(spectral_stack), 0, 3))\n",
    "    return img_stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_patches = create_img_stack(tpa_patch_histories)\n",
    "print(len(positive_patches), 'positive images extracted')\n",
    "\n",
    "negative_patches = create_img_stack(negative_patch_histories)\n",
    "print(len(negative_patches), 'negative images extracted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save positive patch history\n",
    "with open(os.path.join(OUTPUT_DIR, f\"positive_patches_toa_{num_positive_months}_{positive_start_date}.pkl\"),\"wb\") as f:\n",
    "    pickle.dump(positive_patches, f)\n",
    "    \n",
    "# Save negative patch history\n",
    "with open(os.path.join(OUTPUT_DIR, f\"negative_patches_toa_{num_positive_months}_{positive_start_date}.pkl\"),\"wb\") as f:\n",
    "    pickle.dump(negative_patches, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Site Monitoring and Contour Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import json\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "import geojson\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import rasterio as rs\n",
    "from rasterio import warp\n",
    "from tensorflow import keras\n",
    "from tqdm import tqdm\n",
    "\n",
    "from scripts.get_s2_data_ee import get_history, get_history_polygon, get_pixel_vectors, band_descriptions\n",
    "from scripts.viz_tools import stretch_histogram, create_img_stack, normalize\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentinel 2 band descriptions\n",
    "band_descriptions = {\n",
    "    'B1': 'Aerosols, 442nm',\n",
    "    'B2': 'Blue, 492nm',\n",
    "    'B3': 'Green, 559nm',\n",
    "    'B4': 'Red, 665nm',\n",
    "    'B5': 'Red Edge 1, 704nm',\n",
    "    'B6': 'Red Edge 2, 739nm',\n",
    "    'B7': 'Red Edge 3, 779nm',\n",
    "    'B8': 'NIR, 833nm',\n",
    "    'B8A': 'Red Edge 4, 864nm',\n",
    "    'B9': 'Water Vapor, 943nm',\n",
    "    'B11': 'SWIR 1, 1610nm',\n",
    "    'B12': 'SWIR 2, 2186nm'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_time_series(patch_histories, site_name, model):\n",
    "    rgb_stack = []\n",
    "    preds_stack = []\n",
    "    dates_list = []\n",
    "    \n",
    "    dates = list(patch_histories.keys())\n",
    "    for date in dates:\n",
    "        rgb = np.stack((patch_histories[date][site_name]['B4'],\n",
    "                        patch_histories[date][site_name]['B3'],\n",
    "                        patch_histories[date][site_name]['B2']), axis=-1)\n",
    "        \n",
    "        width, height = rgb.shape[:2]\n",
    "        pixel_vectors = []\n",
    "        for i in range(width):\n",
    "            for j in range(height):\n",
    "                pixel_vector = []\n",
    "                band_lengths = [len(patch_histories[date][site_name][band]) for band in band_descriptions]\n",
    "                if np.array(band_lengths).all() > 0:\n",
    "                    for band in band_descriptions:\n",
    "                        pixel_vector.append(patch_histories[date][site_name][band][i][j])\n",
    "                    pixel_vectors.append(pixel_vector)\n",
    "        \n",
    "        pixel_vectors = normalize(pixel_vectors)\n",
    "        cloudiness = np.sum(rgb <= 0) / np.size(rgb)\n",
    "        if len(pixel_vectors) > 0 and cloudiness < .05:\n",
    "            rgb_stack.append(normalize(rgb))\n",
    "            preds = model.predict(np.expand_dims(pixel_vectors, axis=-1))\n",
    "            preds_img = np.reshape(preds, (width, height, 2))[:,:,1]\n",
    "            preds_stack.append(preds_img)\n",
    "            dates_list.append(date)\n",
    "            \n",
    "    return np.array(rgb_stack), np.array(preds_stack), dates_list\n",
    "\n",
    "def filter_small_points(image):\n",
    "    # This is experimental. Filter out \"hot pixel\" predictions\n",
    "    se1 = cv2.getStructuringElement(cv2.MORPH_RECT, (7,7))\n",
    "    se2 = cv2.getStructuringElement(cv2.MORPH_RECT, (2,2))\n",
    "    mask = cv2.morphologyEx(image, cv2.MORPH_CLOSE, se1)\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, se2)\n",
    "    out = image * mask\n",
    "    return out\n",
    "\n",
    "def green_blue_swap(image):\n",
    "    # to play nicely with OpenCV's BGR color order\n",
    "    r,g,b = cv2.split(image)\n",
    "    image[:,:,0] = b\n",
    "    image[:,:,1] = g\n",
    "    image[:,:,2] = r\n",
    "    return image\n",
    "\n",
    "\n",
    "def generate_contours(preds_stack, rgb_stack, dates_list, site_coords, threshold=0.5, window_size=3, plot=False):\n",
    "    \"\"\"Create contour outlines from \"\"\"\n",
    "    # Image upsampling factor. Makes for smoother contours\n",
    "    scale = 8\n",
    "\n",
    "    areas = []\n",
    "    monthly_contours = []\n",
    "    dates = []\n",
    "    rgb_contour_imgs = []\n",
    "    img_size = preds_stack[0].shape\n",
    "    \n",
    "    x, y = warp.transform(rs.crs.CRS.from_epsg(4326), rs.crs.CRS.from_epsg(3857), [site_coords[0] - rect_width / 2, \n",
    "                                                                               site_coords[0] + rect_width / 2],                                                                      [site_coords[1] - rect_width / 2, \n",
    "                                                                               site_coords[1] + rect_width / 2])\n",
    "    width = abs(x[0] - x[1])\n",
    "    height = abs(y[0] - y[1])\n",
    "    img_area_degrees = width * height\n",
    "    num_pixels = img_size[0] * img_size[1]\n",
    "    pixel_area = img_area_degrees / num_pixels\n",
    "    if window_size <= len(preds_stack):\n",
    "        window_size = len(preds_stack) - 2\n",
    "    \n",
    "    for i in range(len(preds_stack) - window_size):\n",
    "        # Create a median prediction image across predictions within window\n",
    "        median_pred = (np.median(preds_stack[i:i+window_size], axis=0) * 255).astype(np.uint8)\n",
    "        # set pixels below threshold to 0\n",
    "        median_pred[median_pred < threshold * 255] = 0\n",
    "        \n",
    "        # Upsample predictions image\n",
    "        median_pred = np.array(Image.fromarray(median_pred).resize((img_size[0] * scale, img_size[1] * scale)))\n",
    "        \n",
    "        # Create a median RGB image\n",
    "        median_rgb = (np.median(rgb_stack[i:i+window_size], axis=0) * 255).astype(np.uint8)\n",
    "        median_rgb = np.array(Image.fromarray(median_rgb).resize((img_size[0] * scale, img_size[1] * scale)))\n",
    "        \n",
    "        # Construct a binary image with pixels above and below threshold\n",
    "        ret, thresh = cv2.threshold(median_pred, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "        \n",
    "        # To set threshold manually...\n",
    "        # thresh_value = threshold * 255 \n",
    "        # ret, thresh = cv2.threshold(median_pred, thresh_value, 255, 0)\n",
    "        contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        # Filter contours with an area below a given threshold\n",
    "        # I wish I didn't need to do this! It rules out detecting anything smaller than the threshold\n",
    "        min_pixel_width = 5\n",
    "        area_threshold = (min_pixel_width * scale) ** 2\n",
    "        filtered_contours = [contour for contour in contours if cv2.contourArea(contour) > area_threshold]\n",
    "        monthly_contours.append(filtered_contours)\n",
    "        \n",
    "        area = np.sum([cv2.contourArea(contour) for contour in filtered_contours])\n",
    "        # Convert area to km^2\n",
    "        area = area * (pixel_area / (1000000 * (scale ** 2)))\n",
    "        areas.append(area)\n",
    "        \n",
    "        # Create images\n",
    "        three_channel_preds = np.stack((median_pred, median_pred, median_pred), axis=-1)\n",
    "        preds_contour_img = cv2.drawContours(three_channel_preds, filtered_contours, -1, (255, 0, 0), 2)\n",
    "        rgb_contour_img = cv2.drawContours(median_rgb, filtered_contours, -1, (255, 0, 0), 2)\n",
    "        rgb_contour_imgs.append(rgb_contour_img)\n",
    "\n",
    "        date = dates_list[i + window_size]\n",
    "        dates.append(date)\n",
    "\n",
    "        if plot:\n",
    "            plt.figure(figsize=(10,5), dpi=150)\n",
    "            plt.subplot(1,2,1)\n",
    "            plt.title(date + ' rgb')\n",
    "            plt.imshow(rgb_contour_img, vmax=255, vmin=0)\n",
    "            plt.axis('off')\n",
    "            plt.subplot(1,2,2)\n",
    "            plt.imshow(preds_contour_img, vmax=255, vmin=0)\n",
    "            plt.title(date + ' pred')\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "    \n",
    "    return monthly_contours, areas, dates, rgb_contour_imgs, scale\n",
    "\n",
    "def contours_to_geojson(monthly_contours, name, areas, date_list, site_coords, img_size, scale):\n",
    "    \n",
    "    # Define patch coordinate bounds to set pixel scale\n",
    "    west  = site_coords[0] - rect_width / 2\n",
    "    east  = site_coords[0] + rect_width / 2\n",
    "    north = site_coords[1] + rect_width / 2\n",
    "    south = site_coords[1] - rect_width / 2\n",
    "    transform = rs.transform.from_bounds(west, south, east, north, img_size[0] * scale, img_size[1] * scale)\n",
    "\n",
    "    polygons = []\n",
    "    for contours, area, date in zip(monthly_contours, areas, date_list):\n",
    "        polygon_coords = []\n",
    "        for contour in contours:\n",
    "            # Convert from pixels to coords\n",
    "            contour_coords = []\n",
    "            for point in contour[:,0]:\n",
    "                lon, lat = rs.transform.xy(transform, point[1], point[0])\n",
    "                contour_coords.append([lon, lat])\n",
    "            # Close the loop\n",
    "            contour_coords.append(contour_coords[0])\n",
    "\n",
    "            # Add individual contour to list of contours for the month\n",
    "            polygon_coords.append(contour_coords)\n",
    "\n",
    "        date = datetime.datetime.strptime(date, \"%Y-%m-%d\").strftime(\"%Y/%m/%d %H:%M\")\n",
    "        polygon = geojson.MultiPolygon(coordinates = [polygon_coords])\n",
    "        contour_feature = geojson.Feature(geometry=polygon, properties={'date': date,\n",
    "                                                                        'name': name,\n",
    "                                                                        'area': area\n",
    "                                                                       })\n",
    "        polygons.append(contour_feature)\n",
    "        \n",
    "    return polygons\n",
    "\n",
    "def plot_site_area(areas, name, site_coords, img_size, dates, scale, path):\n",
    "    plt.figure(figsize=(8,4), facecolor=(1,1,1), dpi=150)\n",
    "    months = [datetime.datetime.strptime(date, '%Y-%m-%d') for date in dates]\n",
    "    plt.plot(months, areas)\n",
    "    \n",
    "    plt.xticks(ha='right', rotation=45)\n",
    "    plt.title(name + ' Landfill Area over Time')\n",
    "    plt.ylabel('Area (km^2)')\n",
    "    plt.xlabel('Date')\n",
    "    plt.savefig(path, bbox_inches='tight')\n",
    "    plt.close('all')\n",
    "\n",
    "def monitor_sites(patch_history, model, names, coords, region_name, threshold=0.5, window_size=3):\n",
    "    region_dir = os.path.join('../data/model_outputs/site_contours/monthly_contours', f'{region_name}_thresh_{threshold}_window_{window_size}')\n",
    "    if not os.path.exists(region_dir):\n",
    "        os.mkdir(region_dir)\n",
    "            \n",
    "    contour_collection = []\n",
    "    \n",
    "    for name, site_coords in tqdm(zip(names, coords)):\n",
    "\n",
    "        data_dir = os.path.join(region_dir, name)\n",
    "        if not os.path.exists(data_dir):\n",
    "            os.mkdir(data_dir)\n",
    "        \n",
    "        rgb_stack, preds_stack, dates_list = predict_time_series(patch_history, name, model)\n",
    "        img_size = preds_stack[0].shape\n",
    "        \n",
    "        # Compute contours\n",
    "        monthly_contours, areas, dates, rgb_contour_imgs, scale = generate_contours(preds_stack, rgb_stack, dates_list, site_coords, threshold=threshold, window_size=window_size, plot=False)\n",
    "        \n",
    "        # Write contour overlay images\n",
    "        for img, date in zip(rgb_contour_imgs, dates):\n",
    "            cv2.imwrite(os.path.join(data_dir, f'{name}_contours_window_size_{window_size}_thresh_{threshold}_{date.replace(\"/\", \"-\")[:10]}.png'), cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "        \n",
    "        # Plot site area\n",
    "        plot_site_area(areas, name, site_coords, img_size, dates, scale, os.path.join(data_dir, f'{name}_site_area_window_size_{window_size}_thresh_{threshold}.png'))\n",
    "        \n",
    "        # Convert contours to GeoJSON\n",
    "        median_contour = contours_to_geojson(monthly_contours, name, areas, dates, site_coords, img_size, scale)\n",
    "        contour_collection.append(median_contour)\n",
    "        json_contours = json.dumps(geojson.FeatureCollection(median_contour))\n",
    "        \n",
    "        # Write site-specific contour\n",
    "        with open(os.path.join(data_dir, f'{name}_contours_window_size_{window_size}_thresh_{threshold}.geojson'), 'w') as f:\n",
    "            f.write(json_contours)\n",
    "    \n",
    "    # Write master GeoJSON for all contours in patch_history\n",
    "    json_contour_collection = json.dumps(geojson.FeatureCollection(contour_collection))\n",
    "    with open(os.path.join('../data/model_outputs/site_contours', f'{region_name}_contours_window_size_{window_size}_thresh_{threshold}.geojson'), 'w') as f:\n",
    "        f.write(json_contour_collection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter rect width in degrees (0.035 max recommended) and site coordinates\n",
    "rect_width = 0.075"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Single Site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_months = 12\n",
    "start_date = '2019-05-01'\n",
    "site_coords = [115.2211451864497, -8.723290447230358]\n",
    "name = 'TPA Suwung'\n",
    "patch_history = get_history([site_coords], \n",
    "                            [name],\n",
    "                            rect_width,\n",
    "                            num_months = num_months,\n",
    "                            start_date = start_date,\n",
    "                            cloud_mask = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download all Bali TPA Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open('../data/sampling_locations/tpa_points.geojson', 'r') as f:\n",
    "    tpa_sites = json.load(f)\n",
    "coords = [site['geometry']['coordinates'] for site in tpa_sites['features']]\n",
    "names = [site['properties']['Name'] for site in tpa_sites['features']]\n",
    "\n",
    "num_months = 60\n",
    "start_date = '2016-01-01'\n",
    "patch_history = get_history(coords, \n",
    "                          names, \n",
    "                          rect_width,\n",
    "                          num_months=num_months,\n",
    "                          start_date=start_date,\n",
    "                          cloud_mask=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download all Java TPA Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "java = pd.read_csv('../data/sampling_locations/v12_java_validated_positives.csv')\n",
    "java_names = list(java['name'])\n",
    "java_coords = [[lon, lat] for lon, lat in zip(java['lon'], java['lat'])]\n",
    "num_months = 24\n",
    "start_date = '2019-01-01'\n",
    "patch_history = get_history(java_coords, \n",
    "                          java_names, \n",
    "                          rect_width,\n",
    "                          num_months=num_months,\n",
    "                          start_date=start_date,\n",
    "                          cloud_mask=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data that has already been downloaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import json\n",
    "with open('../data/sampling_locations/tpa_points.geojson', 'r') as f:\n",
    "    tpa_sites = json.load(f)\n",
    "coords = [site['geometry']['coordinates'] for site in tpa_sites['features']]\n",
    "names = [site['properties']['Name'] for site in tpa_sites['features']]\n",
    "\n",
    "num_months = 60\n",
    "start_date = '2016-01-01'\n",
    "with open('../data/training_data/patch_histories/bali_tpa_raw_60_months_2016-01-01_84px_patch_history.pkl', 'rb') as f:\n",
    "    patch_history = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "java = pd.read_csv('../data/sampling_locations/v12_java_validated_positives.csv')\n",
    "names = list(java['name'])\n",
    "coords = [[lon, lat] for lon, lat in zip(java['lon'], java['lat'])]\n",
    "num_months = 24\n",
    "start_date = '2019-01-01'\n",
    "\n",
    "with open('../data/training_data/patch_histories/java_v12_detections_raw_24_months_2019-01-01_84px_patch_history.pkl', 'rb') as f:\n",
    "    patch_history = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select model to load for predictions\n",
    "model = keras.models.load_model('../models/65_mo_tpa_bootstrap_toa-12-20-2020.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "monitor_sites(patch_history, model, names, coords, 'java_v12', threshold=0.6, window_size=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WIP section to fix contour export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('../data/model_outputs/site_contours/java_v12_contours_window_size_3_thresh_0.6.geojson', 'r') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['features'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geojson\n",
    "feature_list = []\n",
    "for feature in data['features']:\n",
    "    for month in feature:\n",
    "        feature_list.append(month)\n",
    "fc = geojson.FeatureCollection(feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/model_outputs/site_contours/java_v12_contours_window_size_3_thresh_0.6_fix.geojson', 'w') as f:\n",
    "    f.write(json.dumps(fc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

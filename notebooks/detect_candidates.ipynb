{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Blob or Peak Detection on Pixel Heatmap to Identify Candidate Sites\n",
    "Note: This is only working on inputs with EPSG CRS 4326. I may need to make it more general in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import geojson\n",
    "from keplergl import KeplerGl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio as rs\n",
    "from rasterio.windows import Window\n",
    "from rasterio import warp\n",
    "from skimage.feature import blob_doh\n",
    "from skimage.feature.peak import peak_local_max\n",
    "from sklearn.neighbors import KDTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pixels_to_coords(x, y, src_img):\n",
    "    lon, lat = warp.transform(src_img.crs, rs.crs.CRS.from_epsg(4326), [src_img.xy(x, y)[0]], [src_img.xy(x, y)[1]])\n",
    "    return lon[0], lat[0]\n",
    "\n",
    "def coords_to_pixels(lon, lat, src_img):\n",
    "    x, y = warp.transform(rs.crs.CRS.from_epsg(4326), src_img.crs, [lon],  [lat])\n",
    "    pixel_y, pixel_x = src_img.index(x, y)\n",
    "    return pixel_x[0], pixel_y[0]\n",
    "\n",
    "def merge_similar_sites(candidate_sites, search_radius=0.01):\n",
    "    \"\"\"\n",
    "    This process iteratively moves points closer together by taking the mean position of all\n",
    "    matched points. It then searches the KD tree using the unique clusters in these new points.\n",
    "    The algorithm stops once the number of unique sites is the same as in the previous round.\n",
    "    \n",
    "    search_radius is given in degrees\n",
    "    \"\"\"\n",
    "    #coords = np.array([[lon, lat] for lon, lat in zip(candidate_site_df['lon'], candidate_site_df['lat'])])\n",
    "    coords = np.array(candidate_sites)\n",
    "    \n",
    "    # Create a KD tree for efficient lookup of points within a radius\n",
    "    tree = KDTree(coords, leaf_size=2)\n",
    "    \n",
    "    # Initialize a mean_coords array for the search\n",
    "    mean_coords = []\n",
    "    for elem in tree.query_radius(coords, search_radius):\n",
    "        mean_coords.append(np.mean(coords[elem], axis=0))\n",
    "    mean_coords = np.array(mean_coords)\n",
    "    \n",
    "    num_coords = len(mean_coords)\n",
    "    while True:\n",
    "        search = tree.query_radius(mean_coords, search_radius)\n",
    "        uniques = [list(x) for x in set(tuple(elem) for elem in search)]\n",
    "        mean_coords = []\n",
    "        for elem in uniques:\n",
    "            mean_coords.append(np.mean(coords[elem], axis=0))\n",
    "        if len(mean_coords) == num_coords:\n",
    "            print(len(mean_coords), \"unique sites detected\")\n",
    "            mean_coords = np.array(mean_coords)\n",
    "            break\n",
    "        num_coords = len(mean_coords)\n",
    "        \n",
    "    unique_sites = pd.DataFrame(mean_coords, columns=['lon', 'lat'])\n",
    "    unique_sites['name'] = [f\"{name}_{i+1}\" for i in range(len(unique_sites))]\n",
    "    plt.figure(figsize=(10,10), dpi=150, facecolor=(1,1,1))\n",
    "    plt.scatter(coords[:,0], coords[:,1], s=5, label='Original')\n",
    "    plt.scatter(mean_coords[:,0], mean_coords[:,1], s=3, c='r', label='Unique')\n",
    "    plt.axis('equal')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    return unique_sites\n",
    "\n",
    "def detect_peaks(source, name, threshold_rel=0.75, min_distance=10, window_size=5000, save=True):\n",
    "    candidate_peaks = []\n",
    "    for x in range(0, source.shape[0], window_size):\n",
    "        for y in range(0, source.shape[1], window_size):\n",
    "            window = Window.from_slices((x,x + window_size), (y, y + window_size))\n",
    "            transform = source.window_transform(window)\n",
    "            subset = source.read(1, window=window)\n",
    "            peaks = peak_local_max(subset, threshold_rel=threshold_rel, min_distance=min_distance)\n",
    "            for candidate in peaks:\n",
    "                lon, lat = (transform * [candidate[1], candidate[0]])\n",
    "                candidate_peaks.append([lon, lat])\n",
    "    print(len(candidate_peaks), \"peaks detected\")\n",
    "    \n",
    "    if save:\n",
    "        file_path = f\"../data/model_outputs/candidate_sites/{name}_peaks_thresh_{threshold_rel}_min_dist_{min_distance}\"\n",
    "        geojson_features = []\n",
    "        for i, (lon, lat) in enumerate(candidate_peaks):\n",
    "            geojson_features.append(geojson.Feature(geometry = geojson.Point([lon, lat]),\n",
    "                                                    properties={'name': f\"{name}_{i+1}\"}))\n",
    "        feature_collection = geojson.FeatureCollection(geojson_features)\n",
    "        with open(file_path + '.geojson', 'w') as f:\n",
    "            f.write(geojson.dumps(feature_collection))\n",
    "    \n",
    "    candidate_peak_df = pd.DataFrame(candidate_peaks, columns=['lon', 'lat'])\n",
    "    candidate_peak_df['name'] = [f\"{name}_{i}\" for i in range(len(candidate_peaks))]\n",
    "    return candidate_peak_df\n",
    "\n",
    "def detect_blobs(source, name, pred_threshold=0.75, min_sigma=3.5, max_sigma=100, area_threshold=0.0025, window_size=5000, save=True):\n",
    "    \"\"\"\n",
    "    Identify candidates using blob detection on the heatmap.\n",
    "    prediction_threshold masks any prediction below a 0-1 threshold.\n",
    "    min_sigma and area_threshold control the size sensitivity of the blob detection.\n",
    "    Keep min_sigma low to detect smaller blobs\n",
    "    area_threshold establishes a lower bound on candidate blob size. Reduce to detect smaller blobs\n",
    "    \"\"\"\n",
    "    candidate_sites = []\n",
    "    max_val = source.read(1).max()\n",
    "    for x in range(0, source.shape[0], window_size):\n",
    "        for y in range(0, source.shape[1], window_size):\n",
    "            print(f\"Processing row {(x // window_size) + 1} of {int(source.shape[0] / window_size) + 1}, column {(y // window_size) + 1} of {int(source.shape[1] / window_size) + 1}\")\n",
    "            # Set min and max to analyze a subset of the image\n",
    "            window = Window.from_slices((x,x + window_size), (y, y + window_size))\n",
    "            window_median = (source.read(1, window=window) / max_val).astype('float')\n",
    "            # mask predictions below a threshold\n",
    "            mask = np.ma.masked_where(window_median < pred_threshold, window_median).mask\n",
    "            window_median[mask] = 0\n",
    "\n",
    "            blobs = blob_doh(window_median, min_sigma=min_sigma, max_sigma=max_sigma, threshold=area_threshold)\n",
    "            print(len(blobs), \"candidates detected in window\")\n",
    "            \n",
    "            overlap_threshold = 0.01\n",
    "            transform = source.window_transform(window)\n",
    "            for candidate in blobs:\n",
    "                lon, lat = (transform * [candidate[1], candidate[0]])\n",
    "                # Size doesn't mean anything at the moment. Should look into this later\n",
    "                #size = candidate[2]\n",
    "                candidate_sites.append([lon, lat])\n",
    "            \n",
    "    print(len(candidate_sites), \"candidate sites detected in total\")\n",
    "    \n",
    "    candidate_site_df = merge_similar_sites(candidate_sites, search_radius=0.01)\n",
    "    \n",
    "    if save:\n",
    "        # Write candidates to CSV and GeoJSON\n",
    "        file_path = f\"../data/model_outputs/candidate_sites/{name}_candidates_pred-thresh_{pred_threshold}_min-sigma_{min_sigma}_area-thresh_{area_threshold}\"\n",
    "        candidate_site_df.to_csv(file_path + '.csv', index = False)\n",
    "        print(\"Candidate sites written to\", file_path)\n",
    "\n",
    "        geojson_features = []\n",
    "        for i, (lon, lat) in enumerate(zip(candidate_site_df['lon'], candidate_site_df['lat'])):\n",
    "            geojson_features.append(geojson.Feature(geometry = geojson.Point([lon, lat]),\n",
    "                                                    properties={'name': f\"{name}_{i+1}\"}))\n",
    "        feature_collection = geojson.FeatureCollection(geojson_features)\n",
    "        with open(file_path + '.geojson', 'w') as f:\n",
    "            f.write(geojson.dumps(feature_collection))\n",
    "    \n",
    "    return candidate_site_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kepler_config = {\n",
    "  \"version\": \"v1\",\n",
    "  \"config\": {\n",
    "    \"visState\": {\n",
    "      \"layers\": [\n",
    "        {\n",
    "          \"id\": \"iik903a\",\n",
    "          \"type\": \"point\",\n",
    "          \"config\": {\n",
    "            \"dataId\": \"Candidate Peaks\",\n",
    "            \"label\": \"Point\",\n",
    "            \"color\": [\n",
    "              218,\n",
    "              0,\n",
    "              0\n",
    "            ],\n",
    "            \"columns\": {\n",
    "              \"lat\": \"lat\",\n",
    "              \"lng\": \"lon\",\n",
    "              \"altitude\": None\n",
    "            },\n",
    "            \"isVisible\": True,\n",
    "            \"visConfig\": {\n",
    "              \"radius\": 20,\n",
    "              \"fixedRadius\": False,\n",
    "              \"opacity\": 0.99,\n",
    "              \"outline\": True,\n",
    "              \"thickness\": 3,\n",
    "              \"strokeColor\": [\n",
    "                210,\n",
    "                0,\n",
    "                0\n",
    "              ],\n",
    "              \"filled\": False\n",
    "            },\n",
    "          },\n",
    "        },\n",
    "        {\n",
    "          \"id\": \"kyoc7uj\",\n",
    "          \"type\": \"point\",\n",
    "          \"config\": {\n",
    "            \"dataId\": \"Candidate Blobs\",\n",
    "            \"label\": \"Point\",\n",
    "            \"color\": [\n",
    "              246,\n",
    "              218,\n",
    "              0\n",
    "            ],\n",
    "            \"columns\": {\n",
    "              \"lat\": \"lat\",\n",
    "              \"lng\": \"lon\",\n",
    "              \"altitude\": None\n",
    "            },\n",
    "            \"isVisible\": True,\n",
    "            \"visConfig\": {\n",
    "              \"radius\": 20,\n",
    "              \"fixedRadius\": False,\n",
    "              \"opacity\": 0.99,\n",
    "              \"outline\": True,\n",
    "              \"thickness\": 3,\n",
    "              \"strokeColor\": [\n",
    "                246,\n",
    "                218,\n",
    "                0\n",
    "              ],\n",
    "              \"filled\": False\n",
    "            },\n",
    "          },\n",
    "        }\n",
    "      ],\n",
    "    },\n",
    "    \"mapStyle\": {\n",
    "      \"styleType\": \"satellite\",\n",
    "    }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_map = KeplerGl(height=800, config=kepler_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'Bali_v1.1.8_2019-2020'\n",
    "source = rs.open(f'../data/model_outputs/heatmaps/{name}.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "peaks = detect_peaks(source, name=name, min_distance=100, threshold_rel=0.9, save=True)\n",
    "candidate_map.add_data(data=peaks, name='Candidate Peaks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "blobs = detect_blobs(source, name=name, pred_threshold=0.8, save=True)\n",
    "candidate_map.add_data(data=blobs, name='Candidate Blobs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot blob locations on a satellite base image\n",
    "candidate_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.preprocessing import normalize as sklearn_normalize\n",
    "from sklearn.utils import shuffle\n",
    "from tqdm.notebook import tqdm\n",
    "from matplotlib import animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '../data/training_sites'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(DATA_DIR, \"negative_data.pkl\"), 'rb') as file:\n",
    "    x_negative = pickle.load(file)\n",
    "file.close()\n",
    "y_negative = np.zeros(len(x_negative))\n",
    "\n",
    "with open(os.path.join(DATA_DIR, \"positive_data.pkl\"), 'rb') as file:\n",
    "    x_positive = pickle.load(file)\n",
    "file.close()\n",
    "y_positive = np.ones(len(x_positive))\n",
    "\n",
    "with open(os.path.join(DATA_DIR, \"positive_data_test.pkl\"), 'rb') as file:\n",
    "    x_positive_test = pickle.load(file)\n",
    "file.close()\n",
    "y_positive_test = np.ones(len(x_positive_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.concatenate((x_positive, x_negative))\n",
    "y = np.concatenate((y_positive, y_negative))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x):\n",
    "    return (np.array(x) / (3000 - 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = shuffle(x, y, random_state=42)\n",
    "x = normalize(x)\n",
    "x_positive_test = normalize(x_positive_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=42)\n",
    "print(\"Num Train:\\t\\t\", len(x_train))\n",
    "print(\"Num Test:\\t\\t\", len(x_test))\n",
    "print(f\"Percent Negative Train:\\t {100 * sum(y_train == 0.0) / len(y_train):.1f}\")\n",
    "print(f\"Percent Negative Test:\\t {100 * sum(y_test == 0.0) / len(y_test):.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.expand_dims(x_train, -1)\n",
    "x_test = np.expand_dims(x_test, -1)\n",
    "x_positive_test = np.expand_dims(x_positive_test, -1)\n",
    "\n",
    "num_classes = 2\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "y_positive_test = keras.utils.to_categorical(y_positive_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = np.shape(x_train[0])\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        layers.Conv1D(32, kernel_size=(3), activation=\"relu\"),\n",
    "        #layers.MaxPooling2D(pool_size=(2)),\n",
    "        layers.Conv1D(64, kernel_size=(3), activation=\"relu\"),\n",
    "        #layers.MaxPooling2D(pool_size=(2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64, activation=\"relu\"),\n",
    "        layers.Dense(64, activation=\"relu\"),\n",
    "        layers.Dense(64, activation=\"relu\"),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(num_classes, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", \n",
    "              optimizer=\"adam\", \n",
    "              metrics=[\"accuracy\"],\n",
    "              #loss_weights = sum(y_train) / len(y_train),\n",
    "              #weighted_metrics = ['accuracy']\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_positive_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.concatenate((x_positive_test, x_test[:5000])).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_weight, positive_weight = class_weight.compute_class_weight('balanced', \n",
    "                                                           classes = np.unique(y_train),\n",
    "                                                           y = y_train[:,1])\n",
    "\n",
    "print(f\"Negative Weight: {negative_weight:.2f}\")\n",
    "print(f\"Positive Weight: {positive_weight:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "\n",
    "weight_offset = 200000\n",
    "negative_weight = (1 - (sum(y_train) - weight_offset) / len(y_train))[0]\n",
    "positive_weight = (1 - (sum(y_train) + weight_offset) / len(y_train))[1]\n",
    "\n",
    "negative_weight, positive_weight = class_weight.compute_class_weight('balanced', \n",
    "                                                           classes = np.unique(y_train),\n",
    "                                                           y = y_train[:,1])\n",
    "\n",
    "print(f\"Negative Weight: {negative_weight:.2f}\")\n",
    "print(f\"Positive Weight: {positive_weight:.2f}\")\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 60\n",
    "\n",
    "model.fit(x_train, \n",
    "          y_train, \n",
    "          batch_size=batch_size, \n",
    "          epochs=epochs, \n",
    "          validation_data = (np.concatenate((x_positive_test, x_test[:5000])), \n",
    "                             np.concatenate((y_positive_test, y_test[:5000]))),\n",
    "          #validation_split=0.1,\n",
    "          #class_weight = {0: negative_weight, 1: positive_weight}\n",
    "         )\n",
    "\n",
    "plt.figure(figsize=(8,5), dpi=100)\n",
    "plt.plot(model.history.history['accuracy'], label='Train Acc')\n",
    "plt.plot(model.history.history['val_accuracy'], c='r', label='Val Acc')\n",
    "plt.xlabel('Epoch')\n",
    "plt.xticks(range(epochs))\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Network Train and Val Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.models.save_model(model, '../models/model-12-04-2020.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convs = []\n",
    "for filter in range(32):\n",
    "    convs.append([dim[0][filter] for dim in model.layers[0].get_weights()[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = []\n",
    "out.append([[np.dot(x_test[0,i:3+i,0], np.array(conv)) for i in range(10)] for conv in convs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,3), facecolor=(1,1,1))\n",
    "plt.imshow(np.array(convs).T, cmap='seismic', vmin=-1, vmax=1)\n",
    "plt.title('Convolution Kernels')\n",
    "plt.xticks(range(32))\n",
    "plt.xlabel('Convolution Index')\n",
    "plt.colorbar()\n",
    "\n",
    "for sample in range(10):\n",
    "    out = []\n",
    "    out.append([[np.dot(x_test[sample,i:3+i,0], np.array(conv)) for i in range(10)] for conv in convs])\n",
    "    plt.figure(figsize=(20,3), facecolor=(1,1,1))\n",
    "    plt.imshow(np.concatenate((np.transpose(x_test[sample,1:11]), out[0][:])).T, cmap='seismic', vmin=-1, vmax=1)\n",
    "    plt.colorbar()\n",
    "    plt.title('First Layer Convolution Outputs - Sample ' + str(sample) + ', Class: ' + str(int(y_test[sample][1])))\n",
    "    plt.xticks(range(33), ['input'] + [str(_) for _ in range(32)])\n",
    "    plt.xlabel('Input and Convolved Outputs by Conv Index')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_1 = 3\n",
    "sample_2 = 4\n",
    "\n",
    "a_out = []\n",
    "a_out.append([[np.dot(x_test[sample_1,i:3+i,0], np.array(conv)) for i in range(10)] for conv in convs])\n",
    "b_out = []\n",
    "b_out.append([[np.dot(x_test[sample_2,i:3+i,0], np.array(conv)) for i in range(10)] for conv in convs])\n",
    "a = np.concatenate((np.transpose(x_test[sample_1,1:11]), a_out[0][:])).T\n",
    "b = np.concatenate((np.transpose(x_test[sample_2,1:11]), b_out[0][:])).T\n",
    "plt.figure(figsize=(20,3), facecolor=(1,1,1))\n",
    "plt.imshow(a-b, cmap='seismic', vmin=-1, vmax=1)\n",
    "plt.xticks(range(33), ['input'] + [str(_) for _ in range(32)])\n",
    "plt.xlabel('Input and Conv Filter Indices')\n",
    "plt.colorbar()\n",
    "plt.title(f'Convolution Output Difference between Samples {sample_1} and {sample_2}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    plt.plot(x_test[i], label='Not TPA (sample 3)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5), dpi=150, facecolor=(1,1,1))\n",
    "plt.plot(x_test[0], label='Not TPA (sample 3)')\n",
    "plt.plot(x_test[sample_2], color='r', label='TPA (sample 4)')\n",
    "plt.legend()\n",
    "plt.xticks(range(len(band_descriptions)), band_descriptions)\n",
    "plt.xlabel('Band')\n",
    "plt.ylabel('Normalized Reflectance')\n",
    "plt.title('Spectral Profile of Two Pixel Vectors')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for conv in convs:\n",
    "    plt.plot(conv, alpha=0.3, color='k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,3))\n",
    "plt.imshow(np.array(convs).T, cmap='seismic', vmin=-1, vmax=1)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,3))\n",
    "plt.imshow(np.array(convs).T, cmap='seismic', vmin=-1, vmax=1)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(model.history.history['weighted_accuracy'], label='Train Acc')\n",
    "plt.plot(model.history.history['val_weighted_accuracy'], c='r', label='Val Acc')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metrics = model.evaluate(x_positive_test, y_positive_test)\n",
    "print(f\"Test Loss: {test_metrics[0]:.2f}\\nTest Accuracy: {test_metrics[1]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[element[0] for element in y_test[:num_samples]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 50\n",
    "plt.figure(figsize=(20, 3), dpi=200, facecolor=(1,1,1))\n",
    "plt.imshow(x_train[:num_samples,:,0].T, cmap='viridis')\n",
    "plt.ylabel(\"Band\")\n",
    "plt.xlabel(\"Class Label\")\n",
    "plt.yticks(range(len(band_descriptions)), band_descriptions)\n",
    "plt.xticks(range(num_samples), labels=[int(element[1]) for element in y_train[:num_samples]])\n",
    "plt.colorbar()\n",
    "plt.title(\"Input Training Data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 16\n",
    "plt.figure(figsize=(20, 3), dpi=200, facecolor=(1,1,1))\n",
    "plt.imshow(x_positive_test[:num_samples,:,0].T, cmap='viridis')\n",
    "plt.ylabel(\"Band\")\n",
    "plt.colorbar()\n",
    "plt.yticks(range(len(band_descriptions)), band_descriptions)\n",
    "plt.xticks(range(num_samples), labels=[int(element[1]) for element in y_positive_test[:num_samples]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('../models/model-12-02-2020.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentinel 2 band descriptions\n",
    "band_descriptions = {\n",
    "    'B1': 'Aerosols, 442nm',\n",
    "    'B2': 'Blue, 492nm',\n",
    "    'B3': 'Green, 559nm',\n",
    "    'B4': 'Red, 665nm',\n",
    "    'B5': 'Red Edge 1, 704nm',\n",
    "    'B6': 'Red Edge 2, 739nm',\n",
    "    'B7': 'Red Edge 3, 779nm',\n",
    "    'B8': 'NIR, 833nm',\n",
    "    'B8A': 'Red Edge 4, 864nm',\n",
    "    'B9': 'Water Vapor, 943nm',\n",
    "    'B11': 'SWIR 1, 1610nm',\n",
    "    'B12': 'SWIR 2, 2186nm'\n",
    "}\n",
    "\n",
    "band_wavelengths = [442, 492, 559, 665, 704, 739, 779, 833, 864, 943, 1610, 2186]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pixel_vectors(data_source, month):\n",
    "    pixel_vectors = []\n",
    "    for site in data_source[list(data_source.keys())[0]]:\n",
    "        #for month in data_source.keys():\n",
    "        if -999 not in data_source[month][site]['B2']:\n",
    "            width, height = np.shape(data_source[month][site]['B2'])\n",
    "            for i in range(width):\n",
    "                for j in range(height):\n",
    "                    pixel_vector = []\n",
    "                    for band in band_descriptions:\n",
    "                        pixel_vector.append(data_source[month][site][band][i][j])\n",
    "                    pixel_vectors.append(pixel_vector)\n",
    "        else: width, height = 0, 0\n",
    "    return pixel_vectors, width, height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(site_name, threshold):\n",
    "    with open(os.path.join(DATA_DIR, site_name + \"_0.03_patch.pkl\"), 'rb') as file:\n",
    "        test_image = pickle.load(file)\n",
    "\n",
    "    rgb_stack = []\n",
    "    preds_stack = []\n",
    "    threshold_stack = []\n",
    "\n",
    "    for month in tqdm(list(test_image.keys())):\n",
    "        test_pixel_vectors, width, height = get_pixel_vectors(test_image, month)\n",
    "        if width > 0:\n",
    "            test_pixel_vectors = normalize(test_pixel_vectors)\n",
    "\n",
    "            r = np.reshape(np.array(test_pixel_vectors)[:,3], (width, height))\n",
    "            g = np.reshape(np.array(test_pixel_vectors)[:,2], (width, height))\n",
    "            b = np.reshape(np.array(test_pixel_vectors)[:,1], (width, height))\n",
    "            rgb = np.moveaxis(np.stack((r,g,b)), 0, -1)\n",
    "            rgb_stack.append(rgb)\n",
    "\n",
    "            preds = model.predict(np.expand_dims(test_pixel_vectors, axis=-1))\n",
    "            preds_img = np.reshape(preds, (width, height, 2))[:,:,1]\n",
    "            preds_stack.append(preds_img)\n",
    "\n",
    "            thresh_img = preds_img > threshold\n",
    "            threshold_stack.append(thresh_img)\n",
    "    \n",
    "    output_dir = './figures/neural_network/12-04-2020'\n",
    "    if not os.path.exists(output_dir):\n",
    "            os.mkdir(output_dir)\n",
    "\n",
    "            \n",
    "    rgb_median = np.median(rgb_stack, axis=0)\n",
    "    preds_median = np.median(preds_stack, axis=0)\n",
    "    threshold_median = np.median(threshold_stack, axis=0)\n",
    "    \n",
    "    plt.figure(dpi=150, facecolor=(1,1,1), figsize=(15,5))\n",
    "\n",
    "    plt.subplot(1,3,1)\n",
    "    plt.imshow(rgb_median / np.max(rgb_median))\n",
    "    plt.title(f'{site_name} Median', size=8)\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1,3,2)\n",
    "    plt.imshow(preds_median, vmin=0, vmax=1, cmap='seismic')\n",
    "    plt.title('Classification Median', size=8)\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1,3,3)\n",
    "    plt.imshow(threshold_median, vmin=threshold, vmax=1, cmap='gray')\n",
    "    plt.title(f\"Positive Pixels Median: Threshold {threshold}\", size=8)\n",
    "    plt.axis('off')\n",
    "\n",
    "    title = f\"{site_name} Test Set - Median Values - Neural Network Classification - Threshold {threshold}\"\n",
    "    plt.suptitle(title, y=1.01)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, title + '.png'), bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    fig, ax = plt.subplots(dpi=200, facecolor=(1,1,1), figsize=(4,4))\n",
    "    ax.set_axis_off()\n",
    "    clipped_img = np.moveaxis([channel * (preds_median > 0) for channel in np.moveaxis(rgb_median, -1, 0)], 0, -1)\n",
    "    img = plt.imshow(clipped_img / (clipped_img.max()))\n",
    "    ax.set_title('Threshold 0')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    def animate(i):\n",
    "        i /= 100\n",
    "        clipped_img = np.moveaxis([channel * (preds_median > i) for channel in np.moveaxis(rgb_median, -1, 0)], 0, -1)\n",
    "        img.set_data(clipped_img / (clipped_img.max()))\n",
    "        #img.set_data((preds_stack > i) * 1)\n",
    "        ax.set_title(site_name + ' Threshold ' + str(i))\n",
    "        return img,\n",
    "\n",
    "    ani = animation.FuncAnimation(fig, animate, frames=100, interval=60, blit=True, repeat_delay=500)\n",
    "    ani.save(os.path.join(output_dir, site_name + 'test_set_threshold_visualization' + '.mp4'))\n",
    "    plt.close()\n",
    "    \n",
    "    return rgb_median, preds_median, threshold_median\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('../models/model-12-02-2020.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '../data'\n",
    "site_names = ['bare_earth_4', 'city_7', 'tpa_babandem', 'tpa_bangli', 'tpa_biaung', 'tpa_mandung', 'tpa_jimbaran', 'tpa_jimbaran']\n",
    "threshold = 0.90\n",
    "\n",
    "for site_name in site_names:\n",
    "    rgb_median, preds_median, threshold_median = make_predictions(site_name, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '../data'\n",
    "site_names = ['tpa_mandung']\n",
    "threshold = 0.91\n",
    "\n",
    "for site_name in site_names:\n",
    "    rgb_median, preds_median, threshold_median = make_predictions(site_name, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.hist(np.array(preds_median).flatten(), 150, log=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_model = keras.models.load_model('../models/model-12-02-2020.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = np.concatenate((x_positive_test, x_test[:20000]))\n",
    "preds = model.predict(inputs)\n",
    "labels = np.concatenate((y_positive_test, y_test[:20000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(np.array(labels)[:,0] == 1.0) / len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offset = 3300\n",
    "num_samples = 500\n",
    "threshold = 0.9\n",
    "plt.figure(figsize=(8,5), dpi=100)\n",
    "for pred, label, spectra in zip(preds[offset:offset+num_samples], labels[offset:offset+num_samples], inputs[offset:offset+num_samples]):\n",
    "    # If label is negative\n",
    "    if label[0] == 1.0:\n",
    "        # If negative prediction is greater than threshold\n",
    "        # plot lines without points\n",
    "        if pred[0] >= threshold:\n",
    "            plt.plot(spectra, color='green', alpha=0.05)\n",
    "        # If negative prediction is below the threshold\n",
    "        # plot line in yellow\n",
    "        else:\n",
    "            plt.plot(spectra, color='orange', alpha=0.25)\n",
    "    # If label is positive\n",
    "    else:\n",
    "        # if prediction \n",
    "        if pred[1] >= threshold:\n",
    "            plt.plot(spectra, color='C0', alpha=0.05)\n",
    "        else:\n",
    "            plt.plot(spectra, color='red', alpha=.25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_pred = []\n",
    "fp_input = []\n",
    "fp_rgb = []\n",
    "threshold = 0.9\n",
    "for pred, label, spectra in zip(preds, labels, inputs):\n",
    "    if label[1] == 0 and pred[1] > threshold:\n",
    "        fp_pred.append(pred)\n",
    "        fp_input.append(spectra)\n",
    "        rgb = np.zeros((1,1,3))\n",
    "        rgb[0,0,:] = [spectra[3], spectra[2], spectra[1]]\n",
    "        fp_rgb.append([spectra[3], spectra[2], spectra[1]])\n",
    "\n",
    "fp_rgb = (np.squeeze(fp_rgb) - np.min(fp_rgb)) / (np.max(fp_rgb) - np.min(fp_rgb))\n",
    "print(f\"{100 * len(fp_pred) / sum(np.array(labels)[:,1] == 0):.2f}% of negative samples in the test dataset are classified as positives\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn_pred = []\n",
    "tn_input = []\n",
    "tn_rgb = []\n",
    "threshold = 0.9\n",
    "for pred, label, spectra in zip(preds, labels, inputs):\n",
    "    if label[1] == 0 and pred[1] < threshold:\n",
    "        tn_pred.append(pred)\n",
    "        tn_input.append(spectra)\n",
    "        rgb = np.zeros((1,1,3))\n",
    "        rgb[0,0,:] = [spectra[3], spectra[2], spectra[1]]\n",
    "        tn_rgb.append([spectra[3], spectra[2], spectra[1]])\n",
    "\n",
    "tn_rgb = (np.squeeze(tn_rgb) - np.min(tn_rgb)) / (np.max(tn_rgb) - np.min(tn_rgb))\n",
    "print(f\"{100 * len(tn_pred) / sum(np.array(labels)[:,1] == 0):.2f}% of negative samples in the test dataset are correctly classified as negatives\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_pred = []\n",
    "fn_input = []\n",
    "fn_rgb = []\n",
    "threshold = 0.9\n",
    "for pred, label, spectra in zip(preds, labels, inputs):\n",
    "    if label[1] == 1 and pred[1] < threshold:\n",
    "        fn_pred.append(pred)\n",
    "        fn_input.append(spectra)\n",
    "        rgb = np.zeros((1,1,3))\n",
    "        rgb[0,0,:] = [spectra[3], spectra[2], spectra[1]]\n",
    "        fn_rgb.append([spectra[3], spectra[2], spectra[1]])\n",
    "\n",
    "fn_rgb = (np.squeeze(fn_rgb) - np.min(fn_rgb)) / (np.max(fn_rgb) - np.min(fn_rgb))\n",
    "print(f\"{100 * len(fn_pred) / sum(np.array(labels)[:,1] == 1):.0f}% of positive samples in the test dataset are incorrectly classified as negatives\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp_pred = []\n",
    "tp_input = []\n",
    "tp_rgb = []\n",
    "threshold = 0.9\n",
    "for pred, label, spectra in zip(preds, labels, inputs):\n",
    "    if label[1] == 1 and pred[1] > threshold:\n",
    "        tp_pred.append(pred)\n",
    "        tp_input.append(spectra)\n",
    "        rgb = np.zeros((1,1,3))\n",
    "        rgb[0,0,:] = [spectra[3], spectra[2], spectra[1]]\n",
    "        tp_rgb.append([spectra[3], spectra[2], spectra[1]])\n",
    "\n",
    "tp_rgb = (np.squeeze(tp_rgb) - np.min(tp_rgb)) / (np.max(tp_rgb) - np.min(tp_rgb))\n",
    "print(f\"{100 * len(tp_pred) / sum(np.array(labels)[:,1] == 1):.0f}% of positive samples in the test dataset are correctly classified as positives\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(tn_rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(50,3), dpi=350, facecolor=(1,1,1))\n",
    "plt.scatter(range(len(tn_pred)), sorted(np.array(tn_pred)[:,1]), c=np.squeeze(tn_rgb), s=1)\n",
    "plt.xticks([])\n",
    "plt.ylabel(\"Prediction Score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(12):\n",
    "    plt.figure(figsize=(8,5), dpi=150)\n",
    "    plt.scatter(np.array(fn_pred)[:,1], np.array(fn_input)[:,i],\n",
    "                c=np.squeeze(fn_rgb),\n",
    "                s=5\n",
    "               )\n",
    "    plt.ylabel(f'Band {i + 1} Reflectance (Green)')\n",
    "    plt.xlabel('Classification Score')\n",
    "    plt.title('False Positives')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pixel_grid(preds, colors, title):\n",
    "    plt.figure(figsize=(20,20), dpi=50)\n",
    "    num_samples = np.min([len(preds), 100])\n",
    "    indices = np.random.choice(len(preds), num_samples)\n",
    "    for i in range(num_samples):\n",
    "        index = indices[i]\n",
    "        pred = preds[index]\n",
    "        rgb = np.expand_dims(np.expand_dims(colors[index], axis=0), axis=0)\n",
    "        plt.subplot(10,10,i + 1)\n",
    "        plt.imshow(rgb)\n",
    "        plt.axis('off')\n",
    "        plt.title(f\"{pred[1]:.2f}\")\n",
    "    plt.suptitle(title, size=20, y=1.01)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.choice(2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pixel_grid(tp_pred, tp_rgb, 'Colors of True Positives')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pixel_grid(fp_pred, fp_rgb, 'Colors of False Positives')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pixel_grid(tn_pred, tn_rgb, 'Colors of True Negatives')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pixel_grid(fn_pred, fn_rgb, 'Colors of False Negatives')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,20), dpi=50)\n",
    "for i in range(100):\n",
    "    index = i\n",
    "    plt.subplot(10,10,i + 1)\n",
    "    plt.imshow(np.expand_dims(np.expand_dims(np.stack((inputs[index][3][0], inputs[index][2][0], inputs[index][1][0])), axis=0), axis=0))\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"{preds[index][1]:.2f}\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.expand_dims(np.expand_dims(np.stack((inputs[index][3][0], inputs[index][2][0], inputs[index][1][0])), axis=0), axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "\n",
    "\n",
    "clf = tree.DecisionTreeClassifier(max_leaf_nodes=512, max_depth=64)\n",
    "                                  #, class_weight='balanced')\n",
    "clf = clf.fit(np.squeeze(x_train), y_train[:,1])\n",
    "\n",
    "print(\"Accuracy:\", clf.score(np.squeeze(x_test), y_test[:,1]))\n",
    "print(\"Feature Importances:\")\n",
    "for band, importance in zip(band_descriptions, clf.feature_importances_):\n",
    "    print(f\"{band}: {importance:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_name = 'tpa_mandung'\n",
    "with open(os.path.join(DATA_DIR, site_name + \"_0.03_patch.pkl\"), 'rb') as file:\n",
    "    test_image = pickle.load(file)\n",
    "\n",
    "rgb_stack = []\n",
    "preds_stack = []\n",
    "threshold_stack = []\n",
    "\n",
    "for month in tqdm(list(test_image.keys())):\n",
    "    test_pixel_vectors, width, height = get_pixel_vectors(test_image, month)\n",
    "    if width > 0:\n",
    "        test_pixel_vectors = normalize(test_pixel_vectors)\n",
    "\n",
    "        r = np.reshape(np.array(test_pixel_vectors)[:,3], (width, height))\n",
    "        g = np.reshape(np.array(test_pixel_vectors)[:,2], (width, height))\n",
    "        b = np.reshape(np.array(test_pixel_vectors)[:,1], (width, height))\n",
    "        rgb = np.moveaxis(np.stack((r,g,b)), 0, -1)\n",
    "        rgb_stack.append(rgb)\n",
    "\n",
    "        preds = clf.predict(test_pixel_vectors)\n",
    "        preds_img = np.reshape(preds, (width, height))\n",
    "        preds_stack.append(preds_img)\n",
    "\n",
    "        thresh_img = preds_img > threshold\n",
    "        threshold_stack.append(thresh_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_median = np.median(rgb_stack, axis=0)\n",
    "preds_median = np.median(preds_stack, axis=0)\n",
    "threshold_median = np.median(threshold_stack, axis=0)\n",
    "\n",
    "plt.figure(dpi=150, facecolor=(1,1,1), figsize=(15,5))\n",
    "\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(rgb_median / np.max(rgb_median))\n",
    "plt.title(f'{site_name} Median', size=8)\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(preds_median, vmin=0, vmax=1, cmap='seismic')\n",
    "plt.title('Classification Median', size=8)\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(threshold_median, vmin=0, vmax=1, cmap='gray')\n",
    "plt.title(f\"Positive Pixels Median: Threshold {threshold}\", size=8)\n",
    "plt.axis('off')\n",
    "\n",
    "title = f\"{site_name} - Median Values - Decision Tree Classification - Threshold {threshold}\"\n",
    "plt.suptitle(title, y=1.01)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_dir, title + '.png'), bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(dpi=200, facecolor=(1,1,1), figsize=(4,4))\n",
    "ax.set_axis_off()\n",
    "clipped_img = np.moveaxis([channel * (preds_median > 0) for channel in np.moveaxis(rgb_median, -1, 0)], 0, -1)\n",
    "img = plt.imshow(clipped_img / (clipped_img.max()))\n",
    "ax.set_title('Threshold 0')\n",
    "plt.tight_layout()\n",
    "\n",
    "def animate(i):\n",
    "    i /= 100\n",
    "    clipped_img = np.moveaxis([channel * (preds_median > i) for channel in np.moveaxis(rgb_median, -1, 0)], 0, -1)\n",
    "    img.set_data(clipped_img / (clipped_img.max()))\n",
    "    #img.set_data((preds_stack > i) * 1)\n",
    "    ax.set_title(site_name + ' Threshold ' + str(i))\n",
    "    return img,\n",
    "\n",
    "ani = animation.FuncAnimation(fig, animate, frames=101, interval=60, blit=True, repeat_delay=500)\n",
    "ani.save(os.path.join(output_dir, site_name + '_decision_tree_threshold_visualization' + '.mp4'))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.array(x_train).flatten(), 100, log=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output_dir = './figures/neural_network'\n",
    "if not os.path.exists(output_dir):\n",
    "        os.mkdir(output_dir)\n",
    "\n",
    "threshold = 0.75\n",
    "\n",
    "rgb_stack = []\n",
    "classification_stack = []\n",
    "threshold_stack = []\n",
    "\n",
    "for month in list(test_image.keys()):\n",
    "    test_pixel_vectors = get_pixel_vectors(test_image, month)\n",
    "    if len(test_pixel_vectors) > 0:\n",
    "        test_pixel_vectors = normalize(test_pixel_vectors)\n",
    "\n",
    "        r = np.reshape(np.array(test_pixel_vectors)[:,3], (335, 335))\n",
    "        g = np.reshape(np.array(test_pixel_vectors)[:,2], (335, 335))\n",
    "        b = np.reshape(np.array(test_pixel_vectors)[:,1], (335, 335))\n",
    "        rgb = np.moveaxis(np.stack((r,g,b)), 0, -1)\n",
    "        \n",
    "        plt.figure(dpi=150, facecolor=(1,1,1), figsize=(15,5))\n",
    "        \n",
    "        plt.subplot(1,3,1)\n",
    "        plt.imshow(rgb ** 0.65)\n",
    "        plt.title(month, size=8)\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.subplot(1,3,2)\n",
    "        preds = model.predict(np.expand_dims(test_pixel_vectors, axis=-1))\n",
    "        preds_img = np.reshape(preds, (335, 335, 2))[:,:,1]\n",
    "        im = plt.imshow(preds_img, vmin=0, vmax=1, cmap='seismic')\n",
    "        plt.axis('off')\n",
    "        plt.title('Classification', size=8)\n",
    "        #plt.colorbar(im,fraction=0.045, pad=0.02, ticks=[0, 1])\n",
    "        \n",
    "        plt.subplot(1,3,3)\n",
    "        plt.imshow(preds_img > threshold, vmin=0, vmax=1, cmap='gray')\n",
    "        plt.axis('off')\n",
    "        plt.title(f\"Positive Pixels: Threshold {threshold}\", size=8)\n",
    "        \n",
    "        title = f\"TPA Regional Bangli - Neural Network Classification - 0.03° Patch\"\n",
    "        plt.suptitle(title, y=0.9)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(output_dir, title + '_' + month + '.png'), bbox_inches='tight')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clipped_img = np.moveaxis([channel * (preds_median > 0.98) for channel in np.moveaxis(rgb_median, -1, 0)], 0, -1)\n",
    "plt.figure(dpi=300)\n",
    "plt.imshow((clipped_img / (clipped_img.max())))\n",
    "plt.axis('off')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

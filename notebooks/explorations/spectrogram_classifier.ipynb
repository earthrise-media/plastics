{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "from datetime import datetime\n",
    "import ee\n",
    "import geemap\n",
    "from multiprocessing.dummy import Pool as ThreadPool\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from scripts.get_s2_data_ee import get_history, get_history_polygon, get_pixel_vectors\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import normalize as sklearn_normalize\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tqdm import tqdm\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '../data/training_sites'\n",
    "\n",
    "with open(os.path.join(DATA_DIR, \"tpa_patch_histories_toa.pkl\"), 'rb') as file:\n",
    "    positive_histories = pickle.load(file)\n",
    "file.close()\n",
    "\n",
    "with open(os.path.join(DATA_DIR, \"negative_patch_histories_toa.pkl\"), 'rb') as file:\n",
    "    negative_histories = pickle.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentinel 2 band descriptions\n",
    "band_descriptions = {\n",
    "    'B1': 'Aerosols, 442nm',\n",
    "    'B2': 'Blue, 492nm',\n",
    "    'B3': 'Green, 559nm',\n",
    "    'B4': 'Red, 665nm',\n",
    "    'B5': 'Red Edge 1, 704nm',\n",
    "    'B6': 'Red Edge 2, 739nm',\n",
    "    'B7': 'Red Edge 3, 779nm',\n",
    "    'B8': 'NIR, 833nm',\n",
    "    'B8A': 'Red Edge 4, 864nm',\n",
    "    'B9': 'Water Vapor, 943nm',\n",
    "    'B11': 'SWIR 1, 1610nm',\n",
    "    'B12': 'SWIR 2, 2186nm'\n",
    "}\n",
    "\n",
    "band_wavelengths = [442, 492, 559, 665, 704, 739, 779, 833, 864, 943, 1610, 2186]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_spectrogram_dataset(dataset, dates):\n",
    "    sites = list(dataset[dates[0]].keys())\n",
    "    spectrogram_list = []\n",
    "    for site in sites:\n",
    "        date_idx_with_data = np.argmax([len(dataset[date][site]['B2']) for date in dates])\n",
    "        width, height = np.shape(dataset[dates[date_idx_with_data]][site]['B2'])\n",
    "        for i in range(width):\n",
    "            for j in range(height):\n",
    "                spectrogram = []\n",
    "                for date in dates:\n",
    "                    if len(dataset[date][site]['B2']) > 0:\n",
    "                        pixel_vector = []\n",
    "                        for band in band_descriptions:\n",
    "                            if dataset[date][site][band][i][j] != -999:\n",
    "                                pixel_vector.append(dataset[date][site][band][i][j])\n",
    "                            else:\n",
    "                                pixel_vector.append(0)\n",
    "                        spectrogram.append(pixel_vector)\n",
    "                    else:\n",
    "                        spectrogram.append([0] * len(band_descriptions))\n",
    "                spectrogram_list.append(np.transpose(spectrogram))\n",
    "    \n",
    "    return np.array(spectrogram_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = list(negative_histories[0].keys())[:12]\n",
    "city_spectrograms = create_spectrogram_dataset(negative_histories[0], dates)\n",
    "bare_earth_spectrograms = create_spectrogram_dataset(negative_histories[1], dates)\n",
    "adjacent_spectrograms = create_spectrogram_dataset(negative_histories[2], dates)\n",
    "negative_spectrograms = np.concatenate((city_spectrograms, bare_earth_spectrograms, adjacent_spectrograms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = list(positive_histories.keys())[:12]\n",
    "positive_spectrograms = create_spectrogram_dataset(positive_histories, dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = list(positive_histories.keys())[4:16]\n",
    "positive_spectrograms_2016 = create_spectrogram_dataset(positive_histories, dates)\n",
    "\n",
    "dates = list(positive_histories.keys())[16:28]\n",
    "positive_spectrograms_2017 = create_spectrogram_dataset(positive_histories, dates)\n",
    "\n",
    "dates = list(positive_histories.keys())[28:40]\n",
    "positive_spectrograms_2018 = create_spectrogram_dataset(positive_histories, dates)\n",
    "\n",
    "dates = list(positive_histories.keys())[40:52]\n",
    "positive_spectrograms_2019 = create_spectrogram_dataset(positive_histories, dates)\n",
    "\n",
    "positive_spectrograms = np.concatenate((positive_spectrograms_2016, \n",
    "                                        positive_spectrograms_2017, \n",
    "                                        positive_spectrograms_2018, \n",
    "                                        positive_spectrograms_2019))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of Negative Samples:\", len(negative_spectrograms))\n",
    "print(\"Number of Positive Samples:\", len(positive_spectrograms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_ndvi = []\n",
    "for sample in positive_spectrograms:\n",
    "    if sample[7,0] + sample[3,0] > 0:\n",
    "        ndvi = (sample[7,0] - sample[3,0]) / (sample[7,0] + sample[3,0])\n",
    "    else:\n",
    "        ndvi = 0\n",
    "    positive_ndvi.append(ndvi)\n",
    "positive_ndvi = np.array(positive_ndvi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_spectrograms = positive_spectrograms[positive_ndvi < 0.5]\n",
    "print(\"Number of Positive Samples after NDVI Thresholding:\", len(positive_spectrograms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.subplot(2,2,1)\n",
    "plt.imshow(np.median(city_spectrograms, axis=0), vmin=0, vmax=3500)\n",
    "plt.xticks(range(0,len(dates),2), dates[0::2], rotation=45, ha='right')\n",
    "plt.yticks(range(len(band_descriptions)), band_descriptions)\n",
    "plt.colorbar()\n",
    "plt.title('City Sample Median Spectrogram')\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.imshow(np.median(bare_earth_spectrograms, axis=0), vmin=0, vmax=3500)\n",
    "plt.xticks(range(0,len(dates),2), dates[0::2], rotation=45, ha='right')\n",
    "plt.yticks(range(len(band_descriptions)), band_descriptions)\n",
    "plt.colorbar()\n",
    "plt.title('Bare Earth Sample Median Spectrogram')\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.imshow(np.median(adjacent_spectrograms, axis=0), vmin=0, vmax=3500)\n",
    "plt.xticks(range(0,len(dates),2), dates[0::2], rotation=45, ha='right')\n",
    "plt.yticks(range(len(band_descriptions)), band_descriptions)\n",
    "plt.colorbar()\n",
    "plt.title('Adjacent Site Median Spectrogram')\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "plt.imshow(np.median(positive_spectrograms, axis=0), vmin=0, vmax=3500)\n",
    "plt.xticks(range(0,len(dates),2), dates[0::2], rotation=45, ha='right')\n",
    "plt.yticks(range(len(band_descriptions)), band_descriptions)\n",
    "plt.colorbar()\n",
    "plt.title('TPA Site Median Spectrogram')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "for i in range(16):\n",
    "    index = np.random.randint(len(positive_spectrograms))\n",
    "    plt.subplot(4,4,i + 1)\n",
    "    plt.imshow(positive_spectrograms[index], vmin=0, vmax=3500)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.xlabel('Month')\n",
    "    plt.ylabel('Band')\n",
    "    plt.title('Sample ' + str(index))\n",
    "plt.suptitle('TPA Sites')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "for i in range(16):\n",
    "    index = np.random.randint(len(positive_spectrograms))\n",
    "    plt.subplot(4,4,i + 1)\n",
    "    plt.imshow(negative_spectrograms[index], vmin=0, vmax=3500)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.xlabel('Month')\n",
    "    plt.ylabel('Band')\n",
    "    plt.title('Sample ' + str(index))\n",
    "plt.suptitle('Negative Samples')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill empty bands with mean value\n",
    "positive_fill = np.copy(positive_spectrograms)\n",
    "for index, sample in enumerate(positive_spectrograms):\n",
    "    for band_num, band in enumerate(sample):\n",
    "        band[band == 0.0] = np.mean(band)\n",
    "        positive_fill[index, band_num] = band\n",
    "        \n",
    "# Attempt to fill empty bands\n",
    "negative_fill = np.copy(negative_spectrograms)\n",
    "for index, sample in enumerate(negative_spectrograms):\n",
    "    for band_num, band in enumerate(sample):\n",
    "        band[band == 0.0] = np.mean(band)\n",
    "        negative_fill[index, band_num] = band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attempt to interpolate empty bands. Doesn't work at the moment\n",
    "positive_interp = np.copy(positive_spectrograms)\n",
    "for sample in range(len(positive_spectrograms)):\n",
    "    for band in sample:\n",
    "        \n",
    "    # middle samples\n",
    "    for month in range(1,11):\n",
    "        if sum(positive_spectrograms[sample,:,month] == 0) > 6:\n",
    "            interpolated = (positive_spectrograms[sample,:,month - 1] + positive_spectrograms[sample,:,month + 1]) // 2\n",
    "            positive_interp[sample,:,month] = interpolated\n",
    "\n",
    "    # front edge\n",
    "    if sum(positive_spectrograms[sample,:,0] == 0) > 6:\n",
    "        interpolated =  positive_spectrograms[sample,:,1]\n",
    "        positive_interp[sample,:,0] = interpolated\n",
    "\n",
    "    # front edge\n",
    "    if sum(positive_spectrograms[sample,:,11] == 0) > 6:\n",
    "        interpolated =  positive_spectrograms[sample,:,11]\n",
    "        positive_interp[sample,:,0] = interpolated\n",
    "        \n",
    "negative_interp = np.copy(negative_spectrograms)\n",
    "for sample in range(len(negative_spectrograms)):\n",
    "    # middle samples\n",
    "    for month in range(1,11):\n",
    "        if sum(negative_spectrograms[sample,:,month] == 0) > 6:\n",
    "            interpolated = (negative_spectrograms[sample,:,month - 1] + negative_spectrograms[sample,:,month + 1]) // 2\n",
    "            negative_interp[sample,:,month] = interpolated\n",
    "\n",
    "    # front edge\n",
    "    if sum(negative_spectrograms[sample,:,0] == 0) > 6:\n",
    "        interpolated =  negative_spectrograms[sample,:,1]\n",
    "        negative_interp[sample,:,0] = interpolated\n",
    "\n",
    "    # front edge\n",
    "    if sum(negative_spectrograms[sample,:,11] == 0) > 6:\n",
    "        interpolated =  negative_spectrograms[sample,:,11]\n",
    "        negative_interp[sample,:,0] = interpolated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "for i in range(16):\n",
    "    index = np.random.randint(len(positive_fill))\n",
    "    plt.subplot(4,4,i + 1)\n",
    "    plt.imshow(positive_spectrograms[index], vmin=0, vmax=3500)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.xlabel('Month')\n",
    "    plt.ylabel('Band')\n",
    "    plt.title('Sample ' + str(index))\n",
    "plt.suptitle('TPA Sites')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "for i in range(16):\n",
    "    index = np.random.randint(len(negative_fill))\n",
    "    plt.subplot(4,4,i + 1)\n",
    "    plt.imshow(negative_spectrograms[index], vmin=0, vmax=3500)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.xlabel('Month')\n",
    "    plt.ylabel('Band')\n",
    "    plt.title(f'Sample {index}')\n",
    "plt.suptitle('Negative Samples')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Data for Network Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x):\n",
    "    return np.array(x) / 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.concatenate((positive_fill, negative_fill))\n",
    "y = np.concatenate((np.ones(len(positive_fill)), np.zeros(len(negative_fill))))\n",
    "\n",
    "x, y = shuffle(x, y, random_state=42)\n",
    "x = normalize(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=42)\n",
    "print(\"Num Train:\\t\\t\", len(x_train))\n",
    "print(\"Num Test:\\t\\t\", len(x_test))\n",
    "print(f\"Percent Negative Train:\\t {100 * sum(y_train == 0.0) / len(y_train):.1f}\")\n",
    "print(f\"Percent Negative Test:\\t {100 * sum(y_test == 0.0) / len(y_test):.1f}\")\n",
    "\n",
    "x_train = np.expand_dims(x_train, -1)\n",
    "x_test = np.expand_dims(x_test, -1)\n",
    "#x_positive_test = np.expand_dims(x_positive_test, -1)\n",
    "\n",
    "num_classes = 2\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = np.shape(x_train[0])\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        layers.Conv2D(8, kernel_size=(3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2)),\n",
    "        layers.Conv2D(16, kernel_size=(3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2)),\n",
    "        layers.Flatten(),\n",
    "        #layers.Dense(64, activation=\"relu\"),\n",
    "        #layers.Dropout(0.2),\n",
    "        layers.Dense(64, activation=\"relu\"),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(16, activation=\"relu\"),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(num_classes, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"binary_crossentropy\", \n",
    "              optimizer=\"adam\", \n",
    "              metrics=[#keras.metrics.Recall(thresholds=(0.9), name='precision'), \n",
    "                       #keras.metrics.Precision(thresholds=(0.9), name='recall'),\n",
    "                       #keras.metrics.AUC(curve='PR', name='auc'),\n",
    "                       \"accuracy\"]\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 30\n",
    "\n",
    "print(\"Num Train:\\t\\t\", len(x_train))\n",
    "print(\"Num Test:\\t\\t\", len(x_test))\n",
    "print(f\"Percent Negative Train:\\t {100 * sum(y_train[:,1] == 0.0) / len(y_train):.1f}\")\n",
    "print(f\"Percent Negative Test:\\t {100 * sum(y_test[:,1] == 0.0) / len(y_test):.1f}\")\n",
    "\n",
    "model.fit(x_train, \n",
    "          y_train, \n",
    "          batch_size=batch_size, \n",
    "          epochs=epochs, \n",
    "          validation_data = (x_test, y_test),\n",
    "          #validation_split=0.1,\n",
    "          #class_weight = {0: negative_weight, 1: positive_weight}\n",
    "          #class_weight = {0: 2, 1: 1}\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5), dpi=100, facecolor=(1,1,1))\n",
    "plt.plot(model.history.history['accuracy'], label='Train Acc')\n",
    "plt.plot(model.history.history['val_accuracy'], c='r', label='Val Acc')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Network Train and Val Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter rect width in degrees (0.035 max recommended) and site coordinates\n",
    "rect_width = 0.005\n",
    "site_coords = [115.350242, -8.562121]\n",
    "name = 'temesi'\n",
    "start_date = '2019-01-01'\n",
    "patch_history = get_history([site_coords], \n",
    "                            [name], \n",
    "                            rect_width,\n",
    "                            num_months = 12,\n",
    "                            start_date = start_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = create_spectrogram_dataset(patch_history, list(patch_history.keys()))\n",
    "for index, sample in enumerate(test_data):\n",
    "    for band_num, band in enumerate(sample):\n",
    "        band[band == 0.0] = np.mean(band)\n",
    "        test_data[index, band_num] = band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_data = patch_history['2019-06-01']['temesi']\n",
    "rgb = np.stack((site_data['B4'], site_data['B3'], site_data['B2']), axis=-1)\n",
    "plt.imshow(normalize(rgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(np.expand_dims(test_data, axis=-1))[:,1]\n",
    "width = int(np.sqrt(test_data.shape[0]))\n",
    "plt.figure(dpi=150)\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(normalize(rgb))\n",
    "plt.axis('off')\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(np.reshape(preds, (width, width)), cmap='seismic', vmin=0.8)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_flat = [sample.flatten() for sample in x]\n",
    "x_flat = np.array(x_flat)\n",
    "x_flat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import umap\n",
    "num_samples = 10000\n",
    "reduced = umap.UMAP(n_components=2).fit_transform(x_flat[:num_samples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8), dpi=150)\n",
    "plt.scatter(reduced[y[:num_samples] == 0.,0], reduced[y[:num_samples] == 0.,1], alpha=.21, s=1, c='r')\n",
    "plt.scatter(reduced[y[:num_samples] == 1.,0], reduced[y[:num_samples] == 1.,1], alpha=.21, s=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    index = np.random.randint(len(test_data))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(x[index], vmin=0, vmax=1.5)\n",
    "    plt.title(f\"{model.predict(np.expand_dims(x[index:index+1], axis=-1))[0][1]:.2f}, True: {y[index]}\")\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(normalize(test_data[index]), vmin=0, vmax=1.5)\n",
    "    plt.title(f\"{model.predict(np.expand_dims(normalize(test_data[index:index+1]), axis=-1))[0][1]:.2f}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "positives = test_data[preds > 0.8]\n",
    "train_positives = x[y == 1]\n",
    "for i in range(10):\n",
    "    index = np.random.randint(len(positives))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(train_positives[index], vmin=0, vmax=1.5)\n",
    "    plt.title(f\"{model.predict(np.expand_dims(train_positives[index:index+1], axis=-1))[0][1]:.2f}\")\n",
    "    plt.axis('off')\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(normalize(positives[index]), vmin=0, vmax=1.5)\n",
    "    plt.title(f\"{model.predict(np.expand_dims(normalize(positives[index:index+1]), axis=-1))[0][1]:.2f}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_thresh = np.copy(preds.reshape(width, width))\n",
    "plt.figure(dpi=300)\n",
    "plt.imshow(pred_thresh)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(preds > 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectrogram_predict(dataset, site_name, model):\n",
    "        rgb_stack = []\n",
    "        preds_stack = []\n",
    "        spectrogram_list = []\n",
    "        \n",
    "        width, height = np.shape(dataset[dates[0]][site]['B2'])\n",
    "        dates = list(patch_histories.keys())\n",
    "        rgb = np.stack((patch_histories[dates[0]][site_name]['B4'],\n",
    "                        patch_histories[dates[0]][site_name]['B3'],\n",
    "                        patch_histories[dates[0]][site_name]['B2']), axis=-1)\n",
    "        for i in range(width):\n",
    "            for j in range(height):\n",
    "                spectrogram = []\n",
    "                for date in tqdm(dates):\n",
    "                    pixel_vector = []\n",
    "                    for band in band_descriptions:\n",
    "                        if dataset[date][site][band][i][j] != -999:\n",
    "                            pixel_vector.append(dataset[date][site][band][i][j])\n",
    "                        else:\n",
    "                            pixel_vector.append(0)\n",
    "                        spectrogram.append(pixel_vector)\n",
    "\n",
    "                        else:\n",
    "                            spectrogram.append([0] * len(band_descriptions))\n",
    "                spectrogram_list.append(np.transpose(spectrogram))\n",
    "                rgb_stack.append(rgb)\n",
    "        preds = model.predict(np.expand_dims(normalize(spectrogram_list), axis=-1))\n",
    "        preds = np.reshape(preds[:,1], (width, height))\n",
    "    return preds, rgb_stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_histories['2019-01-01'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "preds, rgb = spectrogram_predict(positive_histories, dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(rgb).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(rgb / 3000)\n",
    "plt.show()\n",
    "plt.imshow(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(site_name, dates):\n",
    "    with open(os.path.join(DATA_DIR, site_name + \"_0.03_patch.pkl\"), 'rb') as file:\n",
    "        test_image = pickle.load(file)\n",
    "\n",
    "    preds, rgb = spectrogram_predict(test_image, dates)\n",
    "    plt.figure(figsize=(8,8), dpi=150)\n",
    "    plt.subplot(1,3,1)\n",
    "    plt.imshow(normalize(rgb))\n",
    "    plt.axis('off')\n",
    "    plt.subplot(1,3,2)\n",
    "    plt.imshow(preds, cmap = 'seismic', vmin = 0, vmax=1)\n",
    "    #plt.colorbar()\n",
    "    plt.axis('off')\n",
    "    plt.subplot(1,3,3)\n",
    "    heatmap = np.copy(rgb) / 3000\n",
    "    heatmap[:,:,0] += preds\n",
    "    plt.imshow(heatmap, cmap = 'seismic', vmin = 0, vmax=1)\n",
    "    #plt.colorbar()\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return preds\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '../data'\n",
    "dates = list(positive_histories.keys())[:12]\n",
    "#site_names = ['bare_earth_4', 'tpa_babandem', 'city_7', 'tpa_bangli', 'tpa_biaung', 'tpa_mandung', 'tpa_jimbaran']\n",
    "preds = make_predictions('city_7', dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked = np.copy(preds)\n",
    "masked[masked < 0.9] = 0\n",
    "plt.figure(figsize=(10,10), dpi=150)\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(masked, cmap='seismic')\n",
    "#plt.colorbar()\n",
    "plt.axis('off')\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(preds, cmap='seismic')\n",
    "#plt.colorbar()\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '../data'\n",
    "dates = list(positive_histories.keys())[:12]\n",
    "#site_names = ['bare_earth_4', 'tpa_babandem', 'city_7', 'tpa_bangli', 'tpa_biaung', 'tpa_mandung', 'tpa_jimbaran']\n",
    "preds = make_predictions('tpa_babandem', dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked = np.copy(preds)\n",
    "masked[masked > 0.9] = 0\n",
    "plt.figure(figsize=(10,10), dpi=150)\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(masked, cmap='gray')\n",
    "#plt.colorbar()\n",
    "plt.axis('off')\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(preds, cmap='gray')\n",
    "#plt.colorbar()\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(negative_spectrograms.flatten(), 150, density=True);\n",
    "plt.hist(positive_spectrograms.flatten(), 150, density=True);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negatives = pd.DataFrame(np.median(city_spectrograms, axis=0), index=band_descriptions).transpose()\n",
    "negatives['band'] = band_descriptions\n",
    "negatives['class'] = ['negative'] * 12\n",
    "display(negatives)\n",
    "positives = pd.DataFrame(np.median(positive_spectrograms, axis=0), index=band_descriptions).transpose()\n",
    "positives['band'] = band_descriptions\n",
    "positives['class'] =  ['positive'] * 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "both = negatives.append(positives)\n",
    "both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = both.groupby(by=['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#both = negatives.append(positives).groupby(['band'])\n",
    "from matplotlib import cm\n",
    "plt.figure(figsize=(12,6))\n",
    "fig, ax = joypy.joyplot(both, by='band', colormap=cm.rainbow, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#both = negatives.append(positives).groupby(['band'])\n",
    "from matplotlib import cm\n",
    "fig, ax = joypy.joyplot(positives, colormap=cm.rainbow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negatives = pd.DataFrame(np.median(adjacent_spectrograms, axis=0).T, columns=band_descriptions)\n",
    "negatives['class'] = ['negative'] * 12\n",
    "positives = pd.DataFrame(np.median(positive_spectrograms, axis=0).T, columns=band_descriptions)\n",
    "positives['class'] =  ['positive'] * 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joypy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = joypy.joyplot(positives)\n",
    "plt.title('Distribution of Positive Samples')\n",
    "fig2, ax2 = joypy.joyplot(negatives)\n",
    "plt.title('Distribution of Negative Samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_joyplot(preds, labels, interval):\n",
    "    interval = interval\n",
    "    errors = []\n",
    "    timespan = []\n",
    "    error_colors = []\n",
    "    for time_val in range(0,int(np.max(labels)-interval), interval):\n",
    "        indexes = np.where((labels >= time_val) & (labels  < time_val + interval))\n",
    "        error = preds[indexes] - labels[indexes]\n",
    "        errors.append(error)\n",
    "        error_colors.append(np.median(error))\n",
    "        if time_val % 12 == 0:\n",
    "            timespan.append(str(time_val) + \" min\")\n",
    "        else: timespan.append(None)\n",
    "\n",
    "\n",
    "    orig_cmap = cm.RdYlBu\n",
    "    # Create a normalization scheme so that colorbar has correct legend\n",
    "    norm = plt.Normalize(np.min(error_colors), np.max(error_colors))\n",
    "    # Create a colormap based on avg error at each interval\n",
    "    error_cmap = ListedColormap(orig_cmap(norm(error_colors)))\n",
    "    # Create a color bar\n",
    "    sm = cm.ScalarMappable(cmap=orig_cmap, norm=norm)\n",
    "    sm.set_array([])\n",
    "\n",
    "    fig, axes = joypy.joyplot(errors, labels=timespan, x_range=[-30, 15], overlap=1, figsize=(6,5), colormap=error_cmap, title=\"Distribution of Error Grouped by Time to Eruption\", fade=False, linewidth=0.5,range_style='all', grid='x')\n",
    "    fig.colorbar(sm, ax=axes, label=\"Median Error (minutes)\")\n",
    "    plt.xlabel(\"Error (min)\")\n",
    "    ax = axes[-1]\n",
    "    ax.yaxis.set_label_position(\"left\")\n",
    "    ax.set_ylabel(\"Time until next eruption (min)\")\n",
    "    ax.yaxis.set_label_coords(-0.18,0.5)\n",
    "    ax.yaxis.set_ticks([])\n",
    "    ax.yaxis.set_visible(True)\n",
    "    plt.show()\n",
    "    fig.savefig(\"Distribution of Error by Time to Eruption.png\", dpi=300, bbox_inches='tight', pad_inches=0.1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

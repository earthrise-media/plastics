{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentinel 2A Plastic Waste Exploration\n",
    "A starting point for exploring multispectral data from Sentinel 2A for TPA sites in Indonesia.\n",
    "\n",
    "## Explorations:\n",
    "### [1. Patch Visualization](#Exploration-1)\n",
    "For each known plastic waste site, define a rect centered on the known coordinates. Additionally, define an adjacent rect as a control reference. For every rect, extract an image patch from every Sentinel image band and visualize. \n",
    "\n",
    "### [2. Patch Comparison](#Exploration-2)\n",
    "Using the extracted patches from Exploration #1, compare mean/median reflectance across bands between patches from waste sites and their corresponding control sites. In addition to site-by-site comparisons, aggregate these statistics across all sites to assess the trends.\n",
    "\n",
    "### [3. Temporal Monitoring](#Exploration-3)\n",
    "At each site, visualize how mean/median reflectance changes over time for each Sentinel imaging band.\n",
    "\n",
    "### [4. Spectral Signal Clustering](#Exploration-4)\n",
    "Compile the mean/median values computed at each site and time point in Exploration #3 into a multi-dimensional vector. Compress the dimensionality of the vectors using PCA or tSNE, and visualize whether waste and control sites form separable clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "from tqdm.notebook import tqdm\n",
    "from tqdm.contrib.concurrent import thread_map\n",
    "from functools import partial\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import ee\n",
    "import geemap\n",
    "import geemap.eefolium\n",
    "\n",
    "import folium\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ee.Authenticate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentinel 2 Cloud Filtering\n",
    "Uses the new S2 Cloud Probability dataset. [Details on the algorithm](https://medium.com/google-earth/more-accurate-and-flexible-cloud-masking-for-sentinel-2-images-766897a9ba5f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_s2_sr_cld_col(aoi, start_date, end_date):\n",
    "    \"\"\"\n",
    "    Creates an ImageCollection for a region and time period.\n",
    "    ImageCollection is prefiltered by the QA60 cloud mask band\n",
    "    Prefiltering percentage specified by global `CLOUD_FILTER` variable\n",
    "    \"\"\"\n",
    "    # Import and filter S2 SR.\n",
    "    s2_sr_col = (ee.ImageCollection('COPERNICUS/S2_SR')\n",
    "        .filterBounds(aoi)\n",
    "        .filterDate(start_date, end_date)\n",
    "        .filter(ee.Filter.lte('CLOUDY_PIXEL_PERCENTAGE', CLOUD_FILTER)))\n",
    "\n",
    "    # Import and filter s2cloudless.\n",
    "    s2_cloudless_col = (ee.ImageCollection('COPERNICUS/S2_CLOUD_PROBABILITY')\n",
    "        .filterBounds(aoi)\n",
    "        .filterDate(start_date, end_date))\n",
    "\n",
    "    # Join the filtered s2cloudless collection to the SR collection by the 'system:index' property.\n",
    "    return ee.ImageCollection(ee.Join.saveFirst('s2cloudless').apply(**{\n",
    "        'primary': s2_sr_col,\n",
    "        'secondary': s2_cloudless_col,\n",
    "        'condition': ee.Filter.equals(**{\n",
    "            'leftField': 'system:index',\n",
    "            'rightField': 'system:index'\n",
    "        })\n",
    "    }))\n",
    "\n",
    "def add_cloud_bands(img):\n",
    "    \"\"\"\n",
    "    From the s2_cloud_probability dataset, return an image with\n",
    "    cloud probabilities below the global `CLD_PRB_THRESH` variable\n",
    "    \"\"\"\n",
    "    # Get s2cloudless image, subset the probability band.\n",
    "    cld_prb = ee.Image(img.get('s2cloudless')).select('probability')\n",
    "\n",
    "    # Condition s2cloudless by the probability threshold value.\n",
    "    is_cloud = cld_prb.gt(CLD_PRB_THRESH).rename('clouds')\n",
    "\n",
    "    # Add the cloud probability layer and cloud mask as image bands.\n",
    "    return img.addBands(ee.Image([cld_prb, is_cloud]))\n",
    "\n",
    "def add_shadow_bands(img):\n",
    "    \"\"\"\n",
    "    Isolate cloud shadows over land\n",
    "    Cloud shadow thresholds are given by the global `NIR_DRK_THRESH` variable\n",
    "    CK Note: I don't think this algorithm works over water\n",
    "    \"\"\"\n",
    "    # Identify water pixels from the SCL band.\n",
    "    not_water = img.select('SCL').neq(6)\n",
    "\n",
    "    # Identify dark NIR pixels that are not water (potential cloud shadow pixels).\n",
    "    SR_BAND_SCALE = 1e4\n",
    "    dark_pixels = img.select('B8').lt(NIR_DRK_THRESH*SR_BAND_SCALE).multiply(not_water).rename('dark_pixels')\n",
    "\n",
    "    # Determine the direction to project cloud shadow from clouds (assumes UTM projection).\n",
    "    shadow_azimuth = ee.Number(90).subtract(ee.Number(img.get('MEAN_SOLAR_AZIMUTH_ANGLE')));\n",
    "\n",
    "    # Project shadows from clouds for the distance specified by the CLD_PRJ_DIST input.\n",
    "    cld_proj = (img.select('clouds').directionalDistanceTransform(shadow_azimuth, CLD_PRJ_DIST*10)\n",
    "        .reproject(**{'crs': img.select(0).projection(), 'scale': 100})\n",
    "        .select('distance')\n",
    "        .mask()\n",
    "        .rename('cloud_transform'))\n",
    "\n",
    "    # Identify the intersection of dark pixels with cloud shadow projection.\n",
    "    shadows = cld_proj.multiply(dark_pixels).rename('shadows')\n",
    "\n",
    "    # Add dark pixels, cloud projection, and identified shadows as image bands.\n",
    "    return img.addBands(ee.Image([dark_pixels, cld_proj, shadows]))\n",
    "\n",
    "def add_cld_shdw_mask(img):\n",
    "    \"\"\"\n",
    "    Create a mask based on the cloud and cloud shadow images\n",
    "    \"\"\"\n",
    "    # Add cloud component bands.\n",
    "    img_cloud = add_cloud_bands(img)\n",
    "\n",
    "    # Add cloud shadow component bands.\n",
    "    img_cloud_shadow = add_shadow_bands(img_cloud)\n",
    "\n",
    "    # Combine cloud and shadow mask, set cloud and shadow as value 1, else 0.\n",
    "    is_cld_shdw = img_cloud_shadow.select('clouds').add(img_cloud_shadow.select('shadows')).gt(0)\n",
    "\n",
    "    # Remove small cloud-shadow patches and dilate remaining pixels by BUFFER input.\n",
    "    # 20 m scale is for speed, and assumes clouds don't require 10 m precision.\n",
    "    is_cld_shdw = (is_cld_shdw.focal_min(2).focal_max(BUFFER*2/20)\n",
    "        .reproject(**{'crs': img.select([0]).projection(), 'scale': 20})\n",
    "        .rename('cloudmask'))\n",
    "\n",
    "    # Add the final cloud-shadow mask to the image.\n",
    "    return img_cloud_shadow.addBands(is_cld_shdw)\n",
    "\n",
    "def apply_cld_shdw_mask(img):\n",
    "    \"\"\"\n",
    "    Apply the cloud mask to the all Sentinel bands beginning with `B`\n",
    "    \"\"\"\n",
    "    # Subset the cloudmask band and invert it so clouds/shadow are 0, else 1.\n",
    "    not_cld_shdw = img.select('cloudmask').Not()\n",
    "\n",
    "    # Subset reflectance bands and update their masks, return the result.\n",
    "    return img.select('B.*').updateMask(not_cld_shdw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '../data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLOUD_FILTER = 30\n",
    "CLD_PRB_THRESH = 60\n",
    "NIR_DRK_THRESH = 0.15\n",
    "CLD_PRJ_DIST = 1\n",
    "BUFFER = 50\n",
    "DATASET = 'COPERNICUS/S2_SR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tpa_points dataset and create a list of coordinates for the known sites\n",
    "\n",
    "with open(os.path.join(DATA_DIR, 'tpa_points.json')) as f:\n",
    "    tpa_points = json.load(f)\n",
    "    f.close()\n",
    "\n",
    "tpa_sites = pd.DataFrame({\n",
    "    'name': [site['properties']['Name'] for site in tpa_points['features']],\n",
    "    'lon': [site['geometry']['coordinates'][0] for site in tpa_points['features']],\n",
    "    'lat': [site['geometry']['coordinates'][1] for site in tpa_points['features']],\n",
    "    'area': [site['properties']['Surface_Ha'] for site in tpa_points['features']],\n",
    "    'daily_volume': [site['properties']['TOT_Kg/Day'] for site in tpa_points['features']],\n",
    "    'coords': [site['geometry']['coordinates'] for site in tpa_points['features']]\n",
    "})\n",
    "\n",
    "\n",
    "display(tpa_sites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load bare_earth_points dataset and create a list of coordinates for the known sites\n",
    "\n",
    "with open(os.path.join(DATA_DIR, 'bare_earth_points.json')) as f:\n",
    "    bare_earth_sites = json.load(f)\n",
    "    f.close()\n",
    "\n",
    "bare_earth_sites = pd.DataFrame({\n",
    "    'name': ['bare_earth_' + str(index) for index in range(len(bare_earth_sites['features']))],\n",
    "    'lon': [site['geometry']['coordinates'][0] for site in bare_earth_sites['features']],\n",
    "    'lat': [site['geometry']['coordinates'][1] for site in bare_earth_sites['features']],\n",
    "    'coords': [site['geometry']['coordinates'][0:2] for site in bare_earth_sites['features']],\n",
    "})\n",
    "bare_earth_sites.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load city_points dataset and create a list of coordinates for the known sites\n",
    "\n",
    "with open(os.path.join(DATA_DIR, 'city_points.json')) as f:\n",
    "    city_sites = json.load(f)\n",
    "    f.close()\n",
    "\n",
    "city_sites = pd.DataFrame({\n",
    "    'name': ['city_' + str(index) for index in range(len(city_sites['features']))],\n",
    "    'lon': [site['geometry']['coordinates'][0] for site in city_sites['features']],\n",
    "    'lat': [site['geometry']['coordinates'][1] for site in city_sites['features']],\n",
    "    'coords': [site['geometry']['coordinates'][0:2] for site in city_sites['features']],\n",
    "})\n",
    "city_sites.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentinel 2 band descriptions\n",
    "band_descriptions = {\n",
    "    'B1': 'Aerosols, 442nm',\n",
    "    'B2': 'Blue, 492nm',\n",
    "    'B3': 'Green, 559nm',\n",
    "    'B4': 'Red, 665nm',\n",
    "    'B5': 'Red Edge 1, 704nm',\n",
    "    'B6': 'Red Edge 2, 739nm',\n",
    "    'B7': 'Red Edge 3, 779nm',\n",
    "    'B8': 'NIR, 833nm',\n",
    "    'B8A': 'Red Edge 4, 864nm',\n",
    "    'B9': 'Water Vapor, 943nm',\n",
    "    'B11': 'SWIR 1, 1610nm',\n",
    "    'B12': 'SWIR 2, 2186nm'\n",
    "}\n",
    "\n",
    "band_wavelengths = [442, 492, 559, 665, 704, 739, 779, 833, 864, 943, 1610, 2186]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Cloud-Filtered Imagery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bali_rect = ee.Geometry.Polygon([[116, -8],\n",
    "                    [116, -9],\n",
    "                    [114, -9],\n",
    "                    [114, -8]], None, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2_data = get_s2_sr_cld_col(bali_rect, '2019-06-01', '2019-07-01')\n",
    "s2_sr_median = s2_data.filterBounds(bali_rect) \\\n",
    "                    .map(add_cld_shdw_mask) \\\n",
    "                    .map(apply_cld_shdw_mask) \\\n",
    "                    .median() \\\n",
    "                    .clip(bali_rect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Define visualization parameters\n",
    "vizParams = {'bands': ['B4', 'B3', 'B2'],\n",
    "             'min': 0, 'max': 3000}\n",
    "\n",
    "Map = geemap.eefolium.Map(center=[-8.4, 115.1], zoom=10)\n",
    "tpa_poly_path = os.path.join(DATA_DIR, 'tpa_polygons', 'tpa_polygons.shp')\n",
    "tpa_polygons = geemap.shp_to_ee(tpa_poly_path)\n",
    "Map.addLayer(s2_sr_median.clipToCollection(tpa_sites['polygons'].iloc[0]), vizParams, 'Sentinel 2 Image')\n",
    "\n",
    "# Add the sites of interest as yellow dots\n",
    "for i in range(len(tpa_sites)):\n",
    "    site = tpa_sites.iloc[i]\n",
    "    roi = create_rect(site['lon'], site['lat'], 0.02)\n",
    "    Map.addLayer(roi)\n",
    "    description = f\"{site['name']}<br>Size: {site['area']:.1f} Ha<br>Volume: {site['daily_volume'] / 1000:.0f} Tonnes/day\"\n",
    "    folium.CircleMarker([site['lat'], site['lon']], \n",
    "                        fill=True, \n",
    "                        radius=3,\n",
    "                        color='#FFCE00',\n",
    "                        fll_opacity=1,\n",
    "                        tooltip=description).add_to(Map)\n",
    "\n",
    "display(Map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geemap.zonal_statistics(s2_sr_median, tpa_polygons, 'test.csv', statistics_type='MEAN', scale=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration 1\n",
    "### Patch Extraction and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rect(lon, lat, width):\n",
    "    \"\"\"\n",
    "    Given a set of coordinates, create an earth engine rect of a fixed width/height\n",
    "    \"\"\"\n",
    "    extent = width / 2\n",
    "    rect = ee.Geometry.Polygon([[lon + extent, lat + extent],\n",
    "                                [lon + extent, lat - extent],\n",
    "                                [lon - extent, lat - extent],\n",
    "                                [lon - extent, lat + extent]], None, False)\n",
    "    return rect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the rect width in degrees\n",
    "# NOTE: I realize that degrees -> meters differs for lat/lon\n",
    "# This shouldn't matter, but it's good to keep in mind\n",
    "RECT_WIDTH = 0.002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(tpa_sites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of sites that are adjacent to the patches with dumps. \n",
    "# This should keep the distribution the same while isolating dump-specific factors\n",
    "# could do multiple offset directions and distances. For now, only selecting one\n",
    "\n",
    "offset = 2 * RECT_WIDTH\n",
    "\n",
    "control_sites = pd.DataFrame({\n",
    "    'name': [name + \" Control\" for name in tpa_sites['name']],\n",
    "    'lon': [lon + offset for lon in tpa_sites['lon']],\n",
    "    'lat': [lat for lat in tpa_sites['lat']],\n",
    "    'coords': [[lon + offset, lat] for lon, lat in zip(tpa_sites['lon'], tpa_sites['lat'])]\n",
    "})\n",
    "\n",
    "display(control_sites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_sites = bare_earth_sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpa_sites['polygons'].iloc[0].get('geometry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing.dummy import Pool as ThreadPool\n",
    "\n",
    "def get_sentinel_band(site_name, roi, output_dict, image, band):\n",
    "    band_img = image.select(band).clipToBoundsAndScale(roi, scale=10)\n",
    "    #band_img = image.select(band).clipToCollection(roi)\n",
    "    image_array = geemap.ee_to_numpy(band_img, region=roi, default_value=-999)\n",
    "    patch = np.squeeze(image_array)\n",
    "    if patch.all() != None:\n",
    "        output_dict[band] = np.squeeze(image_array)\n",
    "    else:\n",
    "        output_dict[band] = []\n",
    "    return patch\n",
    "\n",
    "def get_patches(site_names, site_coords, rect_width, image):\n",
    "    \"\"\"\n",
    "    Multithreaded process to export Sentinel 2 patches as numpy arrays.\n",
    "    Input lists of site names and site coordinates along with an Earth Engine image.\n",
    "    Exports each band in image to a dictionary organized by [site name][band][band_img]\n",
    "    \"\"\"\n",
    "    patch_dict = {}\n",
    "    for name, site in zip(site_names, site_coords):\n",
    "        print(\"Processing\", name)\n",
    "        pool = ThreadPool(12)\n",
    "        roi = create_rect(site[0], site[1], rect_width)\n",
    "        images = {}\n",
    "        bands = list(band_descriptions.keys())\n",
    "        get_sentinel_partial = partial(get_sentinel_band, \n",
    "                                       name, \n",
    "                                       roi, \n",
    "                                       images,\n",
    "                                       image)\n",
    "        pool.map(get_sentinel_partial, bands)\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "        patch_dict[name] = images\n",
    "    return patch_dict\n",
    "\n",
    "def get_tpa_patches(site_names, polygons, image):\n",
    "    \"\"\"\n",
    "    Multithreaded process to export Sentinel 2 patches as numpy arrays.\n",
    "    Input lists of site names and site coordinates along with an Earth Engine image.\n",
    "    Exports each band in image to a dictionary organized by [site name][band][band_img]\n",
    "    \"\"\"\n",
    "    patch_dict = {}\n",
    "    for name, roi in zip(site_names, polygons):\n",
    "        print(\"Processing\", name)\n",
    "        pool = ThreadPool(12)\n",
    "        images = {}\n",
    "        bands = list(band_descriptions.keys())\n",
    "        get_sentinel_partial = partial(get_sentinel_band, \n",
    "                                       name, \n",
    "                                       roi, \n",
    "                                       images,\n",
    "                                       image)\n",
    "        pool.map(get_sentinel_partial, bands)\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "        patch_dict[name] = images\n",
    "    return patch_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clipped_tpa = get_tpa_patches(tpa_sites['name'], \n",
    "                              tpa_sites['polygons'],\n",
    "                              s2_sr_median)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract image patches to numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = '2019-01-01'\n",
    "end = '2019-11-01'\n",
    "s2_data = get_s2_sr_cld_col(bali_rect, start, end)\n",
    "s2_sr_median = s2_data.filterBounds(bali_rect) \\\n",
    "                    .map(add_cld_shdw_mask) \\\n",
    "                    .map(apply_cld_shdw_mask) \\\n",
    "                    .median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(DATA_DIR, 'tpa_polygons', 'tpa_polygons.json'), 'r') as f:\n",
    "    json_tpa = json.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpa_polygons = [ee.FeatureCollection([element]) for element in list(json_tpa['features'])]\n",
    "tpa_sites['polygons'] = tpa_polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clipped_tpa = get_tpa_patches(tpa_sites['name'], \n",
    "                          tpa_sites['polygons'], \n",
    "                          s2_sr_median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for name in clipped_tpa:\n",
    "    image = clipped_tpa[name]['B3']\n",
    "    plt.imshow((image - np.min(image)) / (np.max(image) - np.min(image)), cmap='gray')\n",
    "    plt.title(name)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "control_patches = get_patches(control_sites['name'], control_sites['coords'], RECT_WIDTH, s2_sr_median)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_patches(image_dict, output_dir):\n",
    "    for site in image_dict:\n",
    "        plt.figure(figsize=(10,8), dpi=100, facecolor='white')\n",
    "        start_date = start\n",
    "        finish_date = end\n",
    "        plt.suptitle(f\"{site}: {start_date} - {finish_date}\", y=0.95, size=16)\n",
    "        for index, band in enumerate(band_descriptions):\n",
    "            plt.subplot(4, 4, index + 1)\n",
    "            plt.title(f\"{band} - {band_descriptions[band]}\")\n",
    "            plt.imshow(image_dict[site][band], cmap='gray')\n",
    "            plt.axis('off')\n",
    "\n",
    "        plt.subplot(4, 4, 13)\n",
    "        rgb = np.moveaxis([image_dict[site]['B4'], image_dict[site]['B3'], image_dict[site]['B2']], 0, -1)\n",
    "        rgb /= np.max(rgb).astype('float')\n",
    "        plt.title(\"RGB\")\n",
    "        plt.imshow(rgb)\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(4, 4, 14)\n",
    "        ndvi = (np.array(image_dict[site]['B8']) - np.array(image_dict[site]['B4'])) / \\\n",
    "                (np.array(image_dict[site]['B8']) + np.array(image_dict[site]['B4']))\n",
    "        plt.title(\"NDVI\")\n",
    "        plt.imshow(ndvi, cmap='gray')\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(4, 4, 15)\n",
    "        ndwi = (np.array(image_dict[site]['B8']) - np.array(image_dict[site]['B11'])) / \\\n",
    "                (np.array(image_dict[site]['B8']) + np.array(image_dict[site]['B11']))\n",
    "        plt.title(\"NDWI\")\n",
    "        plt.imshow(ndwi, cmap='gray')\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(4, 4, 16)\n",
    "        composite = np.moveaxis([image_dict[site]['B11'], image_dict[site]['B8'], image_dict[site]['B4']], 0, -1)\n",
    "        composite /= np.max(composite)\n",
    "        plt.title(\"Vegetation (B11, B8, B4)\")\n",
    "        plt.imshow(composite)\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "        plt.savefig(os.path.join(output_dir, f\"{site} Patches - Rect Width {RECT_WIDTH}.png\"))\n",
    "        plt.close()\n",
    "        #plt.show()\n",
    "        #print('\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot Patches\n",
    "output_dir = './figures/patches'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.mkdir(output_dir)\n",
    "\n",
    "plot_patches(clipped_tpa, output_dir)\n",
    "#plot_patches(control_patches, output_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration 2\n",
    "### Compare patch reflectance between TPA and control sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_stats(image_dict):\n",
    "    stats = {}\n",
    "    for band in list(band_descriptions):\n",
    "        mean_values = [np.mean(image_dict[location][band]) for location in image_dict]\n",
    "        stats[band] = {\n",
    "            'mean': np.mean(mean_values),\n",
    "            'median': np.median(mean_values),\n",
    "            'std': np.std(mean_values)\n",
    "        } \n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpa_stats = compute_stats(clipped_tpa)\n",
    "control_stats = compute_stats(control_patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output_dir = './figures/reflectance'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.mkdir(output_dir)\n",
    "\n",
    "plt.figure(figsize=(14,4), dpi=100, facecolor=(1,1,1))\n",
    "plt.errorbar(band_wavelengths, \n",
    "             [tpa_stats[band]['mean'] for band in tpa_stats],\n",
    "             [tpa_stats[band]['std'] for band in tpa_stats],\n",
    "             fmt='o-', capsize=3, label='TPA Mean')\n",
    "\n",
    "plt.errorbar(band_wavelengths, \n",
    "             [control_stats[band]['mean'] for band in control_stats], \n",
    "             [control_stats[band]['std'] for band in control_stats], \n",
    "             fmt='o-', capsize=3, c='r', label='Bare Earth Mean')\n",
    "\n",
    "#plt.plot([tpa_stats[band]['median'] for band in tpa_stats], label='TPA Median')\n",
    "#plt.plot([control_stats[band]['median'] for band in control_stats], c='r', label='Control Median')\n",
    "plt.xticks(band_wavelengths, list(tpa_stats), rotation=45, ha='right')\n",
    "plt.grid()\n",
    "plt.xlabel('Band Wavelength')\n",
    "plt.ylabel('Mean Patch Reflectance')\n",
    "plt.ylim([200, 3750])\n",
    "plt.legend()\n",
    "plt.title(f\"TPA Sites vs. Bare Earth Sites - Mean Reflectance - {start} - {end}\\nErrorbars: 1 SD\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_dir, f\"TPA Sites vs. Bare Earth Sites - Mean Reflectance - {start} - {end}.png\"))\n",
    "plt.show()\n",
    "\n",
    "fig = plt.subplots(len(tpa_patches), 2, figsize=(10,3 * len(tpa_patches)), dpi=100, facecolor=(1,1,1))\n",
    "grid = gridspec.GridSpec(len(tpa_patches), 2, width_ratios=[5, 1])\n",
    "for index, (tpa_site, control_site) in enumerate(zip(tpa_patches, control_patches)):\n",
    "    tpa_mean = []\n",
    "    tpa_std = []\n",
    "    control_mean = []\n",
    "    control_std = []\n",
    "    for band in list(band_descriptions):\n",
    "        tpa_mean.append(np.mean(tpa_patches[tpa_site][band]))\n",
    "        tpa_std.append(np.std(tpa_patches[tpa_site][band]))\n",
    "        control_mean.append(np.mean(control_patches[control_site][band]))\n",
    "        control_std.append(np.std(control_patches[control_site][band]))\n",
    "    ax0 = plt.subplot(grid[index, 0])\n",
    "    ax0.errorbar(band_wavelengths, tpa_mean, tpa_std, fmt='o-', capsize=3, label='TPA')\n",
    "    ax0.errorbar(band_wavelengths, control_mean, control_std, fmt='o-', c='r', capsize=3, label='Bare Earth')\n",
    "    ax0.legend()\n",
    "    ax0.set_xticks(band_wavelengths)\n",
    "    ax0.set_xticklabels(list(tpa_stats), rotation=45, ha='right')\n",
    "    ax0.set_title(f\"Mean Value by Site\\n{tpa_site} vs. {control_site}\")\n",
    "    ax0.grid()\n",
    "\n",
    "    ax1 = plt.subplot(grid[index, 1])\n",
    "    ax1.bar([0], [np.mean(tpa_mean[6:10]) - np.mean(tpa_mean[:4])])\n",
    "    ax1.bar([1], [np.mean(control_mean[6:10]) - np.mean(control_mean[:4])], color='r')\n",
    "    ax1.set_title(\"∆ of Bands 7-9 and Bands 1-4\")\n",
    "    ax1.set_xticks([0, 1])\n",
    "    ax1.set_xticklabels(['TPA Site', 'Control Site'], rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.suptitle(f\"Reflectance by Site - {start} - {end}\", size=18, y=1.01)\n",
    "plt.savefig(os.path.join(output_dir, f\"Reflectance by Site - Bare Earth - {start} - {end}.png\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration 3\n",
    "### Temporal Monitoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile a dictionary of patches across a time period\n",
    "History dictionary structure: `{dates: {sites: {bands: patch}`\n",
    "\n",
    "Note: I can't access Sentinel data older than 2019 using earth engine. I'm not sure why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpa_history = {}\n",
    "control_history = {}\n",
    "\n",
    "start = '2019-01-01'\n",
    "num_months = 22\n",
    "\n",
    "date = ee.Date(start)\n",
    "for month in tqdm(range(num_months)):\n",
    "    s2_data = get_s2_sr_cld_col(bali_rect, date, date.advance(1, 'month'))\n",
    "    s2_sr_median = s2_data.filterBounds(bali_rect) \\\n",
    "                        .map(add_cld_shdw_mask) \\\n",
    "                        .map(apply_cld_shdw_mask) \\\n",
    "                        .median() \\\n",
    "                        .clip(bali_rect)\n",
    "\n",
    "    tpa_patches = get_patches(tpa_sites['name'], tpa_sites['coords'], RECT_WIDTH, s2_sr_median)\n",
    "    control_patches = get_patches(control_sites['name'], control_sites['coords'], RECT_WIDTH, s2_sr_median)\n",
    "    \n",
    "    date_text = str(datetime.fromtimestamp(date.getInfo()['value'] // 1000 + 86400).date())\n",
    "    tpa_history[date_text] = tpa_patches\n",
    "    control_history[date_text] = control_patches\n",
    "    \n",
    "    date = date.advance(1, 'month')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize time series by site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output_dir = './figures/time_series'\n",
    "if not os.path.exists(output_dir):\n",
    "        os.mkdir(output_dir)\n",
    "\n",
    "for tpa_site, control_site in zip(tpa_sites['name'], control_sites['name']):\n",
    "    plt.figure(figsize=(12,12), dpi=100, facecolor=(1,1,1))\n",
    "    for index, band in enumerate(band_descriptions):\n",
    "        tpa_means = []\n",
    "        control_means = []\n",
    "        for month in tpa_history.keys():\n",
    "            if len(tpa_history[month][tpa_site][band]) > 0:\n",
    "                tpa_means.append(np.mean(tpa_history[month][tpa_site][band]))\n",
    "            else: \n",
    "                tpa_means.append(None)\n",
    "                \n",
    "            if len(control_history[month][control_site][band]) > 0:\n",
    "                control_means.append(np.mean(control_history[month][control_site][band]))\n",
    "            else: \n",
    "                control_means.append(None)\n",
    "            \n",
    "        plt.subplot(4, 3, index + 1)\n",
    "        plt.plot(list(tpa_history.keys()), tpa_means, '-o', label='TPA Site')\n",
    "        plt.plot(list(control_history.keys()), control_means, '-o', c='r', label='Control Site')\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.ylim([0, 4500])\n",
    "        plt.legend()\n",
    "        plt.title(f'Band {band}')\n",
    "    plt.tight_layout()\n",
    "    plt.suptitle(tpa_site, y=1.02, size=16)\n",
    "    plt.savefig(os.path.join(output_dir, f'{tpa_site} time series.png'), bbox_inches='tight')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration 4\n",
    "### Spectral Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each site, compile a vector of mean band reflectance values for each month in the record from Exploration #3. Reduce dimensionality of each point from the number of bands to 2 using PCA and plot the 2D points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = './figures/clustering'\n",
    "if not os.path.exists(output_dir):\n",
    "        os.mkdir(output_dir)\n",
    "\n",
    "all_tpa_vectors = []\n",
    "all_control_vectors = []\n",
    "for tpa_site, control_site in zip(tpa_sites['name'], control_sites['name']):\n",
    "    tpa_site_vectors = []\n",
    "    control_site_vectors = []\n",
    "    for month in tpa_history.keys():\n",
    "        tpa_means = []\n",
    "        control_means = []\n",
    "        for index, band in enumerate(band_descriptions):\n",
    "            if len(tpa_history[month][tpa_site][band]) > 0:\n",
    "                tpa_means.append(np.mean(tpa_history[month][tpa_site][band]))\n",
    "            if len(control_history[month][control_site][band]) > 0:\n",
    "                control_means.append(np.mean(control_history[month][control_site][band]))\n",
    "                \n",
    "        if len(tpa_means) > 0:\n",
    "            tpa_site_vectors.append(tpa_means)\n",
    "            all_tpa_vectors.append(tpa_means)\n",
    "        if len(control_means) > 0:\n",
    "            control_site_vectors.append(control_means)\n",
    "            all_control_vectors.append(control_means)\n",
    "    \n",
    "    pca = PCA(n_components=2)\n",
    "    pca.fit(tpa_site_vectors)\n",
    "    tpa_pca = pca.transform(tpa_site_vectors)\n",
    "    control_pca = pca.transform(control_site_vectors)\n",
    "    plt.figure(figsize=(8,5), dpi=100)\n",
    "    plt.scatter(tpa_pca[:,0], tpa_pca[:,1], label='TPA')\n",
    "    plt.scatter(control_pca[:,0], control_pca[:,1], c='r', label='Control')\n",
    "    plt.title(tpa_site)\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(output_dir, f\"{tpa_site} reflectance scatter PCA.png\"))\n",
    "    plt.close()\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(all_tpa_vectors)\n",
    "tpa_pca = pca.transform(all_tpa_vectors)\n",
    "control_pca = pca.transform(all_control_vectors)\n",
    "\n",
    "plt.figure(figsize=(8,5), dpi=100)\n",
    "plt.scatter(tpa_pca[:,0], tpa_pca[:,1], label='TPA')\n",
    "plt.scatter(control_pca[:,0], control_pca[:,1], c='r', label='Control')\n",
    "plt.legend()\n",
    "plt.title('All Sites')\n",
    "plt.savefig(os.path.join(output_dir, f\"All sites reflectance scatter PCA.png\"))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.animation as animation\n",
    "\n",
    "for tpa_site, control_site in zip(tpa_sites['name'], control_sites['name']):\n",
    "    fig, ax = plt.subplots(dpi=100, facecolor=(1,1,1))\n",
    "    ax.set_axis_off()\n",
    "    ax.set_title(f\"{tpa_site}\\nLeft: TPA, Right: Control\")\n",
    "    fig.tight_layout()\n",
    "    images = []\n",
    "    for date in control_history:\n",
    "        data_control = control_history[date][control_site]\n",
    "        rgb_control = np.array([data_control['B4'], data_control['B3'], data_control['B2']])\n",
    "        rgb_control = np.moveaxis(rgb_control, 0, -1)\n",
    "        \n",
    "        data_tpa = tpa_history[date][tpa_site]\n",
    "        rgb_tpa = np.array([data_tpa['B4'], data_tpa['B3'], data_tpa['B2']])\n",
    "        rgb_tpa = np.moveaxis(rgb_tpa, 0, -1)\n",
    "        if len(rgb_tpa) > 0 and len(rgb_control) > 0:\n",
    "            combined = np.concatenate((rgb_tpa, np.ones((len(rgb_tpa), 1,3)) * 3000, rgb_control), axis=1)\n",
    "        \n",
    "            im = plt.imshow(combined / 3000, animated=True)\n",
    "            images.append([im])\n",
    "\n",
    "    ani = animation.ArtistAnimation(fig, images, interval=120, blit=True, repeat_delay=500)\n",
    "    ani.save(os.path.join('figures', 'videos', '22-months_both_' + tpa_site + '.gif'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output_dir = './figures/clustering'\n",
    "if not os.path.exists(output_dir):\n",
    "        os.mkdir(output_dir)\n",
    "\n",
    "tpa_pixel_vectors = []\n",
    "control_pixel_vectors = []\n",
    "for tpa_site, control_site in zip(tpa_sites['name'], control_sites['name']):\n",
    "    tpa_site_vectors = []\n",
    "    control_site_vectors = []\n",
    "    for month in tpa_history.keys():\n",
    "        if np.shape(tpa_history[month][tpa_site]['B2']) != (0,):\n",
    "            width, height = np.shape(tpa_history[month][tpa_site]['B2'])\n",
    "            for i in range(width):\n",
    "                for j in range(height):\n",
    "                    pixel_vector = []\n",
    "                    for band in band_descriptions:\n",
    "                        pixel_vector.append(tpa_history[month][tpa_site][band][i][j])\n",
    "                    tpa_site_vectors.append(pixel_vector)\n",
    "                    tpa_pixel_vectors.append(pixel_vector)\n",
    "    \n",
    "    for month in control_history.keys():\n",
    "        if np.shape(control_history[month][control_site]['B2']) != (0,):\n",
    "            width, height = np.shape(control_history[month][control_site]['B2'])\n",
    "            for i in range(width):\n",
    "                for j in range(height):\n",
    "                    pixel_vector = []\n",
    "                    for band in band_descriptions:\n",
    "                        pixel_vector.append(control_history[month][control_site][band][i][j])\n",
    "                    control_site_vectors.append(pixel_vector)\n",
    "                    control_pixel_vectors.append(pixel_vector)\n",
    "    \n",
    "    pca = PCA(n_components=2)\n",
    "    pca.fit(np.concatenate((tpa_site_vectors, control_site_vectors)))\n",
    "    tpa_pca = pca.transform(tpa_site_vectors)\n",
    "    control_pca = pca.transform(control_site_vectors)\n",
    "    plt.figure(figsize=(8,5), dpi=100, facecolor=(1,1,1))\n",
    "    plt.scatter(tpa_pca[:,0], tpa_pca[:,1], s=0.5, alpha=0.5, label='TPA')\n",
    "    plt.scatter(control_pca[:,0], control_pca[:,1], c='r', s=0.5, alpha=0.5, label='Control')\n",
    "    plt.title(tpa_site)\n",
    "    plt.axis('off')\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(output_dir, f\"{tpa_site} per-pixel reflectance scatter PCA.png\"))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "for tpa_site, control_site in zip(tpa_sites['name'], control_sites['name']):\n",
    "    tpa_site_vectors = []\n",
    "    control_site_vectors = []\n",
    "    for month in tpa_history.keys():\n",
    "        if np.shape(tpa_history[month][tpa_site]['B2']) != (0,):\n",
    "            width, height = np.shape(tpa_history[month][tpa_site]['B2'])\n",
    "            for i in range(width):\n",
    "                for j in range(height):\n",
    "                    pixel_vector = []\n",
    "                    for band in band_descriptions:\n",
    "                        pixel_vector.append(tpa_history[month][tpa_site][band][i][j])\n",
    "                    tpa_site_vectors.append(pixel_vector)\n",
    "    \n",
    "    for month in control_history.keys():\n",
    "        if np.shape(control_history[month][control_site]['B2']) != (0,):\n",
    "            width, height = np.shape(control_history[month][control_site]['B2'])\n",
    "            for i in range(width):\n",
    "                for j in range(height):\n",
    "                    pixel_vector = []\n",
    "                    for band in band_descriptions:\n",
    "                        pixel_vector.append(control_history[month][control_site][band][i][j])\n",
    "                    control_site_vectors.append(pixel_vector)\n",
    "    \n",
    "    tsne = TSNE(n_components=2)\n",
    "    embedded = tsne.fit_transform(np.concatenate((tpa_site_vectors, control_site_vectors)))\n",
    "    #tpa_pca = tsne.transform(tpa_site_vectors)\n",
    "    #control_pca = tsne.transform(control_site_vectors)\n",
    "    plt.figure(figsize=(8,5), dpi=100, facecolor=(1,1,1))\n",
    "    plt.scatter(embedded[:len(tpa_site_vectors),0], embedded[:len(tpa_site_vectors),1], s=1, alpha=0.5, label='TPA')\n",
    "    plt.scatter(embedded[len(tpa_site_vectors):,0], embedded[len(tpa_site_vectors):,1], s=1, alpha=0.5, c='r', label='Control')\n",
    "    plt.title(tpa_site)\n",
    "    plt.legend()\n",
    "    plt.axis('off')\n",
    "    plt.savefig(os.path.join(output_dir, f\"{tpa_site} per-pixel reflectance scatter tSNE.png\"))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = np.concatenate((control_pixel_vectors, tpa_pixel_vectors))\n",
    "y = np.concatenate((np.zeros(len(control_pixel_vectors)), np.ones(len(tpa_pixel_vectors))))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "clf = tree.DecisionTreeClassifier(max_leaf_nodes=32, max_depth=8)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "print(\"Accuracy:\", clf.score(X_test, y_test))\n",
    "print(\"Feature Importances:\")\n",
    "for band, importance in zip(band_descriptions, clf.feature_importances_):\n",
    "    print(f\"{band}: {importance:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "site = tpa_sites['name'][1]\n",
    "data_source = tpa_history\n",
    "month = list(data_source.keys())[4]\n",
    "for index, month in enumerate(data_source.keys()):\n",
    "    if np.shape(data_source[month][site]['B2']) != (0,):\n",
    "        width, height = np.shape(data_source[month][site]['B2'])\n",
    "        classification = np.zeros((width, height))\n",
    "        data = data_source[month][site]\n",
    "        rgb = np.array([data['B4'], data['B3'], data['B2']])\n",
    "        rgb = np.moveaxis(rgb, 0, -1)\n",
    "        for i in range(width):\n",
    "            for j in range(height):\n",
    "                pixel_vector = []\n",
    "                for band in band_descriptions:\n",
    "                    pixel_vector.append(data_source[month][site][band][i][j])\n",
    "                classification[i,j] = clf.predict([pixel_vector])\n",
    "        plt.figure(dpi=150, facecolor=(1,1,1))\n",
    "        plt.subplot(1,2,1)\n",
    "        plt.imshow(rgb / 3000)\n",
    "        plt.title(site)\n",
    "        plt.axis('off')\n",
    "        plt.subplot(1,2,2)\n",
    "        plt.imshow(classification, cmap='seismic')\n",
    "        plt.axis('off')\n",
    "        plt.title(month)\n",
    "\n",
    "    else:\n",
    "        print(\"No data found for\", month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = np.concatenate((all_control_vectors, all_tpa_vectors))\n",
    "y = np.concatenate((np.zeros(len(all_control_vectors)), np.ones(len(all_tpa_vectors))))\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "clf = tree.DecisionTreeClassifier(max_leaf_nodes=32, max_depth=8)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "print(\"Accuracy:\", clf.score(X_test, y_test))\n",
    "print(\"Feature Importances:\")\n",
    "for band, importance in zip(band_descriptions, clf.feature_importances_):\n",
    "    print(f\"{band}: {importance:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "output_dir = './figures/tree_classification'\n",
    "if not os.path.exists(output_dir):\n",
    "        os.mkdir(output_dir)\n",
    "\n",
    "data_source = tpa_history\n",
    "plt.figure(dpi=100, facecolor=(1,1,1), figsize=(20,4))\n",
    "for index, site in enumerate(tpa_sites['name']):\n",
    "    classification_images = []\n",
    "    rgb_images = []\n",
    "    for month in data_source.keys():\n",
    "        if np.shape(data_source[month][site]['B2']) != (0,):\n",
    "            width, height = np.shape(data_source[month][site]['B2'])\n",
    "            classification = np.zeros((width, height))\n",
    "            data = data_source[month][site]\n",
    "            rgb = np.array([data['B4'], data['B3'], data['B2']])\n",
    "            rgb = np.moveaxis(rgb, 0, -1)\n",
    "            for i in range(width):\n",
    "                for j in range(height):\n",
    "                    pixel_vector = []\n",
    "                    for band in band_descriptions:\n",
    "                        pixel_vector.append(data_source[month][site][band][i][j])\n",
    "                    classification[i,j] = clf.predict([pixel_vector])\n",
    "            classification_images.append(classification)\n",
    "            rgb_images.append(rgb)\n",
    "    plt.subplot(2,10,2*index + 1)\n",
    "    plt.imshow(np.median(rgb_images, axis=0) / 3000)\n",
    "    plt.axis('off')\n",
    "    plt.title(site, size=8)\n",
    "    plt.subplot(2,10,2*index + 2)\n",
    "    im = plt.imshow(np.mean(classification_images, axis=0), cmap='seismic', vmin=0, vmax=1)\n",
    "    plt.axis('off')\n",
    "    plt.title('Classification', size=8)\n",
    "    plt.colorbar(im,fraction=0.045, pad=0.02, ticks=[0, 1])\n",
    "\n",
    "plt.suptitle('TPA Patches')\n",
    "plt.tight_layout()\n",
    "#plt.savefig(os.path.join(output_dir, f\"Control Site Decision Tree Classification.png\"), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(1,2,1)\n",
    "plt.imshow(np.median(rgb_images, axis=0) / 3000)\n",
    "plt.imshow(np.mean(classification_images, axis=0), alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = './figures/clustering'\n",
    "if not os.path.exists(output_dir):\n",
    "        os.mkdir(output_dir)\n",
    "\n",
    "all_tpa_vectors = []\n",
    "all_control_vectors = []\n",
    "for tpa_site in tpa_sites['name']:\n",
    "    tpa_site_vectors = []\n",
    "    for month in tpa_history.keys():\n",
    "        tpa_means = []\n",
    "        for index, band in enumerate(band_descriptions):\n",
    "            if len(tpa_history[month][tpa_site][band]) > 0:\n",
    "                tpa_means.append(np.mean(tpa_history[month][tpa_site][band]))\n",
    "        if len(tpa_means) > 0:\n",
    "            tpa_site_vectors.append(tpa_means)\n",
    "            all_tpa_vectors.append(tpa_means)\n",
    "            \n",
    "for control_site in control_sites['name']:\n",
    "    control_site_vectors = []\n",
    "    for month in control_history.keys():\n",
    "        control_means = []\n",
    "        for index, band in enumerate(band_descriptions):\n",
    "            if len(control_history[month][control_site][band]) > 0:\n",
    "                control_means.append(np.mean(control_history[month][control_site][band]))\n",
    "        if len(control_means) > 0:\n",
    "            control_site_vectors.append(control_means)\n",
    "            all_control_vectors.append(control_means)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for band in range(np.shape(all_tpa_vectors)[1]):\n",
    "    plt.hist(np.array(all_tpa_vectors)[:,band], 20, histtype='step', density=True, label='TPA')\n",
    "    plt.hist(np.array(all_control_vectors)[:,band], 20, color='r', histtype='step', density=True, label='Bare Earth')\n",
    "    plt.title(band)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_tpa = (all_tpa_vectors - np.min(all_tpa_vectors)) / (np.max(all_tpa_vectors) - np.min(all_tpa_vectors))\n",
    "norm_control = (all_control_vectors - np.min(all_control_vectors)) / (np.max(all_control_vectors) - np.min(all_control_vectors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "pca.fit(np.concatenate((norm_tpa, norm_control)))\n",
    "tpa_pca = pca.transform(norm_tpa)\n",
    "control_pca = pca.transform(norm_control)\n",
    "\n",
    "plt.figure(figsize=(8,5), dpi=100)\n",
    "plt.scatter(control_pca[:,0], control_pca[:,1], label='Bare Earth')\n",
    "plt.scatter(tpa_pca[:,0], tpa_pca[:,1], c='r',label='TPA')\n",
    "plt.legend()\n",
    "plt.title('All Sites')\n",
    "#plt.savefig(os.path.join(output_dir, f\"All sites reflectance scatter PCA.png\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "f = open(os.path.join(DATA_DIR, \"city_history.pkl\"),\"wb\")\n",
    "pickle.dump(control_history, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#create city reflectance history dictionary\n",
    "history = {}\n",
    "sites = tpa_sites\n",
    "start = '2019-01-01'\n",
    "num_months = 22\n",
    "\n",
    "date = ee.Date(start)\n",
    "for month in tqdm(range(num_months)):\n",
    "    s2_data = get_s2_sr_cld_col(bali_rect, date, date.advance(1, 'month'))\n",
    "    s2_sr_median = s2_data.filterBounds(bali_rect) \\\n",
    "                        .map(add_cld_shdw_mask) \\\n",
    "                        .map(apply_cld_shdw_mask) \\\n",
    "                        .median() \\\n",
    "                        .clip(bali_rect)\n",
    "    \n",
    "    patches = get_tpa_patches(sites['name'], sites['polygons'], s2_sr_median)\n",
    "    date_text = str(datetime.fromtimestamp(date.getInfo()['value'] // 1000 + 86400).date())\n",
    "    history[date_text] = patches\n",
    "    \n",
    "    date = date.advance(1, 'month')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "f = open(os.path.join(DATA_DIR, \"tpa_history_clipped.pkl\"),\"wb\")\n",
    "pickle.dump(history, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(DATA_DIR, \"tpa_history_clipped.pkl\"), 'rb') as file:\n",
    "    tpa_history = pickle.load(file)\n",
    "with open(os.path.join(DATA_DIR, \"bare_earth_history.pkl\"), 'rb') as file:\n",
    "    bare_earth_history = pickle.load(file)\n",
    "with open(os.path.join(DATA_DIR, \"adjacent_history.pkl\"), 'rb') as file:\n",
    "    adjacent_history = pickle.load(file)\n",
    "with open(os.path.join(DATA_DIR, \"city_history.pkl\"), 'rb') as file:\n",
    "    city_history = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = []\n",
    "data_source = adjacent_history\n",
    "for site in data_source[list(data_source.keys())[0]]:\n",
    "    for month in data_source.keys():\n",
    "        means = []\n",
    "        for index, band in enumerate(band_descriptions):\n",
    "            if len(data_source[month][site][band]) > 0:\n",
    "                means.append(np.mean(data_source[month][site][band]))\n",
    "        if len(means) > 0:\n",
    "            vectors.append(means)\n",
    "adjacent_vectors = vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = []\n",
    "data_source = city_history\n",
    "for site in data_source[list(data_source.keys())[0]]:\n",
    "    for month in data_source.keys():\n",
    "        means = []\n",
    "        for index, band in enumerate(band_descriptions):\n",
    "            if len(data_source[month][site][band]) > 0:\n",
    "                means.append(np.mean(data_source[month][site][band]))\n",
    "        if len(means) > 0:\n",
    "            vectors.append(means)\n",
    "city_vectors = vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = []\n",
    "data_source = tpa_history\n",
    "for site in data_source[list(data_source.keys())[0]]:\n",
    "    for month in data_source.keys():\n",
    "        means = []\n",
    "        for index, band in enumerate(band_descriptions):\n",
    "            if len(data_source[month][site][band]) > 0:\n",
    "                means.append(np.mean(data_source[month][site][band]))\n",
    "        if len(means) > 0:\n",
    "            vectors.append(means)\n",
    "tpa_vectors = vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = []\n",
    "data_source = bare_earth_history\n",
    "for site in data_source[list(data_source.keys())[0]]:\n",
    "    for month in data_source.keys():\n",
    "        means = []\n",
    "        for index, band in enumerate(band_descriptions):\n",
    "            if len(data_source[month][site][band]) > 0:\n",
    "                means.append(np.mean(data_source[month][site][band]))\n",
    "        if len(means) > 0:\n",
    "            vectors.append(means)\n",
    "bare_earth_vectors = vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pixel_vectors(data_source):\n",
    "    pixel_vectors = []\n",
    "    for site in data_source[list(data_source.keys())[0]]:\n",
    "        for month in data_source.keys():\n",
    "            if np.shape(data_source[month][site]['B2']) != (0,):\n",
    "                width, height = np.shape(data_source[month][site]['B2'])\n",
    "                for i in range(width):\n",
    "                    for j in range(height):\n",
    "                        pixel_vector = []\n",
    "                        for band in band_descriptions:\n",
    "                            pixel_vector.append(data_source[month][site][band][i][j])\n",
    "                        pixel_vectors.append(pixel_vector)\n",
    "    return pixel_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bare_earth_pixel_vectors = get_pixel_vectors(bare_earth_history)\n",
    "city_pixel_vectors = get_pixel_vectors(city_history)\n",
    "adjacent_pixel_vectors = get_pixel_vectors(adjacent_history)\n",
    "tpa_pixel_vectors = get_pixel_vectors(tpa_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter null values set at -999\n",
    "print(len(tpa_pixel_vectors))\n",
    "tpa_pixel_vectors = [element for element in tpa_pixel_vectors if -999 not in element]\n",
    "print(len(tpa_pixel_vectors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = './figures/clustering'\n",
    "if not os.path.exists(output_dir):\n",
    "        os.mkdir(output_dir)\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(np.concatenate((tpa_vectors, city_vectors, bare_earth_vectors, adjacent_vectors)))\n",
    "tpa_pca = pca.transform(tpa_vectors)\n",
    "adjacent_pca = pca.transform(adjacent_vectors)\n",
    "city_pca = pca.transform(city_vectors)\n",
    "bare_earth_pca = pca.transform(bare_earth_vectors)\n",
    "\n",
    "plt.figure(figsize=(8,5), dpi=100, facecolor=(1,1,1))\n",
    "plt.scatter(bare_earth_pca[:,0], bare_earth_pca[:,1], s=12, alpha=0.65, label='Bare Earth')\n",
    "#plt.scatter(city_pca[:,0], city_pca[:,1], s=12, c='gray', alpha=0.65, label='City')\n",
    "#plt.scatter(adjacent_pca[:,0], adjacent_pca[:,1], s=12, c='green', alpha=0.65, label='Adjacent')\n",
    "plt.scatter(tpa_pca[:,0], tpa_pca[:,1], s=12, alpha=0.65,  c='r', label='TPA')\n",
    "plt.legend()\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "title = 'Multiclass Reflectance PCA'\n",
    "plt.title(title)\n",
    "#plt.savefig(os.path.join(output_dir, f\"{title}.png\"), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2)\n",
    "embedded = tsne.fit_transform(np.concatenate((all_tpa_vectors, all_control_vectors, bare_earth_vectors)))\n",
    "plt.figure(figsize=(8,5), dpi=100, facecolor=(1,1,1))\n",
    "plt.scatter(embedded[:len(all_tpa_vectors),0], embedded[:len(all_tpa_vectors),1], s=10, alpha=0.5, label='TPA')\n",
    "plt.scatter(embedded[len(all_tpa_vectors):len(bare_earth_vectors),0], \n",
    "            embedded[len(all_tpa_vectors):len(bare_earth_vectors),1], s=10, alpha=0.5, c='gray', label='City')\n",
    "plt.scatter(embedded[len(all_tpa_vectors) + len(bare_earth_vectors):,0], \n",
    "            embedded[len(all_tpa_vectors) + len(bare_earth_vectors):,1], s=10, alpha=0.5, c='r', label='Bare Earth')\n",
    "plt.title(tpa_site)\n",
    "plt.legend()\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "title = 'City vs. Bare Earth vs. TPA - Reflectance scatter tSNE'\n",
    "plt.title(title)\n",
    "plt.savefig(os.path.join(output_dir, f\"{title}.png\"), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "X = np.concatenate((city_vectors, \n",
    "                    bare_earth_vectors, \n",
    "                    adjacent_vectors, \n",
    "                    tpa_vectors))\n",
    "\n",
    "y = np.concatenate((np.zeros(len(city_vectors)), \n",
    "                    np.ones(len(bare_earth_vectors)), \n",
    "                    np.zeros(len(adjacent_vectors)), \n",
    "                    np.ones(len(tpa_vectors))))\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "clf = tree.DecisionTreeClassifier(max_leaf_nodes=16, max_depth=64, class_weight={0: 500, 1:1})\n",
    "clf = clf.fit(X_train, y_train)\n",
    "print(\"Accuracy:\", clf.score(X_test, y_test))\n",
    "print(\"Feature Importances:\")\n",
    "for band, importance in zip(band_descriptions, clf.feature_importances_):\n",
    "    print(f\"{band}: {importance:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = './figures/tree_classification'\n",
    "if not os.path.exists(output_dir):\n",
    "        os.mkdir(output_dir)\n",
    "\n",
    "data_source = adjacent_history\n",
    "plt.figure(dpi=100, facecolor=(1,1,1), figsize=(20,4))\n",
    "for index, site in enumerate(list(data_source[list(data_source.keys())[0]].keys())[:10]):\n",
    "    classification_images = []\n",
    "    rgb_images = []\n",
    "    for month in data_source.keys():\n",
    "        if np.shape(data_source[month][site]['B2']) != (0,):\n",
    "            width, height = np.shape(data_source[month][site]['B2'])\n",
    "            classification = np.zeros((width, height))\n",
    "            data = data_source[month][site]\n",
    "            rgb = np.array([data['B4'], data['B3'], data['B2']])\n",
    "            rgb = np.moveaxis(rgb, 0, -1)\n",
    "            for i in range(width):\n",
    "                for j in range(height):\n",
    "                    pixel_vector = []\n",
    "                    for band in band_descriptions:\n",
    "                        pixel_vector.append(data_source[month][site][band][i][j])\n",
    "                    classification[i,j] = clf.predict([pixel_vector])\n",
    "            classification_images.append(classification)\n",
    "            rgb_images.append(rgb)\n",
    "    plt.subplot(2,10,2*index + 1)\n",
    "    plt.imshow(np.median(rgb_images, axis=0) / 3000)\n",
    "    plt.axis('off')\n",
    "    plt.title(site, size=8)\n",
    "    plt.subplot(2,10,2*index + 2)\n",
    "    im = plt.imshow(np.mean(classification_images, axis=0), cmap='seismic', vmin=0, vmax=1)\n",
    "    plt.axis('off')\n",
    "    plt.title('Classification', size=8)\n",
    "    plt.colorbar(im,fraction=0.045, pad=0.02, ticks=[0, 1])\n",
    "\n",
    "plt.suptitle('TPA Patches')\n",
    "plt.tight_layout()\n",
    "#plt.savefig(os.path.join(output_dir, f\"Control Site Decision Tree Classification.png\"), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "X = np.concatenate((city_pixel_vectors, \n",
    "                    bare_earth_pixel_vectors, \n",
    "                    adjacent_pixel_vectors, \n",
    "                    tpa_pixel_vectors))\n",
    "\n",
    "y = np.concatenate((np.zeros(len(city_pixel_vectors)), \n",
    "                    np.zeros(len(bare_earth_pixel_vectors)) + 0, \n",
    "                    np.zeros(len(adjacent_pixel_vectors)), \n",
    "                    np.zeros(len(tpa_pixel_vectors)) + 1))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "clf = tree.DecisionTreeClassifier(max_leaf_nodes=256, max_depth=8, class_weight={0: 2, 1:1})\n",
    "clf = clf.fit(X_train, y_train)\n",
    "print(\"Accuracy:\", clf.score(X_test, y_test))\n",
    "print(\"Feature Importances:\")\n",
    "for band, importance in zip(band_descriptions, clf.feature_importances_):\n",
    "    print(f\"{band}: {importance:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = './figures/tree_classification'\n",
    "if not os.path.exists(output_dir):\n",
    "        os.mkdir(output_dir)\n",
    "\n",
    "data_source = city_history\n",
    "plt.figure(dpi=100, facecolor=(1,1,1), figsize=(20,4))\n",
    "for index, site in enumerate(list(data_source[list(data_source.keys())[0]].keys())[:10]):\n",
    "    classification_images = []\n",
    "    rgb_images = []\n",
    "    for month in data_source.keys():\n",
    "        if np.shape(data_source[month][site]['B2']) != (0,):\n",
    "            width, height = np.shape(data_source[month][site]['B2'])\n",
    "            classification = np.zeros((width, height))\n",
    "            data = data_source[month][site]\n",
    "            rgb = np.array([data['B4'], data['B3'], data['B2']])\n",
    "            rgb = np.moveaxis(rgb, 0, -1)\n",
    "            for i in range(width):\n",
    "                for j in range(height):\n",
    "                    pixel_vector = []\n",
    "                    for band in band_descriptions:\n",
    "                        pixel_vector.append(data_source[month][site][band][i][j])\n",
    "                    classification[i,j] = clf.predict([pixel_vector])\n",
    "            classification_images.append(classification)\n",
    "            rgb_images.append(rgb)\n",
    "    plt.subplot(2,10,2*index + 1)\n",
    "    plt.imshow(np.median(rgb_images, axis=0) / 3000)\n",
    "    plt.axis('off')\n",
    "    plt.title(site, size=8)\n",
    "    plt.subplot(2,10,2*index + 2)\n",
    "    im = plt.imshow(np.mean(classification_images, axis=0), cmap='seismic', vmin=0, vmax=1)\n",
    "    plt.axis('off')\n",
    "    plt.title('Classification', size=8)\n",
    "    plt.colorbar(im,fraction=0.045, pad=0.02, ticks=[0, 1])\n",
    "\n",
    "plt.suptitle('TPA Patches')\n",
    "plt.tight_layout()\n",
    "#plt.savefig(os.path.join(output_dir, f\"Control Site Decision Tree Classification.png\"), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = './figures/clustering'\n",
    "if not os.path.exists(output_dir):\n",
    "        os.mkdir(output_dir)\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(np.concatenate((tpa_pixel_vectors, city_pixel_vectors, bare_earth_pixel_vectors, adjacent_pixel_vectors)))\n",
    "tpa_pca = pca.transform(tpa_pixel_vectors)\n",
    "adjacent_pca = pca.transform(adjacent_pixel_vectors)\n",
    "city_pca = pca.transform(city_pixel_vectors)\n",
    "bare_earth_pca = pca.transform(bare_earth_pixel_vectors)\n",
    "\n",
    "plt.figure(figsize=(8,5), dpi=200, facecolor=(1,1,1))\n",
    "plt.scatter(bare_earth_pca[:,0], bare_earth_pca[:,1], s=.1, alpha=0.05, label='Bare Earth')\n",
    "plt.scatter(city_pca[:,0], city_pca[:,1], s=0.1, c='gray', alpha=0.05, label='City')\n",
    "plt.scatter(adjacent_pca[:,0], adjacent_pca[:,1], s=.1, c='green', alpha=0.05, label='Adjacent')\n",
    "plt.scatter(tpa_pca[:,0], tpa_pca[:,1], s=.1, alpha=0.05,  c='r', label='TPA')\n",
    "legend = plt.legend(markerscale=10)\n",
    "for element in legend.legendHandles:\n",
    "    element.set_alpha(1)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "title = 'Per Pixel Multiclass Reflectance PCA'\n",
    "plt.title(title)\n",
    "plt.savefig(os.path.join(output_dir, f\"{title}.png\"), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = './figures/reflectance'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.mkdir(output_dir)\n",
    "    \n",
    "vectors = [tpa_pixel_vectors, city_pixel_vectors, bare_earth_pixel_vectors, adjacent_pixel_vectors]\n",
    "names = ['TPA', 'City', 'Bare Earth', 'Adjacent']\n",
    "color = ['C0', 'gray', 'red', 'green']\n",
    "\n",
    "plt.figure(figsize=(12, 5), facecolor=(1,1,1), dpi=150)\n",
    "for index in range(len(vectors)):\n",
    "    vector = vectors[index]\n",
    "    band_means = []\n",
    "    for band in range(np.shape(vector)[1]):\n",
    "        band_means.append(np.mean(np.array(vector)[:,band]))\n",
    "    plt.plot(band_wavelengths, band_means, color=color[index], label=names[index])\n",
    "plt.xticks(band_wavelengths, list(band_descriptions), rotation=45, ha='right')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "title = f\"Mean Pixel Spectral Profile by Ground Cover Type - 2019-01-01 - 2020-11-01\"\n",
    "plt.title(title)\n",
    "plt.savefig(os.path.join(output_dir, title + '.png'), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = '2019-01-01'\n",
    "end = '2019-11-01'\n",
    "s2_data = get_s2_sr_cld_col(bali_rect, start, end)\n",
    "s2_sr_median = s2_data.filterBounds(bali_rect) \\\n",
    "                    .map(add_cld_shdw_mask) \\\n",
    "                    .map(apply_cld_shdw_mask) \\\n",
    "                    .median()\n",
    "test_patch = get_patches([control_sites['name'].iloc[5]], [control_sites['coords'].iloc[5]], 0.02, s2_sr_median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create city reflectance history dictionary\n",
    "history = {}\n",
    "sites = bare_earth_sites.iloc[4:5]\n",
    "start = '2019-01-01'\n",
    "num_months = 22\n",
    "\n",
    "date = ee.Date(start)\n",
    "for month in tqdm(range(num_months)):\n",
    "    s2_data = get_s2_sr_cld_col(bali_rect, date, date.advance(1, 'month'))\n",
    "    s2_sr_median = s2_data.filterBounds(bali_rect) \\\n",
    "                        .map(add_cld_shdw_mask) \\\n",
    "                        .map(apply_cld_shdw_mask) \\\n",
    "                        .median() \\\n",
    "                        .clip(bali_rect)\n",
    "    \n",
    "    patches = get_patches(sites['name'], sites['coords'], 0.03, s2_sr_median)\n",
    "    date_text = str(datetime.fromtimestamp(date.getInfo()['value'] // 1000 + 86400).date())\n",
    "    history[date_text] = patches\n",
    "    \n",
    "    date = date.advance(1, 'month')\n",
    "bare_earth_site = history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = './figures/tree_classification'\n",
    "if not os.path.exists(output_dir):\n",
    "        os.mkdir(output_dir)\n",
    "\n",
    "data_source = tpa_test_site\n",
    "plt.figure(dpi=100, facecolor=(1,1,1), figsize=(20,4))\n",
    "for index, site in enumerate(list(data_source[list(data_source.keys())[0]].keys())[:10]):\n",
    "    classification_images = []\n",
    "    rgb_images = []\n",
    "    for month in tqdm(data_source.keys()):\n",
    "        if np.shape(data_source[month][site]['B2']) != (0,):\n",
    "            width, height = np.shape(data_source[month][site]['B2'])\n",
    "            classification = np.zeros((width, height))\n",
    "            data = data_source[month][site]\n",
    "            rgb = np.array([data['B4'], data['B3'], data['B2']])\n",
    "            rgb = np.moveaxis(rgb, 0, -1)\n",
    "            for i in range(width):\n",
    "                for j in range(height):\n",
    "                    pixel_vector = []\n",
    "                    for band in band_descriptions:\n",
    "                        pixel_vector.append(data_source[month][site][band][i][j])\n",
    "                    classification[i,j] = clf.predict([pixel_vector])\n",
    "            classification_images.append(classification)\n",
    "            rgb_images.append(rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=200, facecolor=(1,1,1), figsize=(10,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(np.median(rgb_images, axis=0) / 3000)\n",
    "plt.axis('off')\n",
    "plt.title(site, size=8)\n",
    "plt.subplot(1,2,2)\n",
    "im = plt.imshow(np.mean(classification_images, axis=0), cmap='seismic', vmin=0, vmax=1)\n",
    "plt.axis('off')\n",
    "plt.title('Classification', size=8)\n",
    "plt.colorbar(im,fraction=0.045, pad=0.02, ticks=[0, 1])\n",
    "title = f\"Bare Earth Site Decision Tree Classification - 0.03 Patch\"\n",
    "plt.suptitle(title)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_dir, title + '.png'), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create city reflectance history dictionary\n",
    "history = {}\n",
    "sites = city_sites.iloc[7:8]\n",
    "start = '2019-01-01'\n",
    "num_months = 22\n",
    "\n",
    "date = ee.Date(start)\n",
    "for month in tqdm(range(num_months)):\n",
    "    s2_data = get_s2_sr_cld_col(bali_rect, date, date.advance(1, 'month'))\n",
    "    s2_sr_median = s2_data.filterBounds(bali_rect) \\\n",
    "                        .map(add_cld_shdw_mask) \\\n",
    "                        .map(apply_cld_shdw_mask) \\\n",
    "                        .median() \\\n",
    "                        .clip(bali_rect)\n",
    "    \n",
    "    patches = get_patches(sites['name'], sites['coords'], 0.03, s2_sr_median)\n",
    "    date_text = str(datetime.fromtimestamp(date.getInfo()['value'] // 1000 + 86400).date())\n",
    "    history[date_text] = patches\n",
    "    \n",
    "    date = date.advance(1, 'month')\n",
    "tpa_test_site = history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create city reflectance history dictionary\n",
    "history = {}\n",
    "sites = bare_earth_sites.iloc[4:5]\n",
    "start = '2019-01-01'\n",
    "num_months = 22\n",
    "\n",
    "date = ee.Date(start)\n",
    "for month in tqdm(range(num_months)):\n",
    "    s2_data = get_s2_sr_cld_col(bali_rect, date, date.advance(1, 'month'))\n",
    "    s2_sr_median = s2_data.map(add_cld_shdw_mask) \\\n",
    "                        .map(apply_cld_shdw_mask) \\\n",
    "                        .median()\n",
    "    \n",
    "    patches = get_patches(['TPA Jimbaran'], [[115.1658103, -8.7944717]], 0.03, s2_sr_median)\n",
    "    date_text = str(datetime.fromtimestamp(date.getInfo()['value'] // 1000 + 86400).date())\n",
    "    history[date_text] = patches\n",
    "    \n",
    "    date = date.advance(1, 'month')\n",
    "tpa_site = history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(os.path.join(DATA_DIR, \"tpa_jimbaran_0.03_patch.pkl\"),\"wb\")\n",
    "pickle.dump(tpa_site, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "output_dir = './figures/tree_classification'\n",
    "if not os.path.exists(output_dir):\n",
    "        os.mkdir(output_dir)\n",
    "\n",
    "data_source = tpa_test_site\n",
    "plt.figure(dpi=100, facecolor=(1,1,1), figsize=(20,4))\n",
    "for index, site in enumerate(list(data_source[list(data_source.keys())[0]].keys())[:10]):\n",
    "    classification_images = []\n",
    "    rgb_images = []\n",
    "    for month in tqdm(data_source.keys()):\n",
    "        if np.shape(data_source[month][site]['B2']) != (0,):\n",
    "            width, height = np.shape(data_source[month][site]['B2'])\n",
    "            classification = np.zeros((width, height))\n",
    "            data = data_source[month][site]\n",
    "            rgb = np.array([data['B4'], data['B3'], data['B2']])\n",
    "            rgb = np.moveaxis(rgb, 0, -1)\n",
    "            for i in range(width):\n",
    "                for j in range(height):\n",
    "                    pixel_vector = []\n",
    "                    for band in band_descriptions:\n",
    "                        pixel_vector.append(data_source[month][site][band][i][j])\n",
    "                    classification[i,j] = clf.predict([pixel_vector])\n",
    "            classification_images.append(classification)\n",
    "            rgb_images.append(rgb)\n",
    "            \n",
    "plt.figure(dpi=200, facecolor=(1,1,1), figsize=(10,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(np.median(rgb_images, axis=0) / 3000)\n",
    "plt.axis('off')\n",
    "plt.title(site, size=8)\n",
    "plt.subplot(1,2,2)\n",
    "im = plt.imshow(np.mean(classification_images, axis=0), cmap='seismic', vmin=0, vmax=1)\n",
    "plt.axis('off')\n",
    "plt.title('Classification', size=8)\n",
    "plt.colorbar(im,fraction=0.045, pad=0.02, ticks=[0, 1])\n",
    "title = f\"TPA Site Decision Tree Classification - 0.03 Patch\"\n",
    "plt.suptitle(title)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_dir, title + '.png'), bbox_inches='tight')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
